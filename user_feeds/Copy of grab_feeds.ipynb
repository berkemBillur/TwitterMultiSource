{"cells":[{"cell_type":"markdown","metadata":{"id":"yxWCfoFOdmvR"},"source":["## MOUNT"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2191,"status":"ok","timestamp":1662481582442,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"JPWjXb5odVuX","outputId":"d0510603-ee9b-49cf-aaf8-b50dadc9b73c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/MSc_project/.MAIN\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/MSc_project/.MAIN"]},{"cell_type":"markdown","metadata":{"id":"JEe_wcYcdmLo"},"source":["## PIPS"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10118,"status":"ok","timestamp":1662477381624,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"2NNrF4MCdvYX","outputId":"5e56350a-6e0d-4cc3-b3b9-6723a029a8c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting preprocessor\n","  Downloading preprocessor-1.1.3.tar.gz (4.2 kB)\n","Building wheels for collected packages: preprocessor\n","  Building wheel for preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for preprocessor: filename=preprocessor-1.1.3-py3-none-any.whl size=4477 sha256=4f2ee6f4d7789daacb301b7f41d6ab7d1e19ca7171e66a7043aa271d28f3fc73\n","  Stored in directory: /root/.cache/pip/wheels/0e/b7/36/aa37256db62b4bfd35a6f1b5536e9ba843f257b79dcbf3d5f1\n","Successfully built preprocessor\n","Installing collected packages: preprocessor\n","Successfully installed preprocessor-1.1.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tweepy==4.10.0\n","  Downloading tweepy-4.10.0-py3-none-any.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from tweepy==4.10.0) (1.3.1)\n","Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tweepy==4.10.0) (3.2.0)\n","Collecting requests<3,>=2.27.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy==4.10.0) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy==4.10.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy==4.10.0) (2022.6.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy==4.10.0) (2.10)\n","Installing collected packages: requests, tweepy\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: tweepy\n","    Found existing installation: tweepy 3.10.0\n","    Uninstalling tweepy-3.10.0:\n","      Successfully uninstalled tweepy-3.10.0\n","Successfully installed requests-2.28.1 tweepy-4.10.0\n"]}],"source":["!pip install preprocessor\n","!pip install tweepy==4.10.0"]},{"cell_type":"markdown","metadata":{"id":"N4H2dANsdxjQ"},"source":["## IMPORTS "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":671,"status":"ok","timestamp":1662477382288,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"-t2N7n7dd0q3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tweepy\n","import json\n","import os\n","import os.path\n","import time\n","import multiprocessing"]},{"cell_type":"markdown","metadata":{"id":"us9mGrGtd55Q"},"source":["## GRAB FEEDS FUNCTION"]},{"cell_type":"code","execution_count":79,"metadata":{"executionInfo":{"elapsed":200,"status":"ok","timestamp":1662484073144,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"wcNDqyFwd9sn"},"outputs":[],"source":["from matplotlib import collections\n","from psutil import users\n","import tweepy\n","from tweepy import OAuthHandler\n","import pandas as pd\n","import numpy as np\n","import datetime\n","from datetime import timedelta\n","from datetime import datetime\n","import json\n","import time\n","import glob\n","import os\n","from collections import defaultdict\n","import configparser\n","from copy import deepcopy\n","import multiprocessing\n","from joblib import Parallel, delayed\n","import time\n","import os.path\n","import random\n","\n","\n","class crawler(object):\n","    def __init__(self, hashtag,file_names,num_keys): \n","\n","        self.hashtag = hashtag\n","        self.sep = os.path.sep  \n","        self.file_names = file_names\n","        self.num_keys = num_keys\n","        self.ms_path = f'tweets/{hashtag}'\n","        self.path = f'tweets/{hashtag}/100_feeds'\n","        if not os.path.exists(self.path):\n","            os.makedirs(self.path)\n","\n","\n","###########################################################\n","###########################################################\n","# API KEY FUNCTIONS\n","###########################################################\n","###########################################################\n","\n","\n","    def get_api_list(self,filename,num_keys):\n","        settings_file = f\"apikeys{self.sep}{filename}\"\n","        # Read config settings\n","        config = configparser.ConfigParser()\n","        config = configparser.ConfigParser(interpolation=None)\n","        config.readfp(open(settings_file))\n","\n","        # Create API objects for each of the API keys\n","        # 1-based indexing of config file\n","        start_idx = 1\n","        end_idx = num_keys\n","        num_api_keys = end_idx - start_idx + 1\n","\n","        apis = []\n","\n","        print(\"Creating api objects for {} API keys\".format(num_api_keys))\n","        for api_idx in range(start_idx, end_idx + 1):\n","            consumer_key = config.get('API Keys ' + str(api_idx), 'consumer_key')\n","            consumer_secret = config.get('API Keys ' + str(api_idx), 'consumer_secret')\n","            access_token_key = config.get('API Keys ' + str(api_idx),\n","                                        'access_token')\n","            access_token_secret = config.get('API Keys ' + str(api_idx),\n","                                            'access_secret')\n","\n","            # Connect to Twitter API\n","            try:\n","                auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","                auth.set_access_token(access_token_key, access_token_secret)\n","                api = tweepy.API(auth, wait_on_rate_limit=True)\n","            except Exception as e:\n","                print(\"Error while creating API object: \" + str(e))\n","                continue\n","            else:\n","                apis.append(api)\n","        print(f'found {len(apis)} apis from {filename}')\n","        idx = []\n","        for i, apii in enumerate(apis):\n","            try: \n","                a = apii.verify_credentials()\n","            except tweepy.errors.TweepyException as e:\n","                idx.append(i)\n","                # print(i+1)\n","                # print(e)\n","        \n","        working_api = np.delete(apis,idx)\n","        print(f'{len(working_api)} api work')\n","        return working_api.tolist()\n","\n","    def make_api(self):\n","        consumer_key = '3rJOl1ODzm9yZy63FACdg'\n","        consumer_secret = '5jPoQ5kQvMJFDYRNE8bQ4rHuds4xJqhvgNJM4awaE8'\n","\n","        tokens=\"1273621486201450497-2KsGK9JgSSdabGYxFlDNB214MXwi35:kbLULiG4k7SvUlwFkr0p6ESTdvARIThfmI1lQ5GuQmH8s,\"\n","        # tokens+=\"1186873796982128641-RHYpdyKJIfSX6KtRfA6k73emHMOhBY:Zth72rrtcZGfqJ4B9TK8dH1RhS8HC6KOlTDqA3bJnMnGL,\" DOES NOT WORK\n","        tokens+=\"1186715756437868546-U9LOFzfSEk4tTOYHoKn7X08vWFm3An:kWWnOy6JLbHI9nG8GihGIjB1SeH5nJE8oqi4KiRIiHB2B,\"\n","        tokens+=\"1186707518799650816-KOvTi7HOrZ1KiVRXyAvNjpJofF3lY8:EsXAVrtyqkekdmtr0GcZCiVk9RwAJC4v9Kj3fo0RWPpgp,\"\n","        tokens+=\"1186873046726041600-rNJoDJulul6m5GQUbXUG7zNfpnJywj:OsR7WIHZ9PEdlmIE7K36V1CrM3OiMKIzAboNXMdEJm1UJ,\"\n","        tokens+=\"1186872285782794240-X4x7t8KRaf3Ce3oNI2ka7DO7rapVys:VUyNnBIRr6oRpBr10lbEF0MzlGz6eJJW3STUWOGyXgVbr,\"\n","        tokens+=\"1261898258739126273-Dw4HYHPkKj82V4RcgYhpxLsnJdMALV:384AYTeZqRykw5ADdVXhi1BXZadOuflhzOiKljh1Pt0bi,\"\n","        tokens+=\"1261898258739126273-Dw4HYHPkKj82V4RcgYhpxLsnJdMALV:384AYTeZqRykw5ADdVXhi1BXZadOuflhzOiKljh1Pt0bi,\"\n","        tokens+=\"1261901714564583424-odKz6Xonlzg1QVg32o6hdqXbGAZ6nt:lx7hysS64y7kyc0pr4IMdqXNJr8yqbgY9vZ7qhnL6ldGY,\"\n","        tokens+=\"1261905369485373440-mxYEQlU9tEjFvFClg3YTZU2Krh4ezO:mcvotgeJvuOgkJb5pXejP9qzjDBcALZSHqGJesH7FzOOs,\"\n","        tokens+=\"1261908827961585664-YkhHP2z6XczyTwBt8pT7IYmYw4XFTN:OQJhcBCQiHWCOS1lcUHlZp8Minc7drmpW861tFNwweABC,\"\n","        tokens+=\"1261911771528364032-uFSYzCtvZeQPLvSIR2NZM3MwYnPDx9:gjLJUDRkiC6qVhh6zN8czDLzcE3Bnhge9Sgq7QIQsRfZp,\"\n","        tokens+=\"1261913654967992321-dq90nrKd8OTIAiBwK4rmDPR1hvBwTb:6lL8f15qO9DOMczUzImxwUjMmDvPHlQcd3eJBtUzQ53ck,\"\n","        tokens+=\"1261918659942871040-ThZsmIIeIWLfTuhNB8uD3HORhunMVS:D3QNGphJ1R870yzBV41QSvezqS6rysRVgEG1RU3c7tH30,\"\n","        tokens+=\"1261929369691283456-0CdW3UgD4ONxFCshwmBqroq3m8BFG7:YpeYZ3hWRNkFOzfoJGiIPXnW65vzul5e7ofDN1q3zZErV,\"\n","        tokens+=\"1261930395513192448-14EJHzMXDGzDN65NAx9HLXaz8Y1OHf:97qLbZ53tPQl5xwmNPDBlADBrSlZZeXd659N5XXDG2O5E,\"\n","        tokens+=\"1261931615837581317-Bdgkok64OnA0HWB9q3NZfFF12FpBjD:qeYMydCMxt2ctLOkfNV3yix6erJoxti7NiOScNCQ0zHf6,\"\n","        tokens+=\"1261932804046114816-5s1MVYfHsfwjxz1pZ2jhLE3jgO0enO:8XmjhdkKTakxF9a3ZKCMYJzlNUb9ARChEZ74XH91qZVqg,\"\n","        tokens+=\"1259732232433856512-knm0EqhoG7tyEjTsgIQc6974cEy976:lavQjBjsOdZgUy5U64ZtK8YYdfwQeknl9Oy2CP7nJ3uE9,\"\n","        tokens+=\"1262372803174531072-uyPlAvb0BHwSuB1kgPOroGMyjFPtzj:Bsnfo8WTYNqEzr5S9fW9gzfWFc9E2ZqM0wXwUGIUgSwPo,\"\n","        tokens+=\"1262374702003044353-GCVqUDfNPkRGnBzmKHTPeZmmsBHjxx:pzqueROwD89WH3hZyr7qDV4ftnu8OPZM3OfhyNSM4pi9T,\"\n","        tokens+=\"1261903040946171905-mLBFRyOpShKunFrxk5o5DDoJERTEE1:Osvx77SI7qS0qIIYqlI43eLOCOS6UL1e3XSYcUyrYpCHz\"\n","\n","        connections=[]\n","\n","        for tk in tokens.split(\",\"):\n","            token=tk.split(\":\")\n","            auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret,token[0], token[1])\n","            api = tweepy.API(auth, wait_on_rate_limit=True)\n","            # auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","            # auth.set_access_token(token[0], token[1])\n","            # api = tweepy.API(auth, wait_on_rate_limit=True)\n","            \n","            connections.append(api) \n","\n","\n","        print(f'\\nfound {len(connections)} apis from juans stuff')\n","        idx = []\n","        for i, apii in enumerate(connections):\n","            try: \n","                a = apii.verify_credentials()\n","            except tweepy.TweepyException as e:\n","                idx.append(i)\n","                # print(e)\n","        \n","        working_api = np.delete(connections,idx)\n","        print(f'{len(working_api)} api work')\n","        return working_api.tolist()\n","\n","    ### HELPER FUNCTIONS\n","\n","    def load_ms_cases(self):\n","        path = f'{self.ms_path}/{self.hashtag}_ms_cases.json'\n","        with open(path) as jf:\n","            data = json.load(jf)\n","        return data\n","\n","    def get_feeds_db(self):\n","        jsons = [pos_json for pos_json in os.listdir(self.path) if pos_json.endswith('.json')]\n","        all_js = {}\n","        for file in jsons:\n","            with open(os.path.join(f'{self.path}/' + file)) as jf:\n","                all_js = { **all_js, **json.load(jf) }\n","        print(f'pulled data on {len(all_js)} users')\n","        return all_js\n","\n","    def find_all_users(self,data):\n","\n","        users = []\n","        for key,value in data.items():\n","            users.append(value['user-id'])\n","            infector = value['infector-info']\n","            i = [k for k in infector]\n","            inf = infector[i[0]]\n","            users.append(inf['user-id'])\n","            for informer in value['informers-data']:\n","                users.append(informer['user-id'])\n","        unique_users = list(set(users))\n","        return unique_users\n","\n","    @staticmethod\n","    def process_tweet(tweet):\n","        d = {'id':tweet['id_str'], 'tweet-text': tweet['text'],'created_at': tweet['created_at'],\n","        'retweet_count': tweet['retweet_count'], 'favourite_count':tweet['favorite_count']}\n","        return d\n","\n","    def check_already_done(self,users):\n","\n","        users_done_data = self.get_feeds_db()\n","        users_done_ids = list( users_done_data.keys() )\n","\n","        print(f'already have feeds of {len(users_done_ids)} users')\n","\n","        not_done = [user for user in users if user not in users_done_ids ]\n","\n","        print(not_done)\n","\n","        print(f'now getting feeds of remaining {len(not_done)} users')\n","\n","        return not_done\n","\n","\n","    #######\n","    #### MAIN FUNCTION\n","    #######\n","\n","\n","    def get_all_feeds(self):\n","\n","        print(f'working on hashtag {self.hashtag}')\n","\n","        # juan_api = self.make_api()\n","\n","        # everyone_api = self.get_api_list(self.file_names[0],self.num_keys[0])\n","\n","        # just_my_api = self.get_api_list(self.file_names[1],self.num_keys[1])\n","\n","        new_api = self.get_api_list(self.file_names[2],self.num_keys[2])\n","\n","        all_api = new_api\n","        # all_api = just_my_api + juan_api + everyone_api\n","\n","        self.all_api = all_api\n","        num_api = len(all_api)\n","        print(f'total working api is {num_api}')\n","        #  we will keep track of the api that we use\n","\n","        ################################################################################################################\n","        ########################################################\n","        ### PROCESS INTO NECESSARY FORMAT\n","\n","        data = self.load_ms_cases()\n","\n","        print('found unique users of this set')\n","        users = self.find_all_users(data)\n","\n","\n","        ### CHECKING FOR USERS THAT WE HAVE NOT EXTRACTED FEEDS FOR\n","\n","        users = self.check_already_done(users)\n","\n","        print(f'Getting the feeds for each unique user in the hashtag {self.hashtag}')\n","        print('begin timing...\\n')\n","\n","        start = time.perf_counter()\n","        feeds = {}\n","        count_users_pulled = 0 # counter count the number of accounts we request to pull in this batch\n","        num_api = len(all_api)-1\n","        api_idx = 0\n","\n","        for user in users:\n","\n","            try:\n","                api_idx = np.random.randint(0,num_api)\n","                print(f'using api number {api_idx}')\n","                pages = all_api[api_idx].user_timeline(user_id=user, count = 100)\n","                count_users_pulled += 1\n","                ## process each tweet\n","                processed_tweets = [self.process_tweet(tweet._json) for tweet in pages]\n","                feeds.update({user:processed_tweets} )\n","                stamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n","                rn = np.random.randint(0,99999999)\n","                s_path = f'{self.path}/feeds_{stamp}_{rn}.json'\n","                print(feeds)\n","                with open(s_path, 'w') as fp:\n","                    json.dump(feeds,fp)\n","                feeds.clear()\n","\n","            except tweepy.TweepyException as e: # we've got an error with the tweepy API\n","                print(e) \n","                print(f'get rid of api number {api_idx}')\n","                del all_api[api_idx]\n","                num_api -=1 # working with one less api\n","\n","        fin = time.perf_counter()\n","        print(f'finished extracting tweets of everyone in {(fin-start)/3600} hours')\n","\n","        stamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n","        s_path = f'{self.path}/feeds_{stamp}.json'\n","        with open(s_path, 'w') as fp:\n","            json.dump(feeds,fp)"]},{"cell_type":"markdown","metadata":{"id":"TlsrBiSk-izS"},"source":["## Run Script"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mcDKd28PdaA_","executionInfo":{"status":"error","timestamp":1662484081252,"user_tz":-60,"elapsed":5892,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"d8c9eb44-e0e3-4368-af7f-c6af800d79be"},"outputs":[{"output_type":"stream","name":"stdout","text":["working on hashtag climatechange\n","Creating api objects for 10 API keys\n","found 10 apis from apikeys3.txt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: This method will be removed in future versions.  Use 'parser.read_file()' instead.\n"]},{"output_type":"stream","name":"stdout","text":["10 api work\n","total working api is 10\n","found unique users of this set\n","pulled data on 2993 users\n","already have feeds of 2993 users\n","['1521881857498910721', '441208401', '1502581985834848261', '3225642185', '1508181375932932101', '1499577679401603089', '67873734', '1383091918859608064', '1530062693532573696', '323543635', '1369186881431162881', '30588028', '2720051267', '26028448', '1428715012650987525', '396879947', '1554936047162871813', '1067846455837233152', '1378065150', '1548884151285305345', '719586401713434625', '308212534', '1504412905403527172']\n","now getting feeds of remaining 23 users\n","Getting the feeds for each unique user in the hashtag climatechange\n","begin timing...\n","\n","using api number 2\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 2\n","using api number 7\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 7\n","using api number 6\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 6\n","using api number 3\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 3\n","using api number 2\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 2\n","using api number 3\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 3\n","using api number 0\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 0\n","using api number 0\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 0\n","using api number 0\n","401 Unauthorized\n","Not authorized.\n","get rid of api number 0\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-fe89a0263288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_feeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-79-affef86fc92d>\u001b[0m in \u001b[0;36mget_all_feeds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mapi_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'using api number {api_idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_api\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapi_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: high <= 0"]}],"source":["# hashtags = ['avengers','blm','borisjohnson','brexit','climatechange','covid','gaza','loveisland','monkeypox','nhs','olivianewtonjohn','supercup','UkraineWar']\n","\n","hashtags = ['climatechange','covid','gaza','loveisland']\n","\n","# hashtags = ['covid','gaza','loveisland']\n","\n","\n","key_paths = ['apikeys.txt', 'apikeys2.txt','apikeys3.txt']\n","\n","num_of_keys = [45,83,10]\n","\n","for hashtag in hashtags:\n","\n","    c = crawler(hashtag,key_paths, num_of_keys)\n","\n","    c.get_all_feeds()\n","\n","    print('')"]}],"metadata":{"colab":{"background_execution":"on","collapsed_sections":["yxWCfoFOdmvR","JEe_wcYcdmLo","N4H2dANsdxjQ"],"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPCQi0NugM3pQoXwMp3K+Kg"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}