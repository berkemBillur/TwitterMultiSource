{"cells":[{"cell_type":"markdown","source":["## MOUNT"],"metadata":{"id":"FMiPphSbp48l"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/MSc_project/.MAIN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjB04glDz9GM","executionInfo":{"status":"ok","timestamp":1662369142031,"user_tz":-60,"elapsed":17964,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"20699c93-1b08-43c0-b531-1582ef353b9e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/MSc_project/.MAIN\n"]}]},{"cell_type":"markdown","source":["## PIPS"],"metadata":{"id":"oQDW0t3op8cv"}},{"cell_type":"code","source":["!pip install pandas==1.2.4\n","!pip install xgboost\n","!pip install lightgbm\n","!pip install tweet-preprocessor\n","!pip install transformers"],"metadata":{"id":"nX70KVtb4G0i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662369174255,"user_tz":-60,"elapsed":32227,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"b460eac2-da01-4e39-bd44-672b874906ac"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandas==1.2.4\n","  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 11.4 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (2022.2.1)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.4) (1.15.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","Successfully installed pandas-1.2.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tweet-preprocessor\n","  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n","Installing collected packages: tweet-preprocessor\n","Successfully installed tweet-preprocessor-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 11.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 26.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 48.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"]}]},{"cell_type":"markdown","source":["## DATA LOAD AND CLEAN"],"metadata":{"id":"ock8vM_pqAgl"}},{"cell_type":"code","source":["import pandas as pd\n","import os.path\n","\n","import nltk\n","from nltk.stem import PorterStemmer # for stemming\n","from nltk.stem import WordNetLemmatizer # for lemmatization\n","from nltk.corpus import stopwords\n","import re\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBClassifier, Booster\n","from lightgbm import LGBMClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","\n","import numpy as np\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import train_test_split\n","\n","import preprocessor as p\n","import joblib"],"metadata":{"id":"V9Sz024N4MOp","executionInfo":{"status":"ok","timestamp":1662369175953,"user_tz":-60,"elapsed":1705,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"POjBgP6uLqHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662369177370,"user_tz":-60,"elapsed":1422,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"a9b7fca8-3898-49be-a11e-21d6d4dd5dfb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["female    5725\n","male      5469\n","Name: gender, dtype: int64"]},"metadata":{},"execution_count":4}],"source":["df=pd.read_csv('user_gender_class/data/gender-classifier-DFE-791531.csv',encoding='latin1')\n","\n","df.drop(['_unit_id','_last_judgment_at','created','fav_number','profileimage','retweet_count','tweet_coord',\n","         '_trusted_judgments', 'tweet_count', 'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone', \n","         '_golden','_unit_state', 'gender_gold', 'link_color', 'name', 'profile_yn_gold', 'sidebar_color', \n","         'profile_yn', 'profile_yn:confidence','gender:confidence'], axis=1, inplace=True)\n","\n","df.isna().sum()\n","df.dropna(axis=0,inplace=True)\n","df['gender'].value_counts()\n","df['gender'] = df[(df['gender'] == 'female') | (df['gender'] == 'male')]\n","df['gender'].value_counts()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"IflS0bJhSbw1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662369184133,"user_tz":-60,"elapsed":6765,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"826d4ecc-343b-465e-a053-738f88249ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["0    5725\n","1    5469\n","Name: gender, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["now cleaning\n"]}],"source":["for gen in df['gender']:\n","  #print(gen)\n","  if gen=='male':\n","    df['gender'].replace({'male':'1'},inplace=True)\n","  elif gen=='female':\n","    df['gender'].replace({'female':'0'},inplace=True)\n","\n","\n","\n","df = df[df['gender'].notna()]\n","print(df['gender'].value_counts())\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","nltk.download('omw-1.4')\n","remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n","rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n","\n","lemma = WordNetLemmatizer()\n","stopword = nltk.corpus.stopwords.words('english')\n","\n","def remove_stopwords(text):\n","    text = [word for word in text if word not in stopword]\n","    return text\n","\n","def tokenization(text):\n","    text = re.split('\\W+', text)\n","    return text\n","\n","\n","print('now cleaning')\n","\n","p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\n","df['clean_description'] = df.description.map(remove_rt).map(rt).map(p.clean).str.lower().apply(lambda x: tokenization(x)).apply(lambda x: remove_stopwords(x))\n","df['clean_text'] = df.text.map(remove_rt).map(rt).map(p.clean).str.lower().apply(lambda x: tokenization(x)).apply(lambda x: remove_stopwords(x))\n","\n","df['clean_description'] = df.clean_description.apply(lambda lst: [lemma.lemmatize(word) for word in lst]).str.join(\" \")\n","df['clean_text'] = df.clean_text.apply(lambda lst: [lemma.lemmatize(word) for word in lst]).str.join(\" \")\n","\n","df['texty'] = df['clean_text'] = df.text.map(remove_rt).map(rt).map(p.clean).str.lower()\n","df['desc'] = df.description.map(remove_rt).map(rt).map(p.clean).str.lower()\n","\n","n = len(df)\n","df['sep'] = ['.\\n ' for i in range(n)]\n","\n","df['txt'] = df['desc'] + df['sep'] + df['texty']\n","\n","df['gender'] = (df['gender']).astype(int)  "]},{"cell_type":"code","source":["df.txt.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wt7JY3uT2VGM","executionInfo":{"status":"ok","timestamp":1662369184134,"user_tz":-60,"elapsed":9,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"b6b7f134-095e-4582-f73d-9293e8b89c14"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    i sing my own rhythm.\\n robbie e responds to c...\n","1    i m the author of novels filled with family dr...\n","2    louis whining and squealing and all.\\n i absol...\n","3    mobile guy ers shazam google kleiner perkins y...\n","4    ricky wilson the best frontman kaiser chiefs t...\n","Name: txt, dtype: object"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## ROBERTA XLM"],"metadata":{"id":"3T0hbb1DvxpK"}},{"cell_type":"markdown","metadata":{"id":"Gz0eVL0Ml2Hc"},"source":["### PIPS"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":35515,"status":"ok","timestamp":1662367257800,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"wXj-MR15tnye","outputId":"fe601458-9fbd-46ba-fafa-6d16047c60e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.22)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.24.66)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.1.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.6.0)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n","Collecting botocore<1.28.0,>=1.27.66\n","  Using cached botocore-1.27.66-py3-none-any.whl (9.1 MB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.66->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.66->boto3->pytorch-pretrained-bert) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2022.6.15)\n","Installing collected packages: urllib3, botocore\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.22\n","    Uninstalling urllib3-1.22:\n","      Successfully uninstalled urllib3-1.22\n","  Attempting uninstall: botocore\n","    Found existing installation: botocore 1.23.26\n","    Uninstalling botocore-1.23.26:\n","      Successfully uninstalled botocore-1.23.26\n","Successfully installed botocore-1.27.66 urllib3-1.25.11\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["botocore","urllib3"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.25.11)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: simpletransformers in /usr/local/lib/python3.7/dist-packages (0.63.7)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.1.97)\n","Requirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (4.21.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.21.6)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.4.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.23.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.2.4)\n","Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.13.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.7.3)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.8.0)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.12.1)\n","Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (4.64.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2022.6.2)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.12.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (0.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.6.0->simpletransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.6.0->simpletransformers) (3.0.9)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (2.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (5.4.8)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (3.1.27)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (57.4.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (1.15.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (1.9.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (3.17.3)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (1.0.9)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (7.1.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (1.25.11)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.70.13)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (3.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (3.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (2022.7.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.3.5.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.18.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (0.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.6.0->simpletransformers) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simpletransformers) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simpletransformers) (2.8.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->simpletransformers) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->simpletransformers) (3.1.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (7.1.2)\n","Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.5)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (12.5.1)\n","Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.8.0b1)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (5.1.1)\n","Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.0)\n","Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (2.13.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.10.2)\n","Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.0.1)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.4)\n","Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (2.1.9)\n","Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.20.0)\n","Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.5.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (2.11.3)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (4.3.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.12.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (5.9.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.18.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit->simpletransformers) (2.0.1)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.11.0->streamlit->simpletransformers) (0.9.1)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.6.1)\n","Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators>=0.2->streamlit->simpletransformers) (4.4.2)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.47.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (3.4.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.2.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.37.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting botocore==1.23.26\n","  Using cached botocore-1.23.26-py3-none-any.whl (8.5 MB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.23.26) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore==1.23.26) (1.25.11)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.23.26) (0.10.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.23.26) (1.15.0)\n","Installing collected packages: botocore\n","  Attempting uninstall: botocore\n","    Found existing installation: botocore 1.27.66\n","    Uninstalling botocore-1.27.66:\n","      Successfully uninstalled botocore-1.27.66\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","boto3 1.24.66 requires botocore<1.28.0,>=1.27.66, but you have botocore 1.23.26 which is incompatible.\u001b[0m\n","Successfully installed botocore-1.23.26\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["botocore"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting urllib3==1.22.0\n","  Using cached urllib3-1.22-py2.py3-none-any.whl (132 kB)\n","Installing collected packages: urllib3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.25.11\n","    Uninstalling urllib3-1.25.11:\n","      Successfully uninstalled urllib3-1.25.11\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","responses 0.18.0 requires urllib3>=1.25.10, but you have urllib3 1.22 which is incompatible.\n","botocore 1.23.26 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.22 which is incompatible.\n","boto3 1.24.66 requires botocore<1.28.0,>=1.27.66, but you have botocore 1.23.26 which is incompatible.\u001b[0m\n","Successfully installed urllib3-1.22\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: memory_profiler in /usr/local/lib/python3.7/dist-packages (0.60.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n"]}],"source":["!pip install transformers\n","!pip install wget\n","!pip install pytorch-pretrained-bert\n","!pip install urllib3\n","!pip install --upgrade simpletransformers\n","!pip install --upgrade botocore==1.23.26\n","!pip install --upgrade urllib3==1.22.0\n","!pip install memory_profiler"]},{"cell_type":"code","source":["# If there's a GPU available...\n","import torch\n","\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n","\n","import wget\n","import os\n","import os.path\n","import torch, gc, random, datasets\n","from transformers.file_utils import is_tf_available, is_torch_available\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from transformers import AutoConfig\n","%load_ext memory_profiler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VyM3oSO3wP21","executionInfo":{"status":"ok","timestamp":1662366540389,"user_tz":-60,"elapsed":5270,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"cba67c8e-277c-4248-881b-afa53db61cda"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"]}]},{"cell_type":"markdown","source":["### trainer func"],"metadata":{"id":"s4RNJRQcwzvD"}},{"cell_type":"code","source":["def Classification_with_Transformer(model_name: str, Data: pd.Series, Target:pd.Series, test_size: np.float64, max_length: int, num_labels: int, num_epochs: int):\n","\n","    # Make data\n","    X = Data\n","    y = Target\n","\n","\n","    # Split Data\n","    X_train, X_test, y_train, y_test = train_test_split(X.tolist(), y, test_size=test_size)\n","\n","    # Call the Tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    # Encode the text\n","    train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length)\n","    valid_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=max_length)\n","\n","\n","\n","    class MakeTorchData(torch.utils.data.Dataset):\n","          def __init__(self, encodings, labels):\n","              self.encodings = encodings\n","              self.labels = labels\n","\n","          def __getitem__(self, idx):\n","              item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n","              item[\"labels\"] = torch.tensor([self.labels[idx]])\n","              item[\"labels\"] = float(item[\"labels\"])\n","              return item\n","\n","          def __len__(self):\n","              return len(self.labels)\n","\n","    # convert our tokenized data into a torch Dataset\n","    train_dataset = MakeTorchData(train_encodings, y_train.ravel())\n","    valid_dataset = MakeTorchData(valid_encodings, y_test.ravel())\n","\n","\n","    # Call Model\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = num_labels).to(\"cuda\") # np.log(1000)\n","\n","    def compute_metrics(pred):\n","    logits, labels = eval_pred\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","\n","    def compute_metrics_for_regression(eval_pred):\n","          logits, labels = eval_pred\n","          # print(\"Logits:\", logits[0:5])\n","          # print(\"Labels:\", labels[0:5])\n","          # logits = inverse_sigmoid(logits)\n","          labels = labels.reshape(-1, 1)\n","          \n","          print(\"Logits:\", logits[0:5])\n","          print(\"Labels:\", labels[0:5])\n","          # print(\"Labels:\", labels)\n","\n","          mse = mean_squared_error(labels, logits)\n","          rmse = mean_squared_error(labels, logits, squared=False)\n","          mae = mean_absolute_error(labels, logits)\n","          r2 = r2_score(labels, logits)\n","          # smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n","          single_squared_errors = ((logits - labels).flatten()**2).tolist()\n","          accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n","          \n","          return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}\n","\n","    # Specifiy the arguments for the trainer  \n","    training_args = TrainingArguments(\n","        output_dir=f'user_gender_class{os.path.sep}results',          # output directory\n","        num_train_epochs=num_epochs,     # total number of training epochs\n","        per_device_train_batch_size = 32,   # batch size per device during training\n","        per_device_eval_batch_size=20,   # batch size for evaluation\n","        weight_decay=0.01,               # strength of weight decay\n","        learning_rate=2e-5,\n","        # logging_dir='./logs',            # directory for storing logs\n","        save_total_limit=10,\n","        load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","        metric_for_best_model = 'accuracy',    # select the base metrics\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","    ) \n","\n","    # Call the Trainer\n","    trainer = Trainer(\n","        model=model,                         # the instantiated Transformers model to be trained\n","        args=training_args,                  # training arguments, defined above\n","        train_dataset=train_dataset,         # training dataset\n","        eval_dataset=valid_dataset,          # evaluation dataset\n","        compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n","    )\n","\n","    # Train the model\n","    trainer.train()\n","    \n","    # Call the summary\n","    trainer.evaluate()\n","\n","\n","\n","    return trainer, model"],"metadata":{"id":"OAPRIwvjv14e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zyU7ghr-w3Bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.text_clean\n","\n","df['labels'] = df['gender']\n","y = df.labels\n","\n","%%time\n","%%memit\n","bert_trainer, bert_model = Classification_with_Transformer(model_name = 'roberta-base', \n","                                                                 Data = X, \n","                                                                 Target = y.astype(float), \n","                                                                 test_size = 0.2, \n","                                                                 max_length = 256, \n","                                                                 num_labels = 2, \n","                                                                 num_epochs = 3)"],"metadata":{"id":"tcSIxtaxv5m8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Logistic Regression"],"metadata":{"id":"feV7ZfDD8J87"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Split test and train data using 25% of the dataset for validation purposes\n","x_train, x_test, y_train, y_test = train_test_split(df['clean_text'], \n","                                                      df['gender'], test_size=0.25, shuffle=True, random_state=42)"],"metadata":{"id":"UjjNox0T8hpe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a Pipeline with the TfidfVectorizer and LogisticRegression model\n","LR_pipeline = Pipeline(steps = [('tf', TfidfVectorizer()), \n","                                ('lgrg', LogisticRegression())]) # initialize TfidfVectorizer and LogisticRegression\n","\n","\n","# Create Parameter Grid\n","pgrid_lgrg = {\n"," 'tf__max_features' : [1000, 2000, 3000],\n"," 'tf__ngram_range' : [(1,1),(1,2)],\n"," 'tf__use_idf' : [True, False],\n"," 'lgrg__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n"," 'lgrg__class_weight' : ['balanced', None]\n","}\n","\n","# Apply GridSearch to Pipeline to find the best parameters\n","gs_lgrg = GridSearchCV(LR_pipeline, pgrid_lgrg, cv=2, n_jobs=-1, verbose=2)\n","\n","gs_lgrg.fit(x_train, y_train) # Train LR model\n","\n","gs_lgrg.best_params_"],"metadata":{"id":"fUmfEs_l8Mar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Score of train set', gs_lgrg.score(x_train, y_train))\n","print('Score of test set',gs_lgrg.score(x_test, y_test))\n","\n","LR_pred = gs_lgrg.predict(x_test) # Predict on validation data\n","\n","data = {'true_y': y_test,\n","       'predicted_y': LR_pred}\n","df_pred = pd.DataFrame(data, columns=['true_y','predicted_y'])\n","confusion_matrix = pd.crosstab(df_pred['true_y'], df_pred['predicted_y'], rownames=['True'], colnames=['Predicted'])\n","\n","sns.heatmap(confusion_matrix, annot=True)\n","plt.show()\n","\n","print('Accuracy of LR model', accuracy_score(y_test, LR_pred))\n","\n","print(classification_report(y_test, LR_pred, target_names=target_names))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":498},"id":"ZP8zCiBY8TjB","executionInfo":{"status":"ok","timestamp":1662336213554,"user_tz":-60,"elapsed":751,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"8557c31c-8557-4456-8e54-672280540ded"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Score of train set 0.7372245384157237\n","Score of test set 0.5834226509467667\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Accuracy of LR model 0.5834226509467667\n","              precision    recall  f1-score   support\n","\n","      true_y       0.59      0.59      0.59      1430\n"," predicted_y       0.57      0.58      0.58      1369\n","\n","    accuracy                           0.58      2799\n","   macro avg       0.58      0.58      0.58      2799\n","weighted avg       0.58      0.58      0.58      2799\n","\n"]}]},{"cell_type":"markdown","source":["## ROBERTA SIMPLE\n"],"metadata":{"id":"GWgg5M5b3f7D"}},{"cell_type":"code","source":["!pip install --upgrade transformers\n","!pip install simpletransformers"],"metadata":{"id":"I3kvpjY_-Bcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFNXSyisW2rT","executionInfo":{"status":"ok","timestamp":1662326250609,"user_tz":-60,"elapsed":548,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"d2af7977-98f8-4a58-b0c9-a5873357e43a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from simpletransformers.classification import ClassificationModel, ClassificationArgs"],"metadata":{"id":"gONSGdhPW3VO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['gender'], random_state=42)\n","\n","model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir=True, manual_seed=42, silent=True)\n","\n","model = ClassificationModel(model_type='roberta', model_name='roberta-base', use_cuda=True, num_labels=2, \n","                            args=model_args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288,"referenced_widgets":["e4a5ced34f5c46f58ca165095ad40cd6","184b522287ff45238635f4a1d9eb757e","025b7940acb4423cb38c3c5b68d27f63","6eabc0d5bf7b47b7a089d16bd9759bf4","e50b988e4ae643428368d032087e5155","a3c48789abdf448ca103cae57581a197","f57ec88587034553aa453db4bf607079","632855bfa1ec45c588318a8c0b462b65","554da9014d164eaebc61561b38c950e1","4260a6b4efa34546865df129dd310ad9","a4deefd3771e4cd597a8f3d58824b2b6","0bfbc004c8534ce58f9554d8280b56d6","653ffa25927a4a80b0dc919f6d712f26","c2aac61a665c4ef890926aec2ea1b4e0","78bae6d4408c4dceaebda81148a48f06","582beae7e972482d988533501efcc700","9299f27d983e4901abacf9abe0171768","346c2dcc06f7408d8e120a39cb41d167","1f4013d5f5b44f06800567b5abad61ff","09abef4e77314c96a562645cd7c67679","983c62088d67468fb1edca16a879b74d","d9799c2428f9473abcd53d66eaed64ae","7e46324d2113462595b135beede9edd6","9694015f88964b29a09708c3bd297ab4","d2a38192ac224b2f919e2c041c5c97f8","cb483e6281894b1288783bf8eb44f51d","f0f831d180e6415994db3a421bd8a8e6","a007188671664e19b9244ef62772e468","8e687629b2a14f039ae2665f095ef34f","e62c026c69044cc988a3d31df7f35cca","1242f936a54a4c048280b7cd1bd753ff","d7242668ec2d4f1f97cbcc308458d83e","984edaf6a8be4505a8362292692ec474","91ec98082d02417ea5310671ee9ecc44","53dcbaf6e89d4e0aa996a8e40e3828d4","044cdde97df34fb780c742730d0d29f9","42b857cdf32d4669ad8f180068a3e8e8","f37cdef7d4ac4754af78a3e0739cac19","a08ec4d2992143f4bef7f83bbe0682ec","fad162df46df4feba43cf1c047d05829","16592399f9cc472694a6480464c480a7","c9561c984c364872bb8fa7d9d381be6f","ffc9ad27532148819e4f866e036cbc42","841a7425158e428e8f63dfeacf7749f2","71aa44e2a41a4f90843f82d3fbc2132b","c9fa122edfd14287aee598bb3fcd0ba0","3eb4c448cff34cc4aa344fe460d3813a","d43b184f1e5a4a9cbbe22f3f6261b110","3022b3e0872b43ecb900d69acd0b000a","e4f397f6665b45afa3dfd1960ec834f7","449b8ff237f0488abcee530cd814df78","52e770a1fa454254ac0c89c4e4dd31af","dfc177c4c8cc46b887f50a325aabe850","e80c574c50e94a17af91b7b9a9d6b9e4","297507b6d38e45e29e96b70ad4a365ba"]},"id":"O0mbQwUxW_SG","executionInfo":{"status":"ok","timestamp":1662326292938,"user_tz":-60,"elapsed":21699,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"b4ecaafc-c786-4070-9458-c354f7725f81"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4a5ced34f5c46f58ca165095ad40cd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bfbc004c8534ce58f9554d8280b56d6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e46324d2113462595b135beede9edd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91ec98082d02417ea5310671ee9ecc44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71aa44e2a41a4f90843f82d3fbc2132b"}},"metadata":{}}]},{"cell_type":"code","source":["model.train_model(train_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtHjG41dXWLu","outputId":"b530ea1b-0a03-4c0d-e92d-69b331c756fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/simpletransformers/classification/classification_model.py:602: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n","  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"]}]},{"cell_type":"code","source":["result, model_outputs, wrong_predictions = model.eval_model(valid_df)"],"metadata":{"id":"C_iR2QiqXfy6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"ta9e_cEJWu1t"}},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"Rr4eOUsXYcFg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662369189691,"user_tz":-60,"elapsed":5563,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"91496f8e-5dc5-45d0-86ea-543f1229c02e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from wordcloud import WordCloud\n","\n","import pandas as pd\n","import random, time\n","from babel.dates import format_date, format_datetime, format_time\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","\n","import torch\n","from torch import Tensor\n","from torch import nn, optim\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn.functional as F\n","\n","import transformers, os\n","from transformers import BertModel, AutoModel, AdamW, get_linear_schedule_with_warmup, BertTokenizer, BertForSequenceClassification\n","from transformers import RobertaModel, AutoModel, AdamW, get_linear_schedule_with_warmup, RobertaTokenizer, RobertaForSequenceClassification\n","from transformers import AutoTokenizer, RobertaConfig"],"metadata":{"id":"ZCs0qIAlY2H0","executionInfo":{"status":"ok","timestamp":1662369190218,"user_tz":-60,"elapsed":535,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### ROBERTA MODEL"],"metadata":{"id":"ZFRR-ywU0Q5t"}},{"cell_type":"markdown","source":["#### PRETRAINED ROBERTA"],"metadata":{"id":"sT9IeHIP30gm"}},{"cell_type":"code","source":["df['gender'] = (df['gender']).astype(int)\n","\n","\n","# Split test and train data using 25% of the dataset for validation purposes\n","x_train, x_test, y_train, y_test = train_test_split(df['clean_text'], \n","                                                      df['gender'], test_size=0.2, shuffle=True, random_state=42)\n","\n","# Obtain a 10% test set from train set\n","X_train_Transformer, X_val_Transformer, y_train_Transformer, y_val_Transformer = train_test_split(\n","                                                    x_train, y_train, test_size=0.20, random_state=42)\n","\n","model_name = 'roberta-base'\n","SEQ_LEN = 256\n","batch_size = 16\n","epochs = 5\n","learning_rate = 2e-5 # Controls how large a step is taken when updating model weights during training.\n","steps_per_epoch = int(len(df)/16)\n","num_workers = 3\n","\n","def get_split(text1):\n","    '''Get split of the text with 200 char lenght'''\n","    l_total = []\n","    l_parcial = []\n","    if len(text1.split())//150 >0:\n","        n = len(text1.split())//150\n","    else: \n","        n = 1\n","    for w in range(n):\n","        if w == 0:\n","            l_parcial = text1.split()[:200]\n","            l_total.append(\" \".join(l_parcial))\n","        else:\n","            l_parcial = text1.split()[w*150:w*150 + 200]\n","            l_total.append(\" \".join(l_parcial))\n","    return str(l_total)\n","\n","# Splits train and validation sets to be feed to the transformer which only accepts 512 tokens maximum\n","split_train_text = [get_split(t) for t in X_train_Transformer]\n","split_valid_text = [get_split(t) for t in X_val_Transformer]\n","split_test_text = [get_split(t) for t in x_test]\n","\n","\n","# Load the RoBERTa tokenizer and tokenize the data\n","print('Loading ROBERTA tokenizer...')\n","tokenizer = RobertaTokenizer.from_pretrained(model_name, do_lower_case=True)\n","\n","trencoding = tokenizer.batch_encode_plus(\n","  list(split_train_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","valencoding = tokenizer.batch_encode_plus(\n","  list(split_valid_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","\n","testencoding = tokenizer.batch_encode_plus(\n","  list(split_test_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","#compute the class weights\n","class_wts = compute_class_weight(class_weight='balanced', classes = np.unique(df['gender'].values.tolist()), \n","                                 y = df['gender'])\n","\n","#print(class_wts)\n","\n","# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","cross_entropy  = nn.CrossEntropyLoss(weight=weights)\n","\n","def loadData(prep_df, batch_size, num_workers, sampler):\n","    \n","    return  DataLoader(\n","            prep_df,\n","            batch_size=batch_size,\n","            num_workers=num_workers,\n","            sampler=sampler,\n","            pin_memory=True\n","        )\n","\n","## convert lists to tensors\n","train_seq = torch.tensor(trencoding['input_ids'])\n","train_mask = torch.tensor(trencoding['attention_mask'])\n","train_token_ids = torch.tensor(trencoding['token_type_ids'])\n","train_y = torch.tensor(y_train_Transformer.tolist())\n","\n","val_seq = torch.tensor(valencoding['input_ids'])\n","val_mask = torch.tensor(valencoding['attention_mask'])\n","val_token_ids = torch.tensor(valencoding['token_type_ids'])\n","val_y = torch.tensor(y_val_Transformer.tolist())\n","\n","test_seq = torch.tensor(testencoding['input_ids'])\n","test_mask = torch.tensor(testencoding['attention_mask'])\n","test_token_ids = torch.tensor(testencoding['token_type_ids'])\n","test_y = torch.tensor(y_test.tolist())\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_token_ids, train_y)\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","# Train Data Loader\n","traindata = loadData(train_data, batch_size, num_workers, train_sampler)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_token_ids, val_y)\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","# Val Data Loader\n","valdata = loadData(val_data, batch_size, num_workers, val_sampler)\n","\n","# wrap tensors\n","test_data = TensorDataset(test_seq, test_mask, test_token_ids, test_y)\n","# sampler for sampling the data during training\n","test_sampler = SequentialSampler(test_data)\n","# Val Data Loader\n","testdata = loadData(test_data, batch_size, num_workers, test_sampler)\n","\n","\n","print('Number of data in the train set', len(traindata))\n","print('Number of data in the validation set', len(valdata))\n","print('Number of data in the test set', len(testdata))\n","\n","\n","class_names = np.unique(df['gender'])\n","print('Downloading the ROBERTA custom model...')\n","config = RobertaConfig.from_pretrained('roberta-base')\n","\n","\n","model.to(device) # Model to GPU.\n","\n","#optimizer parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","optimizer_parameters = [{'params': [p for n, p in param_optimizer \n","                                    if not any(nd in n for nd in no_decay)],'weight_decay':0.001},\n","                        {'params': [p for n, p in param_optimizer \n","                                    if any(nd in n for nd in no_decay)],'weight_decay':0.0}]\n","\n","print('Preparing the optimizer...')\n","#optimizer \n","optimizer = AdamW(optimizer_parameters, lr=learning_rate)\n","steps = steps_per_epoch\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = steps\n",")\n"],"metadata":{"id":"ZPrUuvYH34Fy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### BAD ROBERTA"],"metadata":{"id":"UhuGkdqP3vEG"}},{"cell_type":"code","source":["df['gender'] = (df['gender']).astype(int)\n","\n","\n","# Split test and train data using 25% of the dataset for validation purposes\n","x_train, x_test, y_train, y_test = train_test_split(df['clean_text'], \n","                                                      df['gender'], test_size=0.2, shuffle=True, random_state=42)\n","\n","# Obtain a 10% test set from train set\n","X_train_Transformer, X_val_Transformer, y_train_Transformer, y_val_Transformer = train_test_split(\n","                                                    x_train, y_train, test_size=0.20, random_state=42)\n","\n","model_name = 'xlm-roberta-base'\n","SEQ_LEN = 256\n","batch_size = 16\n","epochs = 5\n","learning_rate = 2e-5 # Controls how large a step is taken when updating model weights during training.\n","steps_per_epoch = int(len(df)/16)\n","num_workers = 3\n","\n","def get_split(text1):\n","    '''Get split of the text with 200 char lenght'''\n","    l_total = []\n","    l_parcial = []\n","    if len(text1.split())//150 >0:\n","        n = len(text1.split())//150\n","    else: \n","        n = 1\n","    for w in range(n):\n","        if w == 0:\n","            l_parcial = text1.split()[:200]\n","            l_total.append(\" \".join(l_parcial))\n","        else:\n","            l_parcial = text1.split()[w*150:w*150 + 200]\n","            l_total.append(\" \".join(l_parcial))\n","    return str(l_total)\n","\n","# Splits train and validation sets to be feed to the transformer which only accepts 512 tokens maximum\n","split_train_text = [get_split(t) for t in X_train_Transformer]\n","split_valid_text = [get_split(t) for t in X_val_Transformer]\n","split_test_text = [get_split(t) for t in x_test]\n","\n","\n","# Load the RoBERTa tokenizer and tokenize the data\n","print('Loading ROBERTA tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n","\n","trencoding = tokenizer.batch_encode_plus(\n","  list(split_train_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","valencoding = tokenizer.batch_encode_plus(\n","  list(split_valid_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","\n","testencoding = tokenizer.batch_encode_plus(\n","  list(split_test_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","#compute the class weights\n","class_wts = compute_class_weight(class_weight='balanced', classes = np.unique(df['gender'].values.tolist()), \n","                                 y = df['gender'])\n","\n","#print(class_wts)\n","\n","# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","cross_entropy  = nn.CrossEntropyLoss(weight=weights)\n","\n","def loadData(prep_df, batch_size, num_workers, sampler):\n","    \n","    return  DataLoader(\n","            prep_df,\n","            batch_size=batch_size,\n","            num_workers=num_workers,\n","            sampler=sampler,\n","            pin_memory=True\n","        )\n","\n","## convert lists to tensors\n","train_seq = torch.tensor(trencoding['input_ids'])\n","train_mask = torch.tensor(trencoding['attention_mask'])\n","train_token_ids = torch.tensor(trencoding['token_type_ids'])\n","train_y = torch.tensor(y_train_Transformer.tolist())\n","\n","val_seq = torch.tensor(valencoding['input_ids'])\n","val_mask = torch.tensor(valencoding['attention_mask'])\n","val_token_ids = torch.tensor(valencoding['token_type_ids'])\n","val_y = torch.tensor(y_val_Transformer.tolist())\n","\n","test_seq = torch.tensor(testencoding['input_ids'])\n","test_mask = torch.tensor(testencoding['attention_mask'])\n","test_token_ids = torch.tensor(testencoding['token_type_ids'])\n","test_y = torch.tensor(y_test.tolist())\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_token_ids, train_y)\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","# Train Data Loader\n","traindata = loadData(train_data, batch_size, num_workers, train_sampler)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_token_ids, val_y)\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","# Val Data Loader\n","valdata = loadData(val_data, batch_size, num_workers, val_sampler)\n","\n","# wrap tensors\n","test_data = TensorDataset(test_seq, test_mask, test_token_ids, test_y)\n","# sampler for sampling the data during training\n","test_sampler = SequentialSampler(test_data)\n","# Val Data Loader\n","testdata = loadData(test_data, batch_size, num_workers, test_sampler)\n","\n","\n","print('Number of data in the train set', len(traindata))\n","print('Number of data in the validation set', len(valdata))\n","print('Number of data in the test set', len(testdata))\n","\n","class Roberta_Arch(nn.Module):\n","    \n","    def __init__(self, n_classes, freeze_bert=False):\n","        \n","        super(Roberta_Arch,self).__init__()\n","        # Instantiating BERT model object\n","        self.bert = RobertaModel.from_pretrained(model_name, return_dict=False)\n","        \n","        # Freeze bert layers\n","        if freeze_bert:\n","            for p in self.bert.parameters():\n","                p.requires_grad = False\n","                \n","        self.bert_drop_1 = nn.Dropout(0.3)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size) # (768, 64)\n","        self.bn = nn.BatchNorm1d(768) # (768)\n","        self.bert_drop_2 = nn.Dropout(0.25)\n","        self.out = nn.Linear(self.bert.config.hidden_size, n_classes) # (768,2)\n","\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        _, output = self.bert(\n","            input_ids = input_ids,\n","            attention_mask = attention_mask,\n","            token_type_ids = token_type_ids\n","        )\n","        output = self.bert_drop_1(output)\n","        output = self.fc(output)\n","        output = self.bn(output)\n","        output = self.bert_drop_2(output)\n","        output = self.out(output)        \n","        return output\n","\n","class_names = np.unique(df['gender'])\n","print('Downloading the ROBERTA custom model...')\n","model = Roberta_Arch(len(class_names))\n","model.to(device) # Model to GPU.\n","\n","#optimizer parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","optimizer_parameters = [{'params': [p for n, p in param_optimizer \n","                                    if not any(nd in n for nd in no_decay)],'weight_decay':0.001},\n","                        {'params': [p for n, p in param_optimizer \n","                                    if any(nd in n for nd in no_decay)],'weight_decay':0.0}]\n","\n","print('Preparing the optimizer...')\n","#optimizer \n","optimizer = AdamW(optimizer_parameters, lr=learning_rate)\n","steps = steps_per_epoch\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = steps\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iE7ObWuA0VNJ","executionInfo":{"status":"ok","timestamp":1662334287613,"user_tz":-60,"elapsed":9626,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"2770a8e4-9a9f-4e33-f455-67db44f38218"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading ROBERTA tokenizer...\n","Number of data in the train set 448\n","Number of data in the validation set 112\n","Number of data in the test set 140\n","Downloading the ROBERTA custom model...\n"]},{"output_type":"stream","name":"stderr","text":["You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Preparing the optimizer...\n"]}]},{"cell_type":"markdown","source":["### BERT MODEL"],"metadata":{"id":"yYW8hTKH0ONs"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from wordcloud import WordCloud\n","\n","import pandas as pd\n","import random, time\n","from babel.dates import format_date, format_datetime, format_time\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","\n","import torch\n","from torch import Tensor\n","from torch import nn, optim\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn.functional as F\n","\n","import transformers, os\n","from transformers import BertModel, AutoModel, AdamW, get_linear_schedule_with_warmup, BertTokenizer, BertForSequenceClassification\n","from transformers import RobertaModel, AutoModel, AdamW, get_linear_schedule_with_warmup, RobertaTokenizer, RobertaForSequenceClassification\n","from transformers import AutoTokenizer, RobertaConfig"],"metadata":{"id":"Jtx8ji5M3QD-","executionInfo":{"status":"ok","timestamp":1662369190218,"user_tz":-60,"elapsed":7,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df['gender'] = (df['gender']).astype(int)\n","\n","\n","# Split test and train data using 25% of the dataset for validation purposes\n","x_train, x_test, y_train, y_test = train_test_split(df['txt'], \n","                                                      df['gender'], test_size=0.2, shuffle=True, random_state=42)\n","\n","# Obtain a 10% test set from train set\n","X_train_Transformer, X_val_Transformer, y_train_Transformer, y_val_Transformer = train_test_split(\n","                                                    x_train, y_train, test_size=0.20, random_state=42)\n","\n","model_name = 'bert-base-uncased'\n","SEQ_LEN = 512\n","batch_size = 16\n","epochs = 2\n","learning_rate = 1e-5 # Controls how large a step is taken when updating model weights during training.\n","steps_per_epoch = int(len(df)/16)\n","num_workers = 3\n","\n","def get_split(text1):\n","    '''Get split of the text with 200 char lenght'''\n","    l_total = []\n","    l_parcial = []\n","    if len(text1.split())//150 >0:\n","        n = len(text1.split())//150\n","    else: \n","        n = 1\n","    for w in range(n):\n","        if w == 0:\n","            l_parcial = text1.split()[:200]\n","            l_total.append(\" \".join(l_parcial))\n","        else:\n","            l_parcial = text1.split()[w*150:w*150 + 200]\n","            l_total.append(\" \".join(l_parcial))\n","    return str(l_total)\n","\n","# Splits train and validation sets to be feed to the transformer which only accepts 512 tokens maximum\n","split_train_text = [get_split(t) for t in X_train_Transformer]\n","split_valid_text = [get_split(t) for t in X_val_Transformer]\n","split_test_text = [get_split(t) for t in x_test]\n","\n","\n","# Load the RoBERTa tokenizer and tokenize the data\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n","\n","trencoding = tokenizer.batch_encode_plus(\n","  list(split_train_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","valencoding = tokenizer.batch_encode_plus(\n","  list(split_valid_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","\n","testencoding = tokenizer.batch_encode_plus(\n","  list(split_test_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","#compute the class weights\n","class_wts = compute_class_weight(class_weight='balanced', classes = np.unique(df['gender'].values.tolist()), \n","                                 y = df['gender'])\n","\n","#print(class_wts)\n","\n","# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","cross_entropy  = nn.CrossEntropyLoss(weight=weights)\n","\n","def loadData(prep_df, batch_size, num_workers, sampler):\n","    \n","    return  DataLoader(\n","            prep_df,\n","            batch_size=batch_size,\n","            num_workers=num_workers,\n","            sampler=sampler,\n","            pin_memory=True\n","        )\n","\n","## convert lists to tensors\n","train_seq = torch.tensor(trencoding['input_ids'])\n","train_mask = torch.tensor(trencoding['attention_mask'])\n","train_token_ids = torch.tensor(trencoding['token_type_ids'])\n","train_y = torch.tensor(y_train_Transformer.tolist())\n","\n","val_seq = torch.tensor(valencoding['input_ids'])\n","val_mask = torch.tensor(valencoding['attention_mask'])\n","val_token_ids = torch.tensor(valencoding['token_type_ids'])\n","val_y = torch.tensor(y_val_Transformer.tolist())\n","\n","test_seq = torch.tensor(testencoding['input_ids'])\n","test_mask = torch.tensor(testencoding['attention_mask'])\n","test_token_ids = torch.tensor(testencoding['token_type_ids'])\n","test_y = torch.tensor(y_test.tolist())\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_token_ids, train_y)\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","# Train Data Loader\n","traindata = loadData(train_data, batch_size, num_workers, train_sampler)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_token_ids, val_y)\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","# Val Data Loader\n","valdata = loadData(val_data, batch_size, num_workers, val_sampler)\n","\n","# wrap tensors\n","test_data = TensorDataset(test_seq, test_mask, test_token_ids, test_y)\n","# sampler for sampling the data during training\n","test_sampler = SequentialSampler(test_data)\n","# Val Data Loader\n","testdata = loadData(test_data, batch_size, num_workers, test_sampler)\n","\n","\n","print('Number of data in the train set', len(traindata))\n","print('Number of data in the validation set', len(valdata))\n","print('Number of data in the test set', len(testdata))\n","\n","class BERT_Arch(nn.Module):\n","    \n","    def __init__(self, n_classes, freeze_bert=False):\n","        \n","        super(BERT_Arch,self).__init__()\n","        # Instantiating BERT model object\n","        self.bert = BertModel.from_pretrained(model_name, return_dict=False)\n","        \n","        # Freeze bert layers\n","        if freeze_bert:\n","            for p in self.bert.parameters():\n","                p.requires_grad = False\n","                \n","        self.bert_drop_1 = nn.Dropout(0.3)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size) # (768, 64)\n","        self.bn = nn.BatchNorm1d(768) # (768)\n","        self.bert_drop_2 = nn.Dropout(0.25)\n","        self.out = nn.Linear(self.bert.config.hidden_size, 2) # (768,2)\n","\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        _, output = self.bert(\n","            input_ids = input_ids,\n","            attention_mask = attention_mask,\n","            token_type_ids = token_type_ids\n","        )\n","        output = self.bert_drop_1(output)\n","        output = self.fc(output)\n","        output = self.bn(output)\n","        output = self.bert_drop_2(output)\n","        output = self.out(output)        \n","        return output\n","\n","class_names = np.unique(df['gender'])\n","print('Downloading the BERT custom model...')\n","model = BERT_Arch(len(class_names))\n","model.to(device) # Model to GPU.\n","\n","#optimizer parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","optimizer_parameters = [{'params': [p for n, p in param_optimizer \n","                                    if not any(nd in n for nd in no_decay)],'weight_decay':0.001},\n","                        {'params': [p for n, p in param_optimizer \n","                                    if any(nd in n for nd in no_decay)],'weight_decay':0.0}]\n","\n","print('Preparing the optimizer...')\n","#optimizer \n","optimizer = AdamW(optimizer_parameters, lr=learning_rate)\n","steps = steps_per_epoch\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = steps\n",")\n"],"metadata":{"id":"R2Ap835KYd2g","colab":{"base_uri":"https://localhost:8080/","height":368,"referenced_widgets":["f738e0978cfa4df38868f3253d028ec4","ec6f6dbdd02b4aa19a846c2f85e83c99","7b4c9a3057714b1da86649225e7800ac","886e550a6e084c829f2e4bd4180a8ab0","06c909dc0eec416ca1b7b0e1f23752ae","42bc2548fd004db798e28a5b4dd0c401","d125291176494d5a930b6ba770aafa92","9d2f61d0c12b47e89336fc0a35e68f64","f4c1fac6b1d34f829afa1d410775c4db","cd2b72c8e02244a8a7f1bcb611ad9369","e7008b66a35e4d458b2ba98e66dbb820","44dc91d1aae64ff196a68035ed4efe08","a4c3fa965e754c63861640910e5a2e09","6c50cdc3b9d1453a971fac3a83442fee","3b5e2bf419fe4a208943974ed2519b46","d561bf6ac4df4c72be615d6a2569b34e","f8685865e1d84467b41e3eb06c5c34d5","62b2a64630e34a9594e27a8829618306","704d7bcd4fbc469282abf049bdd43b76","9b72ad6cc0654aaf9b00a07a18de1603","58956c31f52747c0804a4c232ede13ae","bc49c6c631ad4b708f997eedb5c188df","6699e20abb6740159bb75d11108cc6c4","a01801e483c54b3cbaba43101e64fccd","d60fcad9e6a544ff9b52e3b150553459","90fc28ca0153425f8e9a33132396c0c1","15110d0934994c22bf0626f53063e954","69bb351dfa334d8792c69dfd832fa8c4","04d2c20f79444fc58b829f7359c5e471","87cf0752ddb54e459e3f3cd15afb1c98","b2e14c1001fe4d27a030800e5f307843","0c81ae1b980d4d1c9bdbbcc0edb07bad","1534f5e6409a43ef94ad7f5552d48f51","ef4328eb0d36448e82e3de8f343e2184","ecbf48b8a3f844efaf20f920e7c836ca","fce6814cb780414ba4da6facc244cd2b","67b33a1433b045088ea9478c87a38997","31abb09ba88e400587a393bbaef69a4b","390c2668f02f45549a2a57b45bf48daa","e56ea56d8b3140b28b8430d3375850a1","19588b721b734d1e9718ea4135cd8bbf","331c526ec3eb484ab7f4d8df13bc3668","a1a702a7f6be48da82265befcef83f7c","8c7d588e80ae4ad58a4b2a53caaccd55"]},"executionInfo":{"status":"ok","timestamp":1662369221897,"user_tz":-60,"elapsed":31685,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"635d292e-9f64-44fe-bde8-e7aed479e89b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f738e0978cfa4df38868f3253d028ec4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44dc91d1aae64ff196a68035ed4efe08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6699e20abb6740159bb75d11108cc6c4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of data in the train set 448\n","Number of data in the validation set 112\n","Number of data in the test set 140\n","Downloading the BERT custom model...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef4328eb0d36448e82e3de8f343e2184"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Preparing the optimizer...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","source":["### TRAINING AND EVAL FUNCS"],"metadata":{"id":"rXGH7qfsas67"}},{"cell_type":"code","source":["# function to train the bert model\n","def trainMODEL():\n","  \n","    print('Training...')\n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","\n","    # empty list to save model predictions\n","    total_preds=[]\n","\n","    # iterate over batches\n","    for step, batch in enumerate(traindata):\n","    \n","        # progress update after every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(traindata)))\n","\n","        if torch.cuda.is_available():\n","            # push the batch to gpu\n","            batch = [r.to(device) for r in batch]\n","\n","        sent_id, mask, token_type_ids, labels = batch\n","        # clear previously calculated gradients \n","        model.zero_grad()        \n","        # get model predictions for the current batch\n","        preds = model(sent_id, mask, token_type_ids)\n","        # compute the loss between actual and predicted values\n","        loss = cross_entropy(preds, labels)\n","        # add on to the total loss\n","        total_loss = total_loss + loss.item()\n","        # backward pass to calculate the gradients\n","        loss.backward()\n","        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        # update parameters\n","        optimizer.step()\n","        # model predictions are stored on GPU. So, push it to CPU\n","        preds=preds.detach().cpu().numpy()\n","        # append the model predictions\n","        total_preds.append(preds)\n","        \n","        torch.cuda.empty_cache()\n","\n","    # compute the training loss of the epoch\n","    avg_loss = total_loss / len(traindata)\n","\n","    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    #returns the loss and predictions\n","    return avg_loss, total_preds\n","\n","# function for evaluating the model\n","def evaluate():\n","  \n","    print(\"\\nEvaluating...\")\n","    t0 = time.time()\n","    \n","    model.eval() # deactivate dropout layers\n","    total_loss, total_accuracy = 0, 0\n","    \n","    # empty list to save the model predictions\n","    total_preds = []\n","\n","    # iterate over batches\n","    for step, batch in enumerate(valdata):\n","        # Progress update every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(valdata)))\n","\n","        if torch.cuda.is_available():\n","            # push the batch to gpu\n","            batch = [t.to(device) for t in batch]\n","\n","        sent_id, mask, token_type_ids, labels = batch\n","\n","        # deactivate autograd\n","        with torch.no_grad(): # Dont store any previous computations, thus freeing GPU space\n","\n","            # model predictions\n","            preds = model(sent_id, mask, token_type_ids)\n","            # compute the validation loss between actual and predicted values\n","            loss = cross_entropy(preds, labels)\n","            total_loss = total_loss + loss.item()\n","            preds = preds.detach().cpu().numpy()\n","            total_preds.append(preds)\n","\n","        torch.cuda.empty_cache()\n","    # compute the validation loss of the epoch\n","    avg_loss = total_loss / len(valdata) \n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    return avg_loss, total_preds"],"metadata":{"id":"yYVrmY1Caufd","executionInfo":{"status":"ok","timestamp":1662369221898,"user_tz":-60,"elapsed":9,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# Empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","# for each epoch perform training and evaluation\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = trainMODEL()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    print('Evaluation done for epoch {}'.format(epoch + 1))\n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        print('Saving model...')\n","        torch.save(model.state_dict(), 'bert_weights.pt') # Save model weight's (you can also save it in .bin format)\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"metadata":{"id":"x-P9e0rNazSZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662369416788,"user_tz":-60,"elapsed":194898,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"c44fb93b-4ab2-49c5-a098-7a0642fa154f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1 / 2\n","Training...\n","  Batch    50  of    448.\n","  Batch   100  of    448.\n","  Batch   150  of    448.\n","  Batch   200  of    448.\n","  Batch   250  of    448.\n","  Batch   300  of    448.\n","  Batch   350  of    448.\n","  Batch   400  of    448.\n","\n","Evaluating...\n","  Batch    50  of    112.\n","  Batch   100  of    112.\n","Evaluation done for epoch 1\n","Saving model...\n","\n","Training Loss: 0.679\n","Validation Loss: 0.573\n","\n"," Epoch 2 / 2\n","Training...\n","  Batch    50  of    448.\n","  Batch   100  of    448.\n","  Batch   150  of    448.\n","  Batch   200  of    448.\n","  Batch   250  of    448.\n","  Batch   300  of    448.\n","  Batch   350  of    448.\n","  Batch   400  of    448.\n","\n","Evaluating...\n","  Batch    50  of    112.\n","  Batch   100  of    112.\n","Evaluation done for epoch 2\n","\n","Training Loss: 0.576\n","Validation Loss: 0.577\n"]}]},{"cell_type":"code","source":["print('\\nTest Set...')\n","\n","test_preds = []\n","\n","print('Total batches:', len(testdata))\n","\n","for fold_index in range(0, 3):\n","    \n","    print('\\nFold Model', fold_index)\n","    \n","    # Load the fold model\n","    path_model = 'bert_weights.pt'\n","    model.load_state_dict(torch.load(path_model))\n","\n","    # Send the model to the GPU\n","    model.to(device)\n","\n","    stacked_val_labels = []\n","    \n","    # Put the model in evaluation mode.\n","    model.eval()\n","\n","    # Turn off the gradient calculations.\n","    # This tells the model not to compute or store gradients.\n","    # This step saves memory and speeds up validation.\n","    torch.set_grad_enabled(False)\n","\n","\n","    # Reset the total loss for this epoch.\n","    total_val_loss = 0\n","\n","    for j, test_batch in enumerate(testdata):\n","\n","        inference_status = 'Batch ' + str(j + 1)\n","\n","        print(inference_status, end='\\r')\n","\n","        b_input_ids = test_batch[0].to(device)\n","        b_input_mask = test_batch[1].to(device)\n","        b_token_type_ids = test_batch[2].to(device)\n","        b_test_y = test_batch[3].to(device)\n","\n","\n","        outputs = model(b_input_ids, \n","                        attention_mask=b_input_mask,\n","                        token_type_ids=b_token_type_ids)\n","\n","        # Get the preds\n","        preds = outputs[0]\n","\n","        # Move preds to the CPU\n","        val_preds = preds.detach().cpu().numpy()\n","        \n","        #true_labels.append(b_test_y.to('cpu').numpy().flatten())\n","        \n","        # Stack the predictions.\n","        if j == 0:  # first batch\n","            stacked_val_preds = val_preds\n","            \n","        else:\n","            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n","            \n","    test_preds.append(stacked_val_preds)\n","    \n","            \n","print('\\nPrediction complete.')"],"metadata":{"id":"pOGH5-EYa-8w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662369439569,"user_tz":-60,"elapsed":22816,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"18c39ce1-f076-4eaf-b201-82b5ad6357a6"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test Set...\n","Total batches: 140\n","\n","Fold Model 0\n","\n","Fold Model 1\n","Batch 140\n","Fold Model 2\n","Batch 140\n","Prediction complete.\n"]}]},{"cell_type":"code","source":["# Sum the predictions of all fold models\n","for i, item in enumerate(test_preds):\n","    if i == 0:\n","        preds = item\n","    else:\n","        # Sum the matrices\n","        preds = item + preds\n","\n","# Average the predictions\n","avg_preds = preds/(len(test_preds))\n","\n","#print(preds)\n","#print()\n","#print(avg_preds)\n","\n","# Take the argmax. \n","# This returns the column index of the max value in each row.\n","test_predictions = np.argmax(avg_preds, axis=1)\n","\n","true_y = []\n","for j, test_batch in enumerate(testdata):\n","    true_y.append(int(test_batch[3][0].numpy().flatten()))\n","print(true_y)\n","\n","# Accuracy and classification report \n","target_names = ['true_y', 'predicted_y']\n","\n","data = {'true_y': true_y,\n","       'predicted_y': test_predictions}\n","\n","df_pred_BERT = pd.DataFrame(data, columns=['true_y','predicted_y'])\n","\n","confusion_matrix = pd.crosstab(df_pred_BERT['true_y'], df_pred_BERT['predicted_y'], rownames=['True'], colnames=['Predicted'])\n","\n","sns.heatmap(confusion_matrix, annot=True)\n","plt.show()\n","\n","print('----')\n","print('Accuracy of BERT model', accuracy_score(true_y, test_predictions))\n","print('----')\n","\n","print(classification_report(true_y, test_predictions, target_names=target_names))"],"metadata":{"id":"1Z7RCNb3bFcQ","colab":{"base_uri":"https://localhost:8080/","height":539},"executionInfo":{"status":"ok","timestamp":1662369440608,"user_tz":-60,"elapsed":1054,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"90cd8b81-7c05-484c-b225-2b79f77f46ba"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["----\n","Accuracy of BERT model 0.6571428571428571\n","----\n","              precision    recall  f1-score   support\n","\n","      true_y       0.62      0.75      0.68        68\n"," predicted_y       0.71      0.57      0.63        72\n","\n","    accuracy                           0.66       140\n","   macro avg       0.66      0.66      0.66       140\n","weighted avg       0.67      0.66      0.65       140\n","\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'user_gender_class/gender_model')"],"metadata":{"id":"2E9ThaDkAMxC","executionInfo":{"status":"ok","timestamp":1662370537201,"user_tz":-60,"elapsed":1946,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["## LOAD AFTERTRAINING\n","from transformers import BertModel, BertTokenizer, BertConfig\n","\n","\n","class BERT_Arch(nn.Module):\n","    \n","    def __init__(self, n_classes, freeze_bert=False):\n","        \n","        super(BERT_Arch,self).__init__()\n","        # Instantiating BERT model object\n","        model_path = 'user_gender_class/gender_model'\n","        self.bert = BertModel.from_pretrained(model_name, return_dict=False)\n","        self.load_state_dict(torch.load(model_path))\n","        \n","        # Freeze bert layers\n","        if freeze_bert:\n","            for p in self.bert.parameters():\n","                p.requires_grad = False\n","                \n","        self.bert_drop_1 = nn.Dropout(0.3)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size) # (768, 64)\n","        self.bn = nn.BatchNorm1d(768) # (768)\n","        self.bert_drop_2 = nn.Dropout(0.25)\n","        self.out = nn.Linear(self.bert.config.hidden_size, 2) # (768,2)\n","\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        _, output = self.bert(\n","            input_ids = input_ids,\n","            attention_mask = attention_mask,\n","            token_type_ids = token_type_ids\n","        )\n","        output = self.bert_drop_1(output)\n","        output = self.fc(output)\n","        output = self.bn(output)\n","        output = self.bert_drop_2(output)\n","        output = self.out(output)        \n","        return output\n","\n","class_names = np.unique(df['gender'])\n","print('Downloading the BERT custom model...')\n","x_model = BERT_Arch(2)\n","\n","#optimizer parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","optimizer_parameters = [{'params': [p for n, p in param_optimizer \n","                                    if not any(nd in n for nd in no_decay)],'weight_decay':0.001},\n","                        {'params': [p for n, p in param_optimizer \n","                                    if any(nd in n for nd in no_decay)],'weight_decay':0.0}]\n","\n","print('Preparing the optimizer...')\n","#optimizer \n","optimizer = AdamW(optimizer_parameters, lr=learning_rate)\n","steps = steps_per_epoch\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = steps\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":511},"id":"p7o8uu536eL_","executionInfo":{"status":"error","timestamp":1662371860737,"user_tz":-60,"elapsed":3662,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"6d75b574-992d-41da-ffaf-f3dff8c2e7a8"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading the BERT custom model...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-4ffbe59784e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading the BERT custom model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERT_Arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#optimizer parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-4ffbe59784e4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_classes, freeze_bert)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'user_gender_class/gender_model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Freeze bert layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1605\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BERT_Arch:\n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\", \"bn.weight\", \"bn.bias\", \"bn.running_mean\", \"bn.running_var\", \"bn.num_batches_tracked\", \"out.weight\", \"out.bias\". "]}]},{"cell_type":"markdown","source":["## ROBERTA NOT SIMPLE"],"metadata":{"id":"3ToMhp1CYX5I"}},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"FnHdjBbn4wrw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662326096460,"user_tz":-60,"elapsed":5206,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"212dad39-64ec-4e6b-cbc4-f1069c8a88c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import json, re\n","from tqdm import tqdm_notebook\n","from uuid import uuid4\n","\n","## Torch Modules\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","import transformers"],"metadata":{"id":"qE5O1ICp5LhX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading pre-trained models\n","from transformers import (\n","    BertForSequenceClassification,\n","#     TFBertForSequenceClassification, \n","                          BertTokenizer,\n","#                           TFRobertaForSequenceClassification,\n","                          RobertaForSequenceClassification,\n","                          RobertaTokenizer,\n","                         AdamW)\n","\n","# Get the lists of sentences and labels\n","sentences = df['text'].values\n","labels = df['gender'].values\n","labels = [int(l) for l in labels]\n","\n","# RoBERTa\n","roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", # 12-layer, 768-hidden, 12-heads, 125M parameters RoBERTa using the BERT-base architecture\n","                                                                    num_labels = 2, # The number of output labels--2 for binary classification.\n","                                                                                    # You can increase this for multi-class tasks.   \n","                                                                    output_attentions = False, # Whether the model returns attentions weights.\n","                                                                    output_hidden_states = False # Whether the model returns all hidden-states.\n","                                                                )\n","roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","# Tell pytorch to run this model on the GPU.\n","roberta_model.cuda()\n","\n","print(' Base models loaded')\n","\n","max_len_bert = 0\n","max_len_roberta = 0\n","\n","# For every sentence...\n","for sent in sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids_roberta = roberta_tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len_roberta = max(max_len_roberta, len(input_ids_roberta))\n","\n","print('Max sentence length RoBERTa: ', max_len_roberta)\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","roberta_input_ids = []\n","roberta_attention_masks = []\n","sentence_ids = []\n","counter = 0\n","\n","# For every sentence...\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.   \n","    \n","    roberta_encoded_dict = roberta_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 120,           # Pad & truncate all sentences.\n","                        truncation = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    # Add the encoded sentence to the list.    \n","    roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n","    \n","    # collecting sentence_ids\n","    sentence_ids.append(counter)\n","    counter  = counter + 1\n","    \n","# Convert the lists into tensors.\n","\n","roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n","roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n","\n","labels = torch.tensor(labels)\n","sentence_ids = torch.tensor(sentence_ids)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[1])\n","print('Token IDs RoBERTa:', roberta_input_ids[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519,"referenced_widgets":["25daca2230ed4996a4eb376745258c2c","174c2264dde745b2aa13686a9efbfd43","eec227ae3a574e918bc30bb39ff96a29","c72cb4cd7b064230b6322ebdbf4ed464","c0ca6403ee52451fb4263e4ef5ee75c1","1be74d1d020a4faabe72142f1e2c49ff","e045a176e827448892c3108df0086476","9f378b8c52b84d49be20ab6eed15a720","96d489631a9641b4a859fa3dd196d64c","6640bc287fe542d8b6aedeb2016bf689","f77aa13e86c74cb39fab0771e71110b5","33c2f9000699460297974da0c41de9cd","8c48c28a50f44bfba8a2373e25c8fb8c","bf7d1e889cf140c8a6e2337bac1a68af","dd622ada44634b2491104e074e8af3ae","a325f62544944ddbbd08cb7132483952","056b286cd6054863adae3d2ca38f4190","1deb244ed774410eaa506185194e8e57","fbf8304925b74ee1aeadf5e48bc398ba","71165554eb254190b6e75bc4be59d324","f316e005c2c744e6ac0ece75654b925a","2a819ba59567451b8ccd0ae8b309c944","e4e2387a545548f2b73ee6418b616cc3","5e68e98b600d475abf29bcd52b4e7a92","143fd23f8c0d46c7b2f93c531066a6be","162714e1ffbe486bad6d16ead26c126f","c536a98664e44bdbbc899ffe16a0cc2c","6d09bdaf92d640cf8388bc082f91a98e","e2a0c2f4942846f486a2bab67a9baf35","5b1a0df2e71845388e236d4adc06bcb4","3c0997f517fa41e6919cf14fbf42d3ae","e8d05ed192b1467db20567ddc609f120","44811bfaea4e42ce87db295aad70a062","58e6911186d8447098bc1a3c011d844e","bc92d55b82004d6fb0c66d12fd57bba4","05226951390b4b08ad80afa8e5adcbe8","d15154e6bf19417d823f5685a9ac21c9","8ab6143bee104912b28fb71c5e4562cc","e6fadb9016c64f6690f9854635a35d7b","e8fd77311bfe4ce3aea56aa458fe556b","2d2fb620c2a14cd7b647faf7e347d95e","d9b503b630a7465a9aa66da4b51921ca","ef881af37a574b4e8e2688ee5c259285","98683b5e7afc44da9b548a9da620b3d4"]},"id":"5rA2P2-iHkdA","executionInfo":{"status":"error","timestamp":1662315267455,"user_tz":-60,"elapsed":27480,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"eea496f0-1eea-4deb-89e3-fa54d2b237a6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25daca2230ed4996a4eb376745258c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c2f9000699460297974da0c41de9cd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e2387a545548f2b73ee6418b616cc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58e6911186d8447098bc1a3c011d844e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Base models loaded\n","Max sentence length RoBERTa:  487\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-998b9d84329f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Convert the lists into tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mroberta_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mroberta_attention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_attention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 35 but got size 59 for tensor number 1 in the list."]}]},{"cell_type":"code","source":["% ------------------------------------------------------------------------------\n","\n","from torch.utils.data import TensorDataset, random_split\n","# function to seed the script globally\n","torch.manual_seed(0)\n","\n","# Combine the training inputs into a TensorDataset.\n","roberta_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks, labels)\n","\n","# function to remove sentice ids from the tensor dataset post train test split\n","def index_remover(tensordata):\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","   \n","    for a,b,c,d in tensordata:\n","        input_ids.append(b.tolist())\n","        attention_masks.append(c.tolist())\n","        labels.append(d.tolist())\n","        \n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","    labels = torch.tensor(labels)\n","    \n","    final_dataset =  TensorDataset(input_ids, attention_masks, labels)\n","    return final_dataset\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(roberta_dataset))\n","val_size = len(roberta_dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","roberta_train_dataset, roberta_val_dataset = random_split(roberta_dataset, [train_size, val_size])\n","\n","# removing sentence ids from tensor dataset so that it can be used for training \n","roberta_train_dataset = index_remover(roberta_train_dataset)\n","roberta_val_dataset = index_remover(roberta_val_dataset)\n","\n","# Checking whether the distribution of target is consitent across both the sets\n","label_temp_list = []\n","for a,b,c in roberta_train_dataset:\n","  label_temp_list.append(c)\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} training samples with real disater tweets'.format(sum(label_temp_list)))\n","\n","\n","label_temp_list = []\n","for a,b,c in roberta_val_dataset:\n","  label_temp_list.append(c)\n","\n","print('{:>5,} validation samples'.format(val_size))\n","print('{:>5,} validation samples with real disater tweets'.format(sum(label_temp_list)))\n","\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","roberta_train_dataloader = DataLoader(\n","            roberta_train_dataset,  # The training samples.\n","            sampler = RandomSampler(roberta_train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","roberta_validation_dataloader = DataLoader(\n","            roberta_val_dataset, # The validation samples.\n","            sampler = SequentialSampler(roberta_val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n","\n","# Get all of the roberta_model's parameters as a list of tuples.\n","params = list(roberta_model.named_parameters())\n","\n","print('The RoBERTa model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","roberta_optimizer = AdamW(roberta_model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 2,I have already seen that the model starts overfitting beyound 2 epochs\n","epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(roberta_train_dataloader) * epochs\n","\n","# Create the learning rate scheduler\n","roberta_scheduler = get_linear_schedule_with_warmup(roberta_optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","\n","import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","\n","import random\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 100\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","roberta_training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the roberta_model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-roberta_model-train-do-in-pytorch)\n","    roberta_model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(roberta_train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(roberta_train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        roberta_model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the roberta_model on this training batch).\n","        # The documentation for this `roberta_model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/roberta_model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # are given and what flags are set. For our usage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the roberta_model\n","        # outputs prior to activation.\n","        loss, logits = roberta_model(b_input_ids, \n","#                              token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The roberta_optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        roberta_optimizer.step()\n","\n","        # Update the learning rate.\n","        roberta_scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(roberta_train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the roberta_model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    roberta_model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in roberta_validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # Get the \"logits\" output by the roberta_model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = roberta_model(b_input_ids, \n","#                                    token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(roberta_validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(roberta_validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    roberta_training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n","\n","import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=roberta_training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"id":"-4ZCgD-95MQF","colab":{"base_uri":"https://localhost:8080/","height":866},"executionInfo":{"status":"error","timestamp":1662288370141,"user_tz":-60,"elapsed":18251,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"72ac7092-f450-46a0-ebb0-0cbd3041af4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'str'>\n","<class 'int'>\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":[" Base models loaded\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Max sentence length BERT:  487\n","Max sentence length RoBERTa:  487\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:  ÛÏIt felt like they were my friends and I was living the story with themÛ https://t.co/arngE0YHNO #retired #IAN1 https://t.co/CIzCANPQFz\n","Token IDs RoBERTa: tensor([    0,  4056, 23171, 49506,  3849,  9357,   243,  1299,   101,    51,\n","           58,   127,   964,     8,    38,    21,  1207,     5,   527,    19,\n","          106,  4056, 23171, 49506,  4056,    46,  1205,   640,    90,     4,\n","          876,    73,   271,  2590,   717,   288,   975,   725, 13449,   849,\n","         4903,  7651,   849, 10296,   134,  1205,   640,    90,     4,   876,\n","           73, 21701,   329, 31448,   510,  1864,   597,   329,     2,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-03848e8144c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m# removing sentence ids from tensor dataset so that it can be used for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mroberta_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_remover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0mroberta_val_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_remover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_val_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-03848e8144c0>\u001b[0m in \u001b[0;36mindex_remover\u001b[0;34m(tensordata)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensordata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mattention_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"]}]},{"cell_type":"markdown","source":["## XGBOOST"],"metadata":{"id":"JaZLJ5dgBJdS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkHBbtn3z0aF"},"outputs":[],"source":["df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zHNuOf0yox6"},"outputs":[],"source":["# df.drop(['description','text'],axis=1,inplace=True)\n","# df.head()\n","\n","cv = CountVectorizer(max_features = 2000)\n","\n","x = cv.fit_transform(df['clean_description']).toarray()\n","\n","x1 = cv.fit_transform(df['clean_text']).toarray()\n","\n","A=pd.DataFrame(x)\n","B=pd.DataFrame(x1)\n","\n","X= pd.concat([B, A], join = 'outer', axis = 1)\n","\n","\n","df['gender'].isnull().sum()\n","\n","df['gender'].fillna(df['gender'].mode()[0], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4ftGnt6z0aM"},"outputs":[],"source":["x = np.array(X)\n","y = np.array(df['gender'])\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 0)"]},{"cell_type":"code","source":["import pickle\n","\n","xgbmodel = XGBClassifier(max_depth=5, min_child_weight=1)\n","xgbmodel.fit(X_train, y_train)\n","\n","y_pred2 = xgbmodel.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2)"],"metadata":{"id":"FEyD8ivnBjjM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662243575359,"user_tz":-60,"elapsed":153854,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"b62bcefd-cab2-4f8d-fb45-8cec1fcdccb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 69.80%\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[2091,   54],\n","       [ 926,  174]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["filename = 'user_gender_class/model/my_xgb_gender.joblib'\n","joblib.dump(xgbmodel, filename)"],"metadata":{"id":"yqaVurSFNxZR","executionInfo":{"status":"ok","timestamp":1662234769253,"user_tz":-60,"elapsed":506,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c41622d-23e4-4daa-ec05-5b1234399691"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['user_gender_class/model/my_xgb_gender.joblib']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# xgbmodel.save_model('user_gender_class/model/xgb_gender.json')\n","# filename = 'user_gender_class/model/xgb_gender.json'\n","# # pickle.dump(xgbmodel, open(filename, 'wb'))"],"metadata":{"id":"NIQk1TTrH-Co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(y_pred2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apSn78-VeCHe","executionInfo":{"status":"ok","timestamp":1662210566074,"user_tz":-60,"elapsed":10,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"a8fb7028-ec07-4721-a7f6-4e18e245bbde"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3245"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["xmodel = pickle.load(open(filename, 'rb'))\n","\n","y_pred2 = xmodel.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWM7K4_0L28z","executionInfo":{"status":"ok","timestamp":1662208970890,"user_tz":-60,"elapsed":899,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"47ec9fc7-8462-4761-e303-93383ebccc8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 69.31%\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[2094,   51],\n","       [ 945,  155]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["from xgboost import DMatrix\n","\n","xmodel = XGBClassifier(max_depth=5, min_child_weight=1)\n","booster = Booster()\n","booster.load_model('user_gender_class/model/xgb_gender.json')\n","xmodel._Booster = booster\n","\n","y_pred2 = xmodel.predict(DMatrix(X_test))\n","\n","accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2)"],"metadata":{"id":"5L89FdDwBlwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## FINDING BEST XGB\n","\n","xgb_param_grid = {\n","              \"max_depth\": [3, 5],\n","              \"min_child_weight\": [1, 2],\n","              }\n","\n","xgbgrid = GridSearchCV(estimator = xgbmodel, param_grid = xgb_param_grid, cv = 3, n_jobs = -1, verbose = 0)\n","\n","xgbgrid.fit(X_train, y_train)\n","\n","xgbgrid.best_params_\n","\n","y_pred2_hyper = xgbgrid.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred2_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2_hyper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwR0l2ZeQmrt","executionInfo":{"status":"ok","timestamp":1662222412342,"user_tz":-60,"elapsed":383456,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"6ffe05e9-d0ec-496b-a01b-b89f69ceb696"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 69.46%\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[2093,   52],\n","       [ 939,  161]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## UNNEEDED CODE"],"metadata":{"id":"Z8F8krfMBFvR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"f32VaDp1z0aM"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnbmodel = GaussianNB()\n","gnbmodel.fit(X_train , y_train)\n","# GaussianNB()\n","# from sklearn.naive_bayes import GaussianNB\n","y_pred = gnbmodel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XDyw5qIJz0aM","outputId":"264593eb-8a2f-44c3-f788-70bb67c5dbb1"},"outputs":[{"data":{"text/plain":["3245"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["len(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8UtG9posz0aM","outputId":"537e19e7-9db8-499b-b568-38c6be7d425f"},"outputs":[{"data":{"text/plain":["3245"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["len(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVMykq9Tz0aN"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4JBpOFQz0aN","outputId":"a3241155-4f90-44dd-89a0-68ac89bb7b19"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 52.05%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCZZGfDbz0aN","outputId":"e628035c-8b10-4283-b6d9-6f7fa4dc0bb7"},"outputs":[{"data":{"text/plain":["array([[ 759, 1386],\n","       [ 170,  930]], dtype=int64)"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"muPiCjpIz0aN","outputId":"5a34e42e-25fd-4bf5-83a8-7f022fc1ccf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.35      0.49      2145\n","           1       0.40      0.85      0.54      1100\n","\n","    accuracy                           0.52      3245\n","   macro avg       0.61      0.60      0.52      3245\n","weighted avg       0.68      0.52      0.51      3245\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgztz0DCz0aN"},"outputs":[],"source":["param_grid_nb = {\n","    'var_smoothing': np.logspace(0,-9, num=100)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDfxHLr6z0aN","outputId":"ad9f3644-aa71-4008-9814-287565bc975e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.7s\n","[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n","[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.9min finished\n"]},{"data":{"text/plain":["GridSearchCV(cv=3, estimator=GaussianNB(), n_jobs=-1,\n","             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n","       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n","       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n","       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n","       3.51119173e-02, 2.8480358...\n","       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n","       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n","       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n","       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n","       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n","       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n","             verbose=1)"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.naive_bayes import GaussianNB\n","from sklearn.model_selection import GridSearchCV\n","nbModel_grid = GridSearchCV(estimator=gnbmodel, param_grid=param_grid_nb, verbose=1, cv=3, n_jobs=-1)\n","nbModel_grid.fit(X_train, y_train)\n","#print(nbModel_grid.best_estimator_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ny4EG_jaz0aO","outputId":"5d68c1e9-0bd7-4e20-fb1f-ef53a0bf1dba"},"outputs":[{"data":{"text/plain":["{'var_smoothing': 0.02310129700083159}"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["nbModel_grid.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZSF8hL-kz0aO"},"outputs":[],"source":["y_pred_hyper = nbModel_grid.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etU5UUPOz0aO","outputId":"85b29d36-d3c3-427d-ad02-9388ed4d11dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1015 1130]\n"," [ 245  855]] : is the confusion matrix\n","Accuracy: 57.63%\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","print(confusion_matrix(y_test, y_pred_hyper), \": is the confusion matrix\")\n","from sklearn.metrics import accuracy_score\n","accuracy_gnb_hyper = accuracy_score(y_test, y_pred_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy_gnb_hyper * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-7f3Gh7z0aO","outputId":"f02334a7-c921-44a3-9c7a-667ef2e4b8d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.47      0.60      2145\n","           1       0.43      0.78      0.55      1100\n","\n","    accuracy                           0.58      3245\n","   macro avg       0.62      0.63      0.58      3245\n","weighted avg       0.68      0.58      0.58      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred_hyper))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0vEq2m3Yz0aO"},"outputs":[],"source":["confusion_matrix(y_test, y_pred_hyper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcnTqdI0z0aP","outputId":"532efa0b-31dd-465b-ed3c-b537051a79a9"},"outputs":[{"data":{"text/plain":["LGBMClassifier(max_depth=3)"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["lgbmodel = LGBMClassifier(max_depth=3)\n","lgbmodel.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MSqnsmWz0aP"},"outputs":[],"source":["y_pred1= lgbmodel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4FyEwhbz0aP","outputId":"8f62d795-6ff8-445b-a9e9-8f0bddc00326"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 68.81%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred1)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdKyrmtYz0aP"},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Zd3omQXLz0aP","outputId":"a7af7ceb-9041-4c73-f5c8-2e12a49acfff"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.98      0.81      2145\n","           1       0.77      0.11      0.20      1100\n","\n","    accuracy                           0.69      3245\n","   macro avg       0.73      0.55      0.50      3245\n","weighted avg       0.71      0.69      0.60      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9hiSk3iz0aP"},"outputs":[],"source":["param_grid = {\n","              \"max_depth\": [2, 3, 5, 10],\n","              \"min_child_weight\": [0.001, 0.002],\n","              \"learning_rate\": [0.05, 0.1]\n","              }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abtUgzC7z0aP","outputId":"c0b9410d-baaf-4cf0-d8b3-92122524c9e4"},"outputs":[{"data":{"text/plain":["GridSearchCV(cv=3, estimator=LGBMClassifier(max_depth=3), n_jobs=-1,\n","             param_grid={'learning_rate': [0.05, 0.1],\n","                         'max_depth': [2, 3, 5, 10],\n","                         'min_child_weight': [0.001, 0.002]})"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["lgbgrid = GridSearchCV(estimator = lgbmodel, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 0)\n","\n","lgbgrid.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KIgFr944z0aQ","outputId":"db3c5899-9c0a-4a53-e2b9-3e917b3e51a7"},"outputs":[{"data":{"text/plain":["{'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 0.001}"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["lgbgrid.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6A0i6Vx7z0aQ"},"outputs":[],"source":["y_pred1_hyper = lgbgrid.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubNCKq9Jz0aQ","outputId":"313be6ac-a83d-4b35-ab26-cb78a54555f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 69.89%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred1_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMStQch7z0aQ","outputId":"7d9ede82-bca4-4aaa-a802-bd9043358c98"},"outputs":[{"data":{"text/plain":["array([[2068,   77],\n","       [ 900,  200]], dtype=int64)"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred1_hyper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W227L-dgz0aQ","outputId":"fd2491b1-9907-45f0-97e8-29ce15261cd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.96      0.81      2145\n","           1       0.72      0.18      0.29      1100\n","\n","    accuracy                           0.70      3245\n","   macro avg       0.71      0.57      0.55      3245\n","weighted avg       0.71      0.70      0.63      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred1_hyper))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fWHG_E2z0aR","outputId":"1b6b972e-601a-4133-dd90-502055a0de94"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[15:06:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n","              importance_type='gain', interaction_constraints='',\n","              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n","              min_child_weight=1, missing=nan, monotone_constraints='()',\n","              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n","              tree_method='exact', validate_parameters=1, verbosity=None)"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["xgbmodel = XGBClassifier(max_depth=5, min_child_weight=1)\n","xgbmodel.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPPNsYlZz0aR"},"outputs":[],"source":["y_pred2 = xgbmodel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pC4-eFW8z0aR","outputId":"8b639a1f-8641-49dc-ce17-139b50574fb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 70.35%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edNku7qSz0aR","outputId":"c20e3f61-f37a-4676-b65f-bb903bfb2045"},"outputs":[{"data":{"text/plain":["array([[2051,   94],\n","       [ 868,  232]], dtype=int64)"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48XdXBstz0aR","outputId":"7011f1d5-0e29-4f76-d39a-39802320262e"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.96      0.81      2145\n","           1       0.71      0.21      0.33      1100\n","\n","    accuracy                           0.70      3245\n","   macro avg       0.71      0.58      0.57      3245\n","weighted avg       0.71      0.70      0.65      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRdZLK3uz0aR"},"outputs":[],"source":["xgb_param_grid = {\n","              \"max_depth\": [3, 5],\n","              \"min_child_weight\": [1, 2],\n","              }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPtXNjewz0aS","outputId":"2fadfc06-d12c-4250-ad37-d810a8a1cec7"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[15:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n","                                     colsample_bylevel=1, colsample_bynode=1,\n","                                     colsample_bytree=1, gamma=0, gpu_id=-1,\n","                                     importance_type='gain',\n","                                     interaction_constraints='',\n","                                     learning_rate=0.300000012,\n","                                     max_delta_step=0, max_depth=5,\n","                                     min_child_weight=1, missing=nan,\n","                                     monotone_constraints='()',\n","                                     n_estimators=100, n_jobs=4,\n","                                     num_parallel_tree=1, random_state=0,\n","                                     reg_alpha=0, reg_lambda=1,\n","                                     scale_pos_weight=1, subsample=1,\n","                                     tree_method='exact', validate_parameters=1,\n","                                     verbosity=None),\n","             n_jobs=-1,\n","             param_grid={'max_depth': [3, 5], 'min_child_weight': [1, 2]})"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["xgbgrid = GridSearchCV(estimator = xgbmodel, param_grid = xgb_param_grid, cv = 3, n_jobs = -1, verbose = 0)\n","\n","xgbgrid.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yohqQ13Qz0aS","outputId":"48632253-23c5-476c-f725-98bc45330602"},"outputs":[{"data":{"text/plain":["{'max_depth': 5, 'min_child_weight': 1}"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["xgbgrid.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6pINMg1Dz0aS"},"outputs":[],"source":["y_pred2_hyper = xgbgrid.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJ-wrTNsz0aS","outputId":"7a2a9cfa-871c-4ab6-c9e7-ef473d959465"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 70.35%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred2_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuhaWAp4z0aS","outputId":"0b2f6937-2953-4fc7-90d9-4704b9361e77"},"outputs":[{"data":{"text/plain":["array([[2051,   94],\n","       [ 868,  232]], dtype=int64)"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred2_hyper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCcJXGIdz0aS"},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bb6RCrNiz0aT","outputId":"470d4e2a-272f-4f4c-d10d-7cf2d23581b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.96      0.81      2145\n","           1       0.71      0.21      0.33      1100\n","\n","    accuracy                           0.70      3245\n","   macro avg       0.71      0.58      0.57      3245\n","weighted avg       0.71      0.70      0.65      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred2_hyper))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkQQDbvmz0aT"},"outputs":[],"source":["#from sklearn.metrics import roc_curve,roc_auc_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HB0ukzH7z0aT"},"outputs":[],"source":["# nb_probs =classifier.predict_proba(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HAEUG0cz0aT"},"outputs":[],"source":["# nb_probs=nb_probs[:,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"du8t6Z9iz0aT"},"outputs":[],"source":["# nb_auc = roc_auc_score(y_test, nb_probs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0mAuF7uz0aT","outputId":"6e0cf421-85aa-4d6b-9902-00dc1aa2333c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gaussian: AUROC = 0.582\n"]}],"source":["# print('Gaussian: AUROC = %.3f' % (nb_auc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3hEkdZ1z0aU","outputId":"254790c3-1b83-469b-d821-5c404e96ae40"},"outputs":[{"data":{"text/plain":["array(['1', '0', '1', ..., '0', '0', '1'], dtype=object)"]},"execution_count":132,"metadata":{},"output_type":"execute_result"}],"source":["# y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KU8H30Quz0aU","outputId":"75f0815b-ed73-44b4-ca23-d726ed04a6ff"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n","  UndefinedMetricWarning)\n"]}],"source":["# nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_probs,pos_label=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEbopn-kz0aU","outputId":"e4c518e3-06c1-4dbe-fd76-f323279b10d9"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0xc42a540f08>]"]},"execution_count":131,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# plt.plot(nb_fpr, nb_tpr, marker='.', label='Gaussian (AUROC = %0.3f)' % nb_auc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsUF4lnTz0aU","outputId":"bbeddfa9-16b9-4e36-b5e2-a4d270faf77f"},"outputs":[{"data":{"text/plain":["(16224, 24000)"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["# X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1EqP-18-z0aU","outputId":"f2576726-d037-4881-89f5-f0c8986cd6cb"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n","  UndefinedMetricWarning)\n"]}],"source":["# fpr1, tpr1,thresh1 =roc_curve(y_test, pred_prob1[:,1],pos_label=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZdAe7lYz0aV","outputId":"5ec9fbbe-47b7-4305-e437-e1b5ba147dfa"},"outputs":[{"data":{"text/plain":["array([nan, nan, nan])"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["# tpr1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rN8jtZwz0aV"},"outputs":[],"source":["# import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlEO4oYbz0aV","outputId":"f1176cc4-a1c8-4c34-b48e-3eaec5fa390a"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0xc4010c2708>]"]},"execution_count":114,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Gaussian')"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["3ToMhp1CYX5I","v14CuYe64g8A","JaZLJ5dgBJdS","Z8F8krfMBFvR"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3.9.7 ('env-pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"59556fecfb9e1650310a175ca5cd58c0b942341d9e7f74cbfe1ccb958d377f3d"}},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e4a5ced34f5c46f58ca165095ad40cd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_184b522287ff45238635f4a1d9eb757e","IPY_MODEL_025b7940acb4423cb38c3c5b68d27f63","IPY_MODEL_6eabc0d5bf7b47b7a089d16bd9759bf4"],"layout":"IPY_MODEL_e50b988e4ae643428368d032087e5155"}},"184b522287ff45238635f4a1d9eb757e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3c48789abdf448ca103cae57581a197","placeholder":"​","style":"IPY_MODEL_f57ec88587034553aa453db4bf607079","value":"Downloading config.json: 100%"}},"025b7940acb4423cb38c3c5b68d27f63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_632855bfa1ec45c588318a8c0b462b65","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_554da9014d164eaebc61561b38c950e1","value":481}},"6eabc0d5bf7b47b7a089d16bd9759bf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4260a6b4efa34546865df129dd310ad9","placeholder":"​","style":"IPY_MODEL_a4deefd3771e4cd597a8f3d58824b2b6","value":" 481/481 [00:00&lt;00:00, 12.8kB/s]"}},"e50b988e4ae643428368d032087e5155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c48789abdf448ca103cae57581a197":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f57ec88587034553aa453db4bf607079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"632855bfa1ec45c588318a8c0b462b65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"554da9014d164eaebc61561b38c950e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4260a6b4efa34546865df129dd310ad9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4deefd3771e4cd597a8f3d58824b2b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bfbc004c8534ce58f9554d8280b56d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_653ffa25927a4a80b0dc919f6d712f26","IPY_MODEL_c2aac61a665c4ef890926aec2ea1b4e0","IPY_MODEL_78bae6d4408c4dceaebda81148a48f06"],"layout":"IPY_MODEL_582beae7e972482d988533501efcc700"}},"653ffa25927a4a80b0dc919f6d712f26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9299f27d983e4901abacf9abe0171768","placeholder":"​","style":"IPY_MODEL_346c2dcc06f7408d8e120a39cb41d167","value":"Downloading pytorch_model.bin: 100%"}},"c2aac61a665c4ef890926aec2ea1b4e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f4013d5f5b44f06800567b5abad61ff","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09abef4e77314c96a562645cd7c67679","value":501200538}},"78bae6d4408c4dceaebda81148a48f06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_983c62088d67468fb1edca16a879b74d","placeholder":"​","style":"IPY_MODEL_d9799c2428f9473abcd53d66eaed64ae","value":" 478M/478M [00:12&lt;00:00, 40.7MB/s]"}},"582beae7e972482d988533501efcc700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9299f27d983e4901abacf9abe0171768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"346c2dcc06f7408d8e120a39cb41d167":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f4013d5f5b44f06800567b5abad61ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09abef4e77314c96a562645cd7c67679":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"983c62088d67468fb1edca16a879b74d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9799c2428f9473abcd53d66eaed64ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e46324d2113462595b135beede9edd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9694015f88964b29a09708c3bd297ab4","IPY_MODEL_d2a38192ac224b2f919e2c041c5c97f8","IPY_MODEL_cb483e6281894b1288783bf8eb44f51d"],"layout":"IPY_MODEL_f0f831d180e6415994db3a421bd8a8e6"}},"9694015f88964b29a09708c3bd297ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a007188671664e19b9244ef62772e468","placeholder":"​","style":"IPY_MODEL_8e687629b2a14f039ae2665f095ef34f","value":"Downloading vocab.json: 100%"}},"d2a38192ac224b2f919e2c041c5c97f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e62c026c69044cc988a3d31df7f35cca","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1242f936a54a4c048280b7cd1bd753ff","value":898823}},"cb483e6281894b1288783bf8eb44f51d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7242668ec2d4f1f97cbcc308458d83e","placeholder":"​","style":"IPY_MODEL_984edaf6a8be4505a8362292692ec474","value":" 878k/878k [00:00&lt;00:00, 2.06MB/s]"}},"f0f831d180e6415994db3a421bd8a8e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a007188671664e19b9244ef62772e468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e687629b2a14f039ae2665f095ef34f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e62c026c69044cc988a3d31df7f35cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1242f936a54a4c048280b7cd1bd753ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7242668ec2d4f1f97cbcc308458d83e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"984edaf6a8be4505a8362292692ec474":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91ec98082d02417ea5310671ee9ecc44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53dcbaf6e89d4e0aa996a8e40e3828d4","IPY_MODEL_044cdde97df34fb780c742730d0d29f9","IPY_MODEL_42b857cdf32d4669ad8f180068a3e8e8"],"layout":"IPY_MODEL_f37cdef7d4ac4754af78a3e0739cac19"}},"53dcbaf6e89d4e0aa996a8e40e3828d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a08ec4d2992143f4bef7f83bbe0682ec","placeholder":"​","style":"IPY_MODEL_fad162df46df4feba43cf1c047d05829","value":"Downloading merges.txt: 100%"}},"044cdde97df34fb780c742730d0d29f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16592399f9cc472694a6480464c480a7","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9561c984c364872bb8fa7d9d381be6f","value":456318}},"42b857cdf32d4669ad8f180068a3e8e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffc9ad27532148819e4f866e036cbc42","placeholder":"​","style":"IPY_MODEL_841a7425158e428e8f63dfeacf7749f2","value":" 446k/446k [00:00&lt;00:00, 705kB/s]"}},"f37cdef7d4ac4754af78a3e0739cac19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a08ec4d2992143f4bef7f83bbe0682ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fad162df46df4feba43cf1c047d05829":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16592399f9cc472694a6480464c480a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9561c984c364872bb8fa7d9d381be6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffc9ad27532148819e4f866e036cbc42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"841a7425158e428e8f63dfeacf7749f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71aa44e2a41a4f90843f82d3fbc2132b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9fa122edfd14287aee598bb3fcd0ba0","IPY_MODEL_3eb4c448cff34cc4aa344fe460d3813a","IPY_MODEL_d43b184f1e5a4a9cbbe22f3f6261b110"],"layout":"IPY_MODEL_3022b3e0872b43ecb900d69acd0b000a"}},"c9fa122edfd14287aee598bb3fcd0ba0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4f397f6665b45afa3dfd1960ec834f7","placeholder":"​","style":"IPY_MODEL_449b8ff237f0488abcee530cd814df78","value":"Downloading tokenizer.json: 100%"}},"3eb4c448cff34cc4aa344fe460d3813a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e770a1fa454254ac0c89c4e4dd31af","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfc177c4c8cc46b887f50a325aabe850","value":1355863}},"d43b184f1e5a4a9cbbe22f3f6261b110":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e80c574c50e94a17af91b7b9a9d6b9e4","placeholder":"​","style":"IPY_MODEL_297507b6d38e45e29e96b70ad4a365ba","value":" 1.29M/1.29M [00:00&lt;00:00, 2.34MB/s]"}},"3022b3e0872b43ecb900d69acd0b000a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f397f6665b45afa3dfd1960ec834f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"449b8ff237f0488abcee530cd814df78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52e770a1fa454254ac0c89c4e4dd31af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc177c4c8cc46b887f50a325aabe850":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e80c574c50e94a17af91b7b9a9d6b9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"297507b6d38e45e29e96b70ad4a365ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25daca2230ed4996a4eb376745258c2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_174c2264dde745b2aa13686a9efbfd43","IPY_MODEL_eec227ae3a574e918bc30bb39ff96a29","IPY_MODEL_c72cb4cd7b064230b6322ebdbf4ed464"],"layout":"IPY_MODEL_c0ca6403ee52451fb4263e4ef5ee75c1"}},"174c2264dde745b2aa13686a9efbfd43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1be74d1d020a4faabe72142f1e2c49ff","placeholder":"​","style":"IPY_MODEL_e045a176e827448892c3108df0086476","value":"Downloading config.json: 100%"}},"eec227ae3a574e918bc30bb39ff96a29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f378b8c52b84d49be20ab6eed15a720","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96d489631a9641b4a859fa3dd196d64c","value":481}},"c72cb4cd7b064230b6322ebdbf4ed464":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6640bc287fe542d8b6aedeb2016bf689","placeholder":"​","style":"IPY_MODEL_f77aa13e86c74cb39fab0771e71110b5","value":" 481/481 [00:00&lt;00:00, 17.4kB/s]"}},"c0ca6403ee52451fb4263e4ef5ee75c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1be74d1d020a4faabe72142f1e2c49ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e045a176e827448892c3108df0086476":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f378b8c52b84d49be20ab6eed15a720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d489631a9641b4a859fa3dd196d64c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6640bc287fe542d8b6aedeb2016bf689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f77aa13e86c74cb39fab0771e71110b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33c2f9000699460297974da0c41de9cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c48c28a50f44bfba8a2373e25c8fb8c","IPY_MODEL_bf7d1e889cf140c8a6e2337bac1a68af","IPY_MODEL_dd622ada44634b2491104e074e8af3ae"],"layout":"IPY_MODEL_a325f62544944ddbbd08cb7132483952"}},"8c48c28a50f44bfba8a2373e25c8fb8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056b286cd6054863adae3d2ca38f4190","placeholder":"​","style":"IPY_MODEL_1deb244ed774410eaa506185194e8e57","value":"Downloading pytorch_model.bin: 100%"}},"bf7d1e889cf140c8a6e2337bac1a68af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf8304925b74ee1aeadf5e48bc398ba","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71165554eb254190b6e75bc4be59d324","value":501200538}},"dd622ada44634b2491104e074e8af3ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f316e005c2c744e6ac0ece75654b925a","placeholder":"​","style":"IPY_MODEL_2a819ba59567451b8ccd0ae8b309c944","value":" 478M/478M [00:08&lt;00:00, 61.1MB/s]"}},"a325f62544944ddbbd08cb7132483952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"056b286cd6054863adae3d2ca38f4190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1deb244ed774410eaa506185194e8e57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbf8304925b74ee1aeadf5e48bc398ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71165554eb254190b6e75bc4be59d324":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f316e005c2c744e6ac0ece75654b925a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a819ba59567451b8ccd0ae8b309c944":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4e2387a545548f2b73ee6418b616cc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e68e98b600d475abf29bcd52b4e7a92","IPY_MODEL_143fd23f8c0d46c7b2f93c531066a6be","IPY_MODEL_162714e1ffbe486bad6d16ead26c126f"],"layout":"IPY_MODEL_c536a98664e44bdbbc899ffe16a0cc2c"}},"5e68e98b600d475abf29bcd52b4e7a92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d09bdaf92d640cf8388bc082f91a98e","placeholder":"​","style":"IPY_MODEL_e2a0c2f4942846f486a2bab67a9baf35","value":"Downloading vocab.json: 100%"}},"143fd23f8c0d46c7b2f93c531066a6be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b1a0df2e71845388e236d4adc06bcb4","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c0997f517fa41e6919cf14fbf42d3ae","value":898823}},"162714e1ffbe486bad6d16ead26c126f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d05ed192b1467db20567ddc609f120","placeholder":"​","style":"IPY_MODEL_44811bfaea4e42ce87db295aad70a062","value":" 878k/878k [00:00&lt;00:00, 1.98MB/s]"}},"c536a98664e44bdbbc899ffe16a0cc2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d09bdaf92d640cf8388bc082f91a98e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a0c2f4942846f486a2bab67a9baf35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b1a0df2e71845388e236d4adc06bcb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c0997f517fa41e6919cf14fbf42d3ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8d05ed192b1467db20567ddc609f120":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44811bfaea4e42ce87db295aad70a062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58e6911186d8447098bc1a3c011d844e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc92d55b82004d6fb0c66d12fd57bba4","IPY_MODEL_05226951390b4b08ad80afa8e5adcbe8","IPY_MODEL_d15154e6bf19417d823f5685a9ac21c9"],"layout":"IPY_MODEL_8ab6143bee104912b28fb71c5e4562cc"}},"bc92d55b82004d6fb0c66d12fd57bba4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6fadb9016c64f6690f9854635a35d7b","placeholder":"​","style":"IPY_MODEL_e8fd77311bfe4ce3aea56aa458fe556b","value":"Downloading merges.txt: 100%"}},"05226951390b4b08ad80afa8e5adcbe8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d2fb620c2a14cd7b647faf7e347d95e","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9b503b630a7465a9aa66da4b51921ca","value":456318}},"d15154e6bf19417d823f5685a9ac21c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef881af37a574b4e8e2688ee5c259285","placeholder":"​","style":"IPY_MODEL_98683b5e7afc44da9b548a9da620b3d4","value":" 446k/446k [00:00&lt;00:00, 674kB/s]"}},"8ab6143bee104912b28fb71c5e4562cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6fadb9016c64f6690f9854635a35d7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8fd77311bfe4ce3aea56aa458fe556b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d2fb620c2a14cd7b647faf7e347d95e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9b503b630a7465a9aa66da4b51921ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef881af37a574b4e8e2688ee5c259285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98683b5e7afc44da9b548a9da620b3d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f738e0978cfa4df38868f3253d028ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec6f6dbdd02b4aa19a846c2f85e83c99","IPY_MODEL_7b4c9a3057714b1da86649225e7800ac","IPY_MODEL_886e550a6e084c829f2e4bd4180a8ab0"],"layout":"IPY_MODEL_06c909dc0eec416ca1b7b0e1f23752ae"}},"ec6f6dbdd02b4aa19a846c2f85e83c99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42bc2548fd004db798e28a5b4dd0c401","placeholder":"​","style":"IPY_MODEL_d125291176494d5a930b6ba770aafa92","value":"Downloading vocab.txt: 100%"}},"7b4c9a3057714b1da86649225e7800ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d2f61d0c12b47e89336fc0a35e68f64","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4c1fac6b1d34f829afa1d410775c4db","value":231508}},"886e550a6e084c829f2e4bd4180a8ab0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd2b72c8e02244a8a7f1bcb611ad9369","placeholder":"​","style":"IPY_MODEL_e7008b66a35e4d458b2ba98e66dbb820","value":" 226k/226k [00:00&lt;00:00, 590kB/s]"}},"06c909dc0eec416ca1b7b0e1f23752ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42bc2548fd004db798e28a5b4dd0c401":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d125291176494d5a930b6ba770aafa92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d2f61d0c12b47e89336fc0a35e68f64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4c1fac6b1d34f829afa1d410775c4db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd2b72c8e02244a8a7f1bcb611ad9369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7008b66a35e4d458b2ba98e66dbb820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44dc91d1aae64ff196a68035ed4efe08":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4c3fa965e754c63861640910e5a2e09","IPY_MODEL_6c50cdc3b9d1453a971fac3a83442fee","IPY_MODEL_3b5e2bf419fe4a208943974ed2519b46"],"layout":"IPY_MODEL_d561bf6ac4df4c72be615d6a2569b34e"}},"a4c3fa965e754c63861640910e5a2e09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8685865e1d84467b41e3eb06c5c34d5","placeholder":"​","style":"IPY_MODEL_62b2a64630e34a9594e27a8829618306","value":"Downloading tokenizer_config.json: 100%"}},"6c50cdc3b9d1453a971fac3a83442fee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_704d7bcd4fbc469282abf049bdd43b76","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b72ad6cc0654aaf9b00a07a18de1603","value":28}},"3b5e2bf419fe4a208943974ed2519b46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58956c31f52747c0804a4c232ede13ae","placeholder":"​","style":"IPY_MODEL_bc49c6c631ad4b708f997eedb5c188df","value":" 28.0/28.0 [00:00&lt;00:00, 838B/s]"}},"d561bf6ac4df4c72be615d6a2569b34e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8685865e1d84467b41e3eb06c5c34d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b2a64630e34a9594e27a8829618306":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"704d7bcd4fbc469282abf049bdd43b76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b72ad6cc0654aaf9b00a07a18de1603":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58956c31f52747c0804a4c232ede13ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc49c6c631ad4b708f997eedb5c188df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6699e20abb6740159bb75d11108cc6c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a01801e483c54b3cbaba43101e64fccd","IPY_MODEL_d60fcad9e6a544ff9b52e3b150553459","IPY_MODEL_90fc28ca0153425f8e9a33132396c0c1"],"layout":"IPY_MODEL_15110d0934994c22bf0626f53063e954"}},"a01801e483c54b3cbaba43101e64fccd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69bb351dfa334d8792c69dfd832fa8c4","placeholder":"​","style":"IPY_MODEL_04d2c20f79444fc58b829f7359c5e471","value":"Downloading config.json: 100%"}},"d60fcad9e6a544ff9b52e3b150553459":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87cf0752ddb54e459e3f3cd15afb1c98","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2e14c1001fe4d27a030800e5f307843","value":570}},"90fc28ca0153425f8e9a33132396c0c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c81ae1b980d4d1c9bdbbcc0edb07bad","placeholder":"​","style":"IPY_MODEL_1534f5e6409a43ef94ad7f5552d48f51","value":" 570/570 [00:00&lt;00:00, 18.6kB/s]"}},"15110d0934994c22bf0626f53063e954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69bb351dfa334d8792c69dfd832fa8c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d2c20f79444fc58b829f7359c5e471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87cf0752ddb54e459e3f3cd15afb1c98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2e14c1001fe4d27a030800e5f307843":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c81ae1b980d4d1c9bdbbcc0edb07bad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1534f5e6409a43ef94ad7f5552d48f51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef4328eb0d36448e82e3de8f343e2184":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecbf48b8a3f844efaf20f920e7c836ca","IPY_MODEL_fce6814cb780414ba4da6facc244cd2b","IPY_MODEL_67b33a1433b045088ea9478c87a38997"],"layout":"IPY_MODEL_31abb09ba88e400587a393bbaef69a4b"}},"ecbf48b8a3f844efaf20f920e7c836ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_390c2668f02f45549a2a57b45bf48daa","placeholder":"​","style":"IPY_MODEL_e56ea56d8b3140b28b8430d3375850a1","value":"Downloading pytorch_model.bin: 100%"}},"fce6814cb780414ba4da6facc244cd2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19588b721b734d1e9718ea4135cd8bbf","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_331c526ec3eb484ab7f4d8df13bc3668","value":440473133}},"67b33a1433b045088ea9478c87a38997":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1a702a7f6be48da82265befcef83f7c","placeholder":"​","style":"IPY_MODEL_8c7d588e80ae4ad58a4b2a53caaccd55","value":" 420M/420M [00:10&lt;00:00, 44.4MB/s]"}},"31abb09ba88e400587a393bbaef69a4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390c2668f02f45549a2a57b45bf48daa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e56ea56d8b3140b28b8430d3375850a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19588b721b734d1e9718ea4135cd8bbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"331c526ec3eb484ab7f4d8df13bc3668":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1a702a7f6be48da82265befcef83f7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c7d588e80ae4ad58a4b2a53caaccd55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}