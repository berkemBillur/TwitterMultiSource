{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/MSc_project/.MAIN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjB04glDz9GM","executionInfo":{"status":"ok","timestamp":1662326022742,"user_tz":-60,"elapsed":20874,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"4fae9aec-c02b-4733-8770-64560c65b8ef"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/MSc_project/.MAIN\n"]}]},{"cell_type":"code","source":["!pip install pandas==1.2.4\n","!pip install xgboost\n","!pip install lightgbm\n","!pip install tweet-preprocessor"],"metadata":{"id":"nX70KVtb4G0i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662326045993,"user_tz":-60,"elapsed":23256,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"9bd7af15-afee-4ff0-e645-e5ded980401e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandas==1.2.4\n","  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 11.7 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (2022.2.1)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.4) (1.15.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","Successfully installed pandas-1.2.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tweet-preprocessor\n","  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n","Installing collected packages: tweet-preprocessor\n","Successfully installed tweet-preprocessor-0.6.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os.path\n","\n","import nltk\n","from nltk.stem import PorterStemmer # for stemming\n","from nltk.stem import WordNetLemmatizer # for lemmatization\n","from nltk.corpus import stopwords\n","import re\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBClassifier, Booster\n","from lightgbm import LGBMClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","\n","import numpy as np\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import train_test_split\n","\n","import preprocessor as p\n","import joblib"],"metadata":{"id":"V9Sz024N4MOp","executionInfo":{"status":"ok","timestamp":1662326047224,"user_tz":-60,"elapsed":1241,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"POjBgP6uLqHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662326048673,"user_tz":-60,"elapsed":1065,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"b1210342-a86d-44e4-e833-d69f338c3684"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["female    5725\n","male      5469\n","Name: gender, dtype: int64"]},"metadata":{},"execution_count":4}],"source":["df=pd.read_csv('user_gender_class/data/gender-classifier-DFE-791531.csv',encoding='latin1')\n","\n","df.drop(['_unit_id','_last_judgment_at','created','fav_number','profileimage','retweet_count','tweet_coord',\n","         '_trusted_judgments', 'tweet_count', 'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone', \n","         '_golden','_unit_state', 'gender_gold', 'link_color', 'name', 'profile_yn_gold', 'sidebar_color', \n","         'profile_yn', 'profile_yn:confidence','gender:confidence'], axis=1, inplace=True)\n","\n","df.isna().sum()\n","df.dropna(axis=0,inplace=True)\n","df['gender'].value_counts()\n","df['gender'] = df[(df['gender'] == 'female') | (df['gender'] == 'male')]\n","df['gender'].value_counts()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"IflS0bJhSbw1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662326054334,"user_tz":-60,"elapsed":5664,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"46f10b4a-2177-4947-f9bc-a1fdc01d59e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["0    5725\n","1    5469\n","Name: gender, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["now cleaning\n"]}],"source":["  for gen in df['gender']:\n","    #print(gen)\n","    if gen=='male':\n","      df['gender'].replace({'male':'1'},inplace=True)\n","    elif gen=='female':\n","      df['gender'].replace({'female':'0'},inplace=True)\n","\n","  \n","\n","  df = df[df['gender'].notna()]\n","  print(df['gender'].value_counts())\n","\n","  nltk.download('punkt')\n","  nltk.download('stopwords')\n","  nltk.download('wordnet')\n","\n","  nltk.download('omw-1.4')\n","  remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n","  rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n","\n","  lemma = WordNetLemmatizer()\n","  stopword = nltk.corpus.stopwords.words('english')\n","\n","  def remove_stopwords(text):\n","      text = [word for word in text if word not in stopword]\n","      return text\n","\n","  def tokenization(text):\n","      text = re.split('\\W+', text)\n","      return text\n","\n","\n","  print('now cleaning')\n","\n","  p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\n","  df['clean_description'] = df.description.map(remove_rt).map(rt).map(p.clean).str.lower().apply(lambda x: tokenization(x)).apply(lambda x: remove_stopwords(x))\n","  df['clean_text'] = df.text.map(remove_rt).map(rt).map(p.clean).str.lower().apply(lambda x: tokenization(x)).apply(lambda x: remove_stopwords(x))\n","\n","  df['clean_description'] = df.clean_description.apply(lambda lst: [lemma.lemmatize(word) for word in lst]).str.join(\" \")\n","  df['clean_text'] = df.clean_text.apply(lambda lst: [lemma.lemmatize(word) for word in lst]).str.join(\" \")"]},{"cell_type":"markdown","source":["## ROBERTA SIMPLE\n"],"metadata":{"id":"GWgg5M5b3f7D"}},{"cell_type":"code","source":["!pip install --upgrade transformers\n","!pip install simpletransformers"],"metadata":{"id":"I3kvpjY_-Bcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFNXSyisW2rT","executionInfo":{"status":"ok","timestamp":1662326250609,"user_tz":-60,"elapsed":548,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"d2af7977-98f8-4a58-b0c9-a5873357e43a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from simpletransformers.classification import ClassificationModel, ClassificationArgs"],"metadata":{"id":"gONSGdhPW3VO","executionInfo":{"status":"ok","timestamp":1662326231423,"user_tz":-60,"elapsed":3212,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['gender'], random_state=42)\n","\n","model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir=True, manual_seed=42, silent=True)\n","\n","model = ClassificationModel(model_type='roberta', model_name='roberta-base', use_cuda=True, num_labels=2, \n","                            args=model_args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288,"referenced_widgets":["e4a5ced34f5c46f58ca165095ad40cd6","184b522287ff45238635f4a1d9eb757e","025b7940acb4423cb38c3c5b68d27f63","6eabc0d5bf7b47b7a089d16bd9759bf4","e50b988e4ae643428368d032087e5155","a3c48789abdf448ca103cae57581a197","f57ec88587034553aa453db4bf607079","632855bfa1ec45c588318a8c0b462b65","554da9014d164eaebc61561b38c950e1","4260a6b4efa34546865df129dd310ad9","a4deefd3771e4cd597a8f3d58824b2b6","0bfbc004c8534ce58f9554d8280b56d6","653ffa25927a4a80b0dc919f6d712f26","c2aac61a665c4ef890926aec2ea1b4e0","78bae6d4408c4dceaebda81148a48f06","582beae7e972482d988533501efcc700","9299f27d983e4901abacf9abe0171768","346c2dcc06f7408d8e120a39cb41d167","1f4013d5f5b44f06800567b5abad61ff","09abef4e77314c96a562645cd7c67679","983c62088d67468fb1edca16a879b74d","d9799c2428f9473abcd53d66eaed64ae","7e46324d2113462595b135beede9edd6","9694015f88964b29a09708c3bd297ab4","d2a38192ac224b2f919e2c041c5c97f8","cb483e6281894b1288783bf8eb44f51d","f0f831d180e6415994db3a421bd8a8e6","a007188671664e19b9244ef62772e468","8e687629b2a14f039ae2665f095ef34f","e62c026c69044cc988a3d31df7f35cca","1242f936a54a4c048280b7cd1bd753ff","d7242668ec2d4f1f97cbcc308458d83e","984edaf6a8be4505a8362292692ec474","91ec98082d02417ea5310671ee9ecc44","53dcbaf6e89d4e0aa996a8e40e3828d4","044cdde97df34fb780c742730d0d29f9","42b857cdf32d4669ad8f180068a3e8e8","f37cdef7d4ac4754af78a3e0739cac19","a08ec4d2992143f4bef7f83bbe0682ec","fad162df46df4feba43cf1c047d05829","16592399f9cc472694a6480464c480a7","c9561c984c364872bb8fa7d9d381be6f","ffc9ad27532148819e4f866e036cbc42","841a7425158e428e8f63dfeacf7749f2","71aa44e2a41a4f90843f82d3fbc2132b","c9fa122edfd14287aee598bb3fcd0ba0","3eb4c448cff34cc4aa344fe460d3813a","d43b184f1e5a4a9cbbe22f3f6261b110","3022b3e0872b43ecb900d69acd0b000a","e4f397f6665b45afa3dfd1960ec834f7","449b8ff237f0488abcee530cd814df78","52e770a1fa454254ac0c89c4e4dd31af","dfc177c4c8cc46b887f50a325aabe850","e80c574c50e94a17af91b7b9a9d6b9e4","297507b6d38e45e29e96b70ad4a365ba"]},"id":"O0mbQwUxW_SG","executionInfo":{"status":"ok","timestamp":1662326292938,"user_tz":-60,"elapsed":21699,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"b4ecaafc-c786-4070-9458-c354f7725f81"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4a5ced34f5c46f58ca165095ad40cd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bfbc004c8534ce58f9554d8280b56d6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e46324d2113462595b135beede9edd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91ec98082d02417ea5310671ee9ecc44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71aa44e2a41a4f90843f82d3fbc2132b"}},"metadata":{}}]},{"cell_type":"code","source":["model.train_model(train_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtHjG41dXWLu","outputId":"b530ea1b-0a03-4c0d-e92d-69b331c756fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/simpletransformers/classification/classification_model.py:602: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n","  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"]}]},{"cell_type":"code","source":["result, model_outputs, wrong_predictions = model.eval_model(valid_df)"],"metadata":{"id":"C_iR2QiqXfy6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"ta9e_cEJWu1t"}},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"Rr4eOUsXYcFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"uJYNY8kvY3Q3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from wordcloud import WordCloud\n","\n","import pandas as pd\n","import random, time\n","from babel.dates import format_date, format_datetime, format_time\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","\n","import torch\n","from torch import Tensor\n","from torch import nn, optim\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn.functional as F\n","\n","import transformers, os\n","from transformers import BertModel, AutoModel, AdamW, get_linear_schedule_with_warmup, BertTokenizer, BertForSequenceClassification"],"metadata":{"id":"ZCs0qIAlY2H0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split test and train data using 25% of the dataset for validation purposes\n","x_train, x_test, y_train, y_test = train_test_split(df['clean_description','clean_text',], \n","                                                      df['gender'], test_size=0.2, shuffle=True, random_state=42)\n","\n","# Obtain a 10% test set from train set\n","X_train_Transformer, X_val_Transformer, y_train_Transformer, y_val_Transformer = train_test_split(\n","                                                    x_train, y_train, test_size=0.20, random_state=42)\n","\n","model_name = 'bert-base-uncased'\n","SEQ_LEN = 200\n","batch_size = 16\n","epochs = 5\n","learning_rate = 1e-5 # Controls how large a step is taken when updating model weights during training.\n","steps_per_epoch = 50\n","num_workers = 3\n","\n","def get_split(text1):\n","    '''Get split of the text with 200 char lenght'''\n","    l_total = []\n","    l_parcial = []\n","    if len(text1.split())//150 >0:\n","        n = len(text1.split())//150\n","    else: \n","        n = 1\n","    for w in range(n):\n","        if w == 0:\n","            l_parcial = text1.split()[:200]\n","            l_total.append(\" \".join(l_parcial))\n","        else:\n","            l_parcial = text1.split()[w*150:w*150 + 200]\n","            l_total.append(\" \".join(l_parcial))\n","    return str(l_total)\n","\n","# Splits train and validation sets to be feed to the transformer which only accepts 512 tokens maximum\n","split_train_text = [get_split(t) for t in X_train_Transformer]\n","split_valid_text = [get_split(t) for t in X_val_Transformer]\n","split_test_text = [get_split(t) for t in x_test]\n","\n","\n","# Load the RoBERTa tokenizer and tokenize the data\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n","\n","trencoding = tokenizer.batch_encode_plus(\n","  list(split_train_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","valencoding = tokenizer.batch_encode_plus(\n","  list(split_valid_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","\n","testencoding = tokenizer.batch_encode_plus(\n","  list(split_test_text),\n","  max_length=SEQ_LEN,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=True,\n","  truncation=True,\n","  padding='longest',\n","  return_attention_mask=True,\n",")\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(df['label'].values.tolist()), \n","                                 df['label'])\n","\n","#print(class_wts)\n","\n","# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","#cross_entropy  = nn.NLLLoss(weight=weights) \n","cross_entropy  = nn.CrossEntropyLoss(weight=weights)\n","\n","def loadData(prep_df, batch_size, num_workers, sampler):\n","    \n","    return  DataLoader(\n","            prep_df,\n","            batch_size=batch_size,\n","            num_workers=num_workers,\n","            sampler=sampler,\n","            pin_memory=True\n","        )\n","\n","## convert lists to tensors\n","train_seq = torch.tensor(trencoding['input_ids'])\n","train_mask = torch.tensor(trencoding['attention_mask'])\n","train_token_ids = torch.tensor(trencoding['token_type_ids'])\n","train_y = torch.tensor(y_train_Transformer.tolist())\n","\n","val_seq = torch.tensor(valencoding['input_ids'])\n","val_mask = torch.tensor(valencoding['attention_mask'])\n","val_token_ids = torch.tensor(valencoding['token_type_ids'])\n","val_y = torch.tensor(y_val_Transformer.tolist())\n","\n","test_seq = torch.tensor(testencoding['input_ids'])\n","test_mask = torch.tensor(testencoding['attention_mask'])\n","test_token_ids = torch.tensor(testencoding['token_type_ids'])\n","test_y = torch.tensor(y_test.tolist())\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_token_ids, train_y)\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","# Train Data Loader\n","traindata = loadData(train_data, batch_size, num_workers, train_sampler)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_token_ids, val_y)\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","# Val Data Loader\n","valdata = loadData(val_data, batch_size, num_workers, val_sampler)\n","\n","# wrap tensors\n","test_data = TensorDataset(test_seq, test_mask, test_token_ids, test_y)\n","# sampler for sampling the data during training\n","test_sampler = SequentialSampler(test_data)\n","# Val Data Loader\n","testdata = loadData(test_data, batch_size, num_workers, test_sampler)\n","\n","\n","print('Number of data in the train set', len(traindata))\n","print('Number of data in the validation set', len(valdata))\n","print('Number of data in the test set', len(testdata))\n","\n","class BERT_Arch(nn.Module):\n","    \n","    def __init__(self, n_classes, freeze_bert=False):\n","        \n","        super(BERT_Arch,self).__init__()\n","        # Instantiating BERT model object\n","        self.bert = BertModel.from_pretrained(model_name, return_dict=False)\n","        \n","        # Freeze bert layers\n","        if freeze_bert:\n","            for p in self.bert.parameters():\n","                p.requires_grad = False\n","                \n","        self.bert_drop_1 = nn.Dropout(0.3)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size) # (768, 64)\n","        self.bn = nn.BatchNorm1d(768) # (768)\n","        self.bert_drop_2 = nn.Dropout(0.25)\n","        self.out = nn.Linear(self.bert.config.hidden_size, n_classes) # (768,2)\n","\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        _, output = self.bert(\n","            input_ids = input_ids,\n","            attention_mask = attention_mask,\n","            token_type_ids = token_type_ids\n","        )\n","        output = self.bert_drop_1(output)\n","        output = self.fc(output)\n","        output = self.bn(output)\n","        output = self.bert_drop_2(output)\n","        output = self.out(output)        \n","        return output\n","\n","class_names = np.unique(df['label'])\n","print('Downloading the BERT custom model...')\n","model = BERT_Arch(len(class_names))\n","model.to(device) # Model to GPU.\n","\n","#optimizer parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","optimizer_parameters = [{'params': [p for n, p in param_optimizer \n","                                    if not any(nd in n for nd in no_decay)],'weight_decay':0.001},\n","                        {'params': [p for n, p in param_optimizer \n","                                    if any(nd in n for nd in no_decay)],'weight_decay':0.0}]\n","\n","print('Preparing the optimizer...')\n","#optimizer \n","optimizer = AdamW(optimizer_parameters, lr=learning_rate)\n","steps = steps_per_epoch\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = steps\n",")\n"],"metadata":{"id":"R2Ap835KYd2g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### TRAINING AND EVAL FUNCS"],"metadata":{"id":"rXGH7qfsas67"}},{"cell_type":"code","source":["# function to train the bert model\n","def trainBERT():\n","  \n","    print('Training...')\n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","\n","    # empty list to save model predictions\n","    total_preds=[]\n","\n","    # iterate over batches\n","    for step, batch in enumerate(traindata):\n","    \n","        # progress update after every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(traindata)))\n","\n","        if torch.cuda.is_available():\n","            # push the batch to gpu\n","            batch = [r.to(device) for r in batch]\n","\n","        sent_id, mask, token_type_ids, labels = batch\n","        # clear previously calculated gradients \n","        model.zero_grad()        \n","        # get model predictions for the current batch\n","        preds = model(sent_id, mask, token_type_ids)\n","        # compute the loss between actual and predicted values\n","        loss = cross_entropy(preds, labels)\n","        # add on to the total loss\n","        total_loss = total_loss + loss.item()\n","        # backward pass to calculate the gradients\n","        loss.backward()\n","        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        # update parameters\n","        optimizer.step()\n","        # model predictions are stored on GPU. So, push it to CPU\n","        preds=preds.detach().cpu().numpy()\n","        # append the model predictions\n","        total_preds.append(preds)\n","        \n","        torch.cuda.empty_cache()\n","\n","    # compute the training loss of the epoch\n","    avg_loss = total_loss / len(traindata)\n","\n","    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    #returns the loss and predictions\n","    return avg_loss, total_preds\n","\n","# function for evaluating the model\n","def evaluate():\n","  \n","    print(\"\\nEvaluating...\")\n","    t0 = time.time()\n","    \n","    model.eval() # deactivate dropout layers\n","    total_loss, total_accuracy = 0, 0\n","    \n","    # empty list to save the model predictions\n","    total_preds = []\n","\n","    # iterate over batches\n","    for step, batch in enumerate(valdata):\n","        # Progress update every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(valdata)))\n","\n","        if torch.cuda.is_available():\n","            # push the batch to gpu\n","            batch = [t.to(device) for t in batch]\n","\n","        sent_id, mask, token_type_ids, labels = batch\n","\n","        # deactivate autograd\n","        with torch.no_grad(): # Dont store any previous computations, thus freeing GPU space\n","\n","            # model predictions\n","            preds = model(sent_id, mask, token_type_ids)\n","            # compute the validation loss between actual and predicted values\n","            loss = cross_entropy(preds, labels)\n","            total_loss = total_loss + loss.item()\n","            preds = preds.detach().cpu().numpy()\n","            total_preds.append(preds)\n","\n","        torch.cuda.empty_cache()\n","    # compute the validation loss of the epoch\n","    avg_loss = total_loss / len(valdata) \n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    return avg_loss, total_preds"],"metadata":{"id":"yYVrmY1Caufd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# Empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","# for each epoch perform training and evaluation\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = trainBERT()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    print('Evaluation done for epoch {}'.format(epoch + 1))\n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        print('Saving model...')\n","        torch.save(model.state_dict(), 'bert_weights.pt') # Save model weight's (you can also save it in .bin format)\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"metadata":{"id":"x-P9e0rNazSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('\\nTest Set...')\n","\n","test_preds = []\n","\n","print('Total batches:', len(testdata))\n","\n","for fold_index in range(0, 3):\n","    \n","    print('\\nFold Model', fold_index)\n","    \n","    # Load the fold model\n","    path_model = 'bert_weights.pt'\n","    model.load_state_dict(torch.load(path_model))\n","\n","    # Send the model to the GPU\n","    model.to(device)\n","\n","    stacked_val_labels = []\n","    \n","    # Put the model in evaluation mode.\n","    model.eval()\n","\n","    # Turn off the gradient calculations.\n","    # This tells the model not to compute or store gradients.\n","    # This step saves memory and speeds up validation.\n","    torch.set_grad_enabled(False)\n","\n","\n","    # Reset the total loss for this epoch.\n","    total_val_loss = 0\n","\n","    for j, test_batch in enumerate(testdata):\n","\n","        inference_status = 'Batch ' + str(j + 1)\n","\n","        print(inference_status, end='\\r')\n","\n","        b_input_ids = test_batch[0].to(device)\n","        b_input_mask = test_batch[1].to(device)\n","        b_token_type_ids = test_batch[2].to(device)\n","        b_test_y = test_batch[3].to(device)\n","\n","\n","        outputs = model(b_input_ids, \n","                        attention_mask=b_input_mask,\n","                        token_type_ids=b_token_type_ids)\n","\n","        # Get the preds\n","        preds = outputs[0]\n","\n","        # Move preds to the CPU\n","        val_preds = preds.detach().cpu().numpy()\n","        \n","        #true_labels.append(b_test_y.to('cpu').numpy().flatten())\n","        \n","        # Stack the predictions.\n","        if j == 0:  # first batch\n","            stacked_val_preds = val_preds\n","            \n","        else:\n","            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n","            \n","    test_preds.append(stacked_val_preds)\n","    \n","            \n","print('\\nPrediction complete.')"],"metadata":{"id":"pOGH5-EYa-8w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sum the predictions of all fold models\n","for i, item in enumerate(test_preds):\n","    if i == 0:\n","        preds = item\n","    else:\n","        # Sum the matrices\n","        preds = item + preds\n","\n","# Average the predictions\n","avg_preds = preds/(len(test_preds))\n","\n","#print(preds)\n","#print()\n","#print(avg_preds)\n","\n","# Take the argmax. \n","# This returns the column index of the max value in each row.\n","test_predictions = np.argmax(avg_preds, axis=1)\n","\n","true_y = []\n","for j, test_batch in enumerate(testdata):\n","    true_y.append(int(test_batch[3][0].numpy().flatten()))\n","print(true_y)\n","\n","# Accuracy and classification report \n","target_names = ['true_y', 'predicted_y']\n","\n","data = {'true_y': true_y,\n","       'predicted_y': test_predictions}\n","\n","df_pred_BERT = pd.DataFrame(data, columns=['true_y','predicted_y'])\n","\n","confusion_matrix = pd.crosstab(df_pred_BERT['true_y'], df_pred_BERT['predicted_y'], rownames=['True'], colnames=['Predicted'])\n","\n","sns.heatmap(confusion_matrix, annot=True)\n","plt.show()\n","\n","print('----')\n","print('Accuracy of BERT model', accuracy_score(true_y, test_predictions))\n","print('----')\n","\n","print(classification_report(true_y, test_predictions, target_names=target_names))"],"metadata":{"id":"1Z7RCNb3bFcQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ROBERTA NOT SIMPLE"],"metadata":{"id":"3ToMhp1CYX5I"}},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"FnHdjBbn4wrw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662326096460,"user_tz":-60,"elapsed":5206,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"212dad39-64ec-4e6b-cbc4-f1069c8a88c5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import json, re\n","from tqdm import tqdm_notebook\n","from uuid import uuid4\n","\n","## Torch Modules\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","import transformers"],"metadata":{"id":"qE5O1ICp5LhX","executionInfo":{"status":"ok","timestamp":1662315237604,"user_tz":-60,"elapsed":24,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# loading pre-trained models\n","from transformers import (\n","    BertForSequenceClassification,\n","#     TFBertForSequenceClassification, \n","                          BertTokenizer,\n","#                           TFRobertaForSequenceClassification,\n","                          RobertaForSequenceClassification,\n","                          RobertaTokenizer,\n","                         AdamW)\n","\n","# Get the lists of sentences and labels\n","sentences = df['text'].values\n","labels = df['gender'].values\n","labels = [int(l) for l in labels]\n","\n","# RoBERTa\n","roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", # 12-layer, 768-hidden, 12-heads, 125M parameters RoBERTa using the BERT-base architecture\n","                                                                    num_labels = 2, # The number of output labels--2 for binary classification.\n","                                                                                    # You can increase this for multi-class tasks.   \n","                                                                    output_attentions = False, # Whether the model returns attentions weights.\n","                                                                    output_hidden_states = False # Whether the model returns all hidden-states.\n","                                                                )\n","roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","# Tell pytorch to run this model on the GPU.\n","roberta_model.cuda()\n","\n","print(' Base models loaded')\n","\n","max_len_bert = 0\n","max_len_roberta = 0\n","\n","# For every sentence...\n","for sent in sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids_roberta = roberta_tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len_roberta = max(max_len_roberta, len(input_ids_roberta))\n","\n","print('Max sentence length RoBERTa: ', max_len_roberta)\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","roberta_input_ids = []\n","roberta_attention_masks = []\n","sentence_ids = []\n","counter = 0\n","\n","# For every sentence...\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.   \n","    \n","    roberta_encoded_dict = roberta_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 120,           # Pad & truncate all sentences.\n","                        truncation = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    # Add the encoded sentence to the list.    \n","    roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n","    \n","    # collecting sentence_ids\n","    sentence_ids.append(counter)\n","    counter  = counter + 1\n","    \n","# Convert the lists into tensors.\n","\n","roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n","roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n","\n","labels = torch.tensor(labels)\n","sentence_ids = torch.tensor(sentence_ids)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[1])\n","print('Token IDs RoBERTa:', roberta_input_ids[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519,"referenced_widgets":["25daca2230ed4996a4eb376745258c2c","174c2264dde745b2aa13686a9efbfd43","eec227ae3a574e918bc30bb39ff96a29","c72cb4cd7b064230b6322ebdbf4ed464","c0ca6403ee52451fb4263e4ef5ee75c1","1be74d1d020a4faabe72142f1e2c49ff","e045a176e827448892c3108df0086476","9f378b8c52b84d49be20ab6eed15a720","96d489631a9641b4a859fa3dd196d64c","6640bc287fe542d8b6aedeb2016bf689","f77aa13e86c74cb39fab0771e71110b5","33c2f9000699460297974da0c41de9cd","8c48c28a50f44bfba8a2373e25c8fb8c","bf7d1e889cf140c8a6e2337bac1a68af","dd622ada44634b2491104e074e8af3ae","a325f62544944ddbbd08cb7132483952","056b286cd6054863adae3d2ca38f4190","1deb244ed774410eaa506185194e8e57","fbf8304925b74ee1aeadf5e48bc398ba","71165554eb254190b6e75bc4be59d324","f316e005c2c744e6ac0ece75654b925a","2a819ba59567451b8ccd0ae8b309c944","e4e2387a545548f2b73ee6418b616cc3","5e68e98b600d475abf29bcd52b4e7a92","143fd23f8c0d46c7b2f93c531066a6be","162714e1ffbe486bad6d16ead26c126f","c536a98664e44bdbbc899ffe16a0cc2c","6d09bdaf92d640cf8388bc082f91a98e","e2a0c2f4942846f486a2bab67a9baf35","5b1a0df2e71845388e236d4adc06bcb4","3c0997f517fa41e6919cf14fbf42d3ae","e8d05ed192b1467db20567ddc609f120","44811bfaea4e42ce87db295aad70a062","58e6911186d8447098bc1a3c011d844e","bc92d55b82004d6fb0c66d12fd57bba4","05226951390b4b08ad80afa8e5adcbe8","d15154e6bf19417d823f5685a9ac21c9","8ab6143bee104912b28fb71c5e4562cc","e6fadb9016c64f6690f9854635a35d7b","e8fd77311bfe4ce3aea56aa458fe556b","2d2fb620c2a14cd7b647faf7e347d95e","d9b503b630a7465a9aa66da4b51921ca","ef881af37a574b4e8e2688ee5c259285","98683b5e7afc44da9b548a9da620b3d4"]},"id":"5rA2P2-iHkdA","executionInfo":{"status":"error","timestamp":1662315267455,"user_tz":-60,"elapsed":27480,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"eea496f0-1eea-4deb-89e3-fa54d2b237a6"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25daca2230ed4996a4eb376745258c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c2f9000699460297974da0c41de9cd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e2387a545548f2b73ee6418b616cc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58e6911186d8447098bc1a3c011d844e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Base models loaded\n","Max sentence length RoBERTa:  487\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-998b9d84329f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Convert the lists into tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mroberta_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mroberta_attention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_attention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 35 but got size 59 for tensor number 1 in the list."]}]},{"cell_type":"code","source":["% ------------------------------------------------------------------------------\n","\n","from torch.utils.data import TensorDataset, random_split\n","# function to seed the script globally\n","torch.manual_seed(0)\n","\n","# Combine the training inputs into a TensorDataset.\n","roberta_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks, labels)\n","\n","# function to remove sentice ids from the tensor dataset post train test split\n","def index_remover(tensordata):\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","   \n","    for a,b,c,d in tensordata:\n","        input_ids.append(b.tolist())\n","        attention_masks.append(c.tolist())\n","        labels.append(d.tolist())\n","        \n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","    labels = torch.tensor(labels)\n","    \n","    final_dataset =  TensorDataset(input_ids, attention_masks, labels)\n","    return final_dataset\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(roberta_dataset))\n","val_size = len(roberta_dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","roberta_train_dataset, roberta_val_dataset = random_split(roberta_dataset, [train_size, val_size])\n","\n","# removing sentence ids from tensor dataset so that it can be used for training \n","roberta_train_dataset = index_remover(roberta_train_dataset)\n","roberta_val_dataset = index_remover(roberta_val_dataset)\n","\n","# Checking whether the distribution of target is consitent across both the sets\n","label_temp_list = []\n","for a,b,c in roberta_train_dataset:\n","  label_temp_list.append(c)\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} training samples with real disater tweets'.format(sum(label_temp_list)))\n","\n","\n","label_temp_list = []\n","for a,b,c in roberta_val_dataset:\n","  label_temp_list.append(c)\n","\n","print('{:>5,} validation samples'.format(val_size))\n","print('{:>5,} validation samples with real disater tweets'.format(sum(label_temp_list)))\n","\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","roberta_train_dataloader = DataLoader(\n","            roberta_train_dataset,  # The training samples.\n","            sampler = RandomSampler(roberta_train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","roberta_validation_dataloader = DataLoader(\n","            roberta_val_dataset, # The validation samples.\n","            sampler = SequentialSampler(roberta_val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n","\n","# Get all of the roberta_model's parameters as a list of tuples.\n","params = list(roberta_model.named_parameters())\n","\n","print('The RoBERTa model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","roberta_optimizer = AdamW(roberta_model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 2,I have already seen that the model starts overfitting beyound 2 epochs\n","epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(roberta_train_dataloader) * epochs\n","\n","# Create the learning rate scheduler\n","roberta_scheduler = get_linear_schedule_with_warmup(roberta_optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","\n","import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","\n","import random\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 100\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","roberta_training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the roberta_model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-roberta_model-train-do-in-pytorch)\n","    roberta_model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(roberta_train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(roberta_train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        roberta_model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the roberta_model on this training batch).\n","        # The documentation for this `roberta_model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/roberta_model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # are given and what flags are set. For our usage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the roberta_model\n","        # outputs prior to activation.\n","        loss, logits = roberta_model(b_input_ids, \n","#                              token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The roberta_optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        roberta_optimizer.step()\n","\n","        # Update the learning rate.\n","        roberta_scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(roberta_train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the roberta_model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    roberta_model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in roberta_validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # Get the \"logits\" output by the roberta_model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = roberta_model(b_input_ids, \n","#                                    token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(roberta_validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(roberta_validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    roberta_training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n","\n","import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=roberta_training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"id":"-4ZCgD-95MQF","colab":{"base_uri":"https://localhost:8080/","height":866},"executionInfo":{"status":"error","timestamp":1662288370141,"user_tz":-60,"elapsed":18251,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"72ac7092-f450-46a0-ebb0-0cbd3041af4f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'str'>\n","<class 'int'>\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":[" Base models loaded\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Max sentence length BERT:  487\n","Max sentence length RoBERTa:  487\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:  ÛÏIt felt like they were my friends and I was living the story with themÛ https://t.co/arngE0YHNO #retired #IAN1 https://t.co/CIzCANPQFz\n","Token IDs RoBERTa: tensor([    0,  4056, 23171, 49506,  3849,  9357,   243,  1299,   101,    51,\n","           58,   127,   964,     8,    38,    21,  1207,     5,   527,    19,\n","          106,  4056, 23171, 49506,  4056,    46,  1205,   640,    90,     4,\n","          876,    73,   271,  2590,   717,   288,   975,   725, 13449,   849,\n","         4903,  7651,   849, 10296,   134,  1205,   640,    90,     4,   876,\n","           73, 21701,   329, 31448,   510,  1864,   597,   329,     2,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-03848e8144c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m# removing sentence ids from tensor dataset so that it can be used for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mroberta_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_remover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0mroberta_val_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_remover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_val_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-03848e8144c0>\u001b[0m in \u001b[0;36mindex_remover\u001b[0;34m(tensordata)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensordata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mattention_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"]}]},{"cell_type":"markdown","source":["## Cleaning the Twitter Data"],"metadata":{"id":"v14CuYe64g8A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkHBbtn3z0aF"},"outputs":[],"source":["df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zHNuOf0yox6"},"outputs":[],"source":["# df.drop(['description','text'],axis=1,inplace=True)\n","# df.head()\n","\n","cv = CountVectorizer(max_features = 2000)\n","\n","x = cv.fit_transform(df['clean_description']).toarray()\n","\n","x1 = cv.fit_transform(df['clean_text']).toarray()\n","\n","A=pd.DataFrame(x)\n","B=pd.DataFrame(x1)\n","\n","X= pd.concat([B, A], join = 'outer', axis = 1)\n","\n","\n","df['gender'].isnull().sum()\n","\n","df['gender'].fillna(df['gender'].mode()[0], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4ftGnt6z0aM"},"outputs":[],"source":["x = np.array(X)\n","y = np.array(df['gender'])\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 0)"]},{"cell_type":"markdown","source":["## XGBOOST"],"metadata":{"id":"JaZLJ5dgBJdS"}},{"cell_type":"code","source":["import pickle\n","\n","xgbmodel = XGBClassifier(max_depth=5, min_child_weight=1)\n","xgbmodel.fit(X_train, y_train)\n","\n","y_pred2 = xgbmodel.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2)"],"metadata":{"id":"FEyD8ivnBjjM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662243575359,"user_tz":-60,"elapsed":153854,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"b62bcefd-cab2-4f8d-fb45-8cec1fcdccb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 69.80%\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[2091,   54],\n","       [ 926,  174]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["filename = 'user_gender_class/model/my_xgb_gender.joblib'\n","joblib.dump(xgbmodel, filename)"],"metadata":{"id":"yqaVurSFNxZR","executionInfo":{"status":"ok","timestamp":1662234769253,"user_tz":-60,"elapsed":506,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c41622d-23e4-4daa-ec05-5b1234399691"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['user_gender_class/model/my_xgb_gender.joblib']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# xgbmodel.save_model('user_gender_class/model/xgb_gender.json')\n","# filename = 'user_gender_class/model/xgb_gender.json'\n","# # pickle.dump(xgbmodel, open(filename, 'wb'))"],"metadata":{"id":"NIQk1TTrH-Co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(y_pred2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apSn78-VeCHe","executionInfo":{"status":"ok","timestamp":1662210566074,"user_tz":-60,"elapsed":10,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"a8fb7028-ec07-4721-a7f6-4e18e245bbde"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3245"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["xmodel = pickle.load(open(filename, 'rb'))\n","\n","y_pred2 = xmodel.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWM7K4_0L28z","executionInfo":{"status":"ok","timestamp":1662208970890,"user_tz":-60,"elapsed":899,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"47ec9fc7-8462-4761-e303-93383ebccc8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 69.31%\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[2094,   51],\n","       [ 945,  155]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["from xgboost import DMatrix\n","\n","xmodel = XGBClassifier(max_depth=5, min_child_weight=1)\n","booster = Booster()\n","booster.load_model('user_gender_class/model/xgb_gender.json')\n","xmodel._Booster = booster\n","\n","y_pred2 = xmodel.predict(DMatrix(X_test))\n","\n","accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2)"],"metadata":{"id":"5L89FdDwBlwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## FINDING BEST XGB\n","\n","xgb_param_grid = {\n","              \"max_depth\": [3, 5],\n","              \"min_child_weight\": [1, 2],\n","              }\n","\n","xgbgrid = GridSearchCV(estimator = xgbmodel, param_grid = xgb_param_grid, cv = 3, n_jobs = -1, verbose = 0)\n","\n","xgbgrid.fit(X_train, y_train)\n","\n","xgbgrid.best_params_\n","\n","y_pred2_hyper = xgbgrid.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred2_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","\n","confusion_matrix(y_test, y_pred2_hyper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwR0l2ZeQmrt","executionInfo":{"status":"ok","timestamp":1662222412342,"user_tz":-60,"elapsed":383456,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"6ffe05e9-d0ec-496b-a01b-b89f69ceb696"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 69.46%\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[2093,   52],\n","       [ 939,  161]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## UNNEEDED CODE"],"metadata":{"id":"Z8F8krfMBFvR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"f32VaDp1z0aM"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnbmodel = GaussianNB()\n","gnbmodel.fit(X_train , y_train)\n","# GaussianNB()\n","# from sklearn.naive_bayes import GaussianNB\n","y_pred = gnbmodel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XDyw5qIJz0aM","outputId":"264593eb-8a2f-44c3-f788-70bb67c5dbb1"},"outputs":[{"data":{"text/plain":["3245"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["len(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8UtG9posz0aM","outputId":"537e19e7-9db8-499b-b568-38c6be7d425f"},"outputs":[{"data":{"text/plain":["3245"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["len(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVMykq9Tz0aN"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4JBpOFQz0aN","outputId":"a3241155-4f90-44dd-89a0-68ac89bb7b19"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 52.05%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCZZGfDbz0aN","outputId":"e628035c-8b10-4283-b6d9-6f7fa4dc0bb7"},"outputs":[{"data":{"text/plain":["array([[ 759, 1386],\n","       [ 170,  930]], dtype=int64)"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"muPiCjpIz0aN","outputId":"5a34e42e-25fd-4bf5-83a8-7f022fc1ccf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.35      0.49      2145\n","           1       0.40      0.85      0.54      1100\n","\n","    accuracy                           0.52      3245\n","   macro avg       0.61      0.60      0.52      3245\n","weighted avg       0.68      0.52      0.51      3245\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgztz0DCz0aN"},"outputs":[],"source":["param_grid_nb = {\n","    'var_smoothing': np.logspace(0,-9, num=100)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDfxHLr6z0aN","outputId":"ad9f3644-aa71-4008-9814-287565bc975e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.7s\n","[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n","[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.9min finished\n"]},{"data":{"text/plain":["GridSearchCV(cv=3, estimator=GaussianNB(), n_jobs=-1,\n","             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n","       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n","       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n","       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n","       3.51119173e-02, 2.8480358...\n","       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n","       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n","       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n","       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n","       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n","       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n","             verbose=1)"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.naive_bayes import GaussianNB\n","from sklearn.model_selection import GridSearchCV\n","nbModel_grid = GridSearchCV(estimator=gnbmodel, param_grid=param_grid_nb, verbose=1, cv=3, n_jobs=-1)\n","nbModel_grid.fit(X_train, y_train)\n","#print(nbModel_grid.best_estimator_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ny4EG_jaz0aO","outputId":"5d68c1e9-0bd7-4e20-fb1f-ef53a0bf1dba"},"outputs":[{"data":{"text/plain":["{'var_smoothing': 0.02310129700083159}"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["nbModel_grid.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZSF8hL-kz0aO"},"outputs":[],"source":["y_pred_hyper = nbModel_grid.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etU5UUPOz0aO","outputId":"85b29d36-d3c3-427d-ad02-9388ed4d11dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1015 1130]\n"," [ 245  855]] : is the confusion matrix\n","Accuracy: 57.63%\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","print(confusion_matrix(y_test, y_pred_hyper), \": is the confusion matrix\")\n","from sklearn.metrics import accuracy_score\n","accuracy_gnb_hyper = accuracy_score(y_test, y_pred_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy_gnb_hyper * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-7f3Gh7z0aO","outputId":"f02334a7-c921-44a3-9c7a-667ef2e4b8d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.47      0.60      2145\n","           1       0.43      0.78      0.55      1100\n","\n","    accuracy                           0.58      3245\n","   macro avg       0.62      0.63      0.58      3245\n","weighted avg       0.68      0.58      0.58      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred_hyper))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0vEq2m3Yz0aO"},"outputs":[],"source":["confusion_matrix(y_test, y_pred_hyper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcnTqdI0z0aP","outputId":"532efa0b-31dd-465b-ed3c-b537051a79a9"},"outputs":[{"data":{"text/plain":["LGBMClassifier(max_depth=3)"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["lgbmodel = LGBMClassifier(max_depth=3)\n","lgbmodel.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MSqnsmWz0aP"},"outputs":[],"source":["y_pred1= lgbmodel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4FyEwhbz0aP","outputId":"8f62d795-6ff8-445b-a9e9-8f0bddc00326"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 68.81%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred1)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdKyrmtYz0aP"},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Zd3omQXLz0aP","outputId":"a7af7ceb-9041-4c73-f5c8-2e12a49acfff"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.98      0.81      2145\n","           1       0.77      0.11      0.20      1100\n","\n","    accuracy                           0.69      3245\n","   macro avg       0.73      0.55      0.50      3245\n","weighted avg       0.71      0.69      0.60      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9hiSk3iz0aP"},"outputs":[],"source":["param_grid = {\n","              \"max_depth\": [2, 3, 5, 10],\n","              \"min_child_weight\": [0.001, 0.002],\n","              \"learning_rate\": [0.05, 0.1]\n","              }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abtUgzC7z0aP","outputId":"c0b9410d-baaf-4cf0-d8b3-92122524c9e4"},"outputs":[{"data":{"text/plain":["GridSearchCV(cv=3, estimator=LGBMClassifier(max_depth=3), n_jobs=-1,\n","             param_grid={'learning_rate': [0.05, 0.1],\n","                         'max_depth': [2, 3, 5, 10],\n","                         'min_child_weight': [0.001, 0.002]})"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["lgbgrid = GridSearchCV(estimator = lgbmodel, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 0)\n","\n","lgbgrid.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KIgFr944z0aQ","outputId":"db3c5899-9c0a-4a53-e2b9-3e917b3e51a7"},"outputs":[{"data":{"text/plain":["{'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 0.001}"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["lgbgrid.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6A0i6Vx7z0aQ"},"outputs":[],"source":["y_pred1_hyper = lgbgrid.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubNCKq9Jz0aQ","outputId":"313be6ac-a83d-4b35-ab26-cb78a54555f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 69.89%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred1_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMStQch7z0aQ","outputId":"7d9ede82-bca4-4aaa-a802-bd9043358c98"},"outputs":[{"data":{"text/plain":["array([[2068,   77],\n","       [ 900,  200]], dtype=int64)"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred1_hyper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W227L-dgz0aQ","outputId":"fd2491b1-9907-45f0-97e8-29ce15261cd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.96      0.81      2145\n","           1       0.72      0.18      0.29      1100\n","\n","    accuracy                           0.70      3245\n","   macro avg       0.71      0.57      0.55      3245\n","weighted avg       0.71      0.70      0.63      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred1_hyper))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fWHG_E2z0aR","outputId":"1b6b972e-601a-4133-dd90-502055a0de94"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[15:06:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n","              importance_type='gain', interaction_constraints='',\n","              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n","              min_child_weight=1, missing=nan, monotone_constraints='()',\n","              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n","              tree_method='exact', validate_parameters=1, verbosity=None)"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["xgbmodel = XGBClassifier(max_depth=5, min_child_weight=1)\n","xgbmodel.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPPNsYlZz0aR"},"outputs":[],"source":["y_pred2 = xgbmodel.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pC4-eFW8z0aR","outputId":"8b639a1f-8641-49dc-ce17-139b50574fb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 70.35%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred2)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edNku7qSz0aR","outputId":"c20e3f61-f37a-4676-b65f-bb903bfb2045"},"outputs":[{"data":{"text/plain":["array([[2051,   94],\n","       [ 868,  232]], dtype=int64)"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48XdXBstz0aR","outputId":"7011f1d5-0e29-4f76-d39a-39802320262e"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.96      0.81      2145\n","           1       0.71      0.21      0.33      1100\n","\n","    accuracy                           0.70      3245\n","   macro avg       0.71      0.58      0.57      3245\n","weighted avg       0.71      0.70      0.65      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRdZLK3uz0aR"},"outputs":[],"source":["xgb_param_grid = {\n","              \"max_depth\": [3, 5],\n","              \"min_child_weight\": [1, 2],\n","              }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPtXNjewz0aS","outputId":"2fadfc06-d12c-4250-ad37-d810a8a1cec7"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[15:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n","                                     colsample_bylevel=1, colsample_bynode=1,\n","                                     colsample_bytree=1, gamma=0, gpu_id=-1,\n","                                     importance_type='gain',\n","                                     interaction_constraints='',\n","                                     learning_rate=0.300000012,\n","                                     max_delta_step=0, max_depth=5,\n","                                     min_child_weight=1, missing=nan,\n","                                     monotone_constraints='()',\n","                                     n_estimators=100, n_jobs=4,\n","                                     num_parallel_tree=1, random_state=0,\n","                                     reg_alpha=0, reg_lambda=1,\n","                                     scale_pos_weight=1, subsample=1,\n","                                     tree_method='exact', validate_parameters=1,\n","                                     verbosity=None),\n","             n_jobs=-1,\n","             param_grid={'max_depth': [3, 5], 'min_child_weight': [1, 2]})"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["xgbgrid = GridSearchCV(estimator = xgbmodel, param_grid = xgb_param_grid, cv = 3, n_jobs = -1, verbose = 0)\n","\n","xgbgrid.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yohqQ13Qz0aS","outputId":"48632253-23c5-476c-f725-98bc45330602"},"outputs":[{"data":{"text/plain":["{'max_depth': 5, 'min_child_weight': 1}"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["xgbgrid.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6pINMg1Dz0aS"},"outputs":[],"source":["y_pred2_hyper = xgbgrid.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJ-wrTNsz0aS","outputId":"7a2a9cfa-871c-4ab6-c9e7-ef473d959465"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 70.35%\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred2_hyper)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuhaWAp4z0aS","outputId":"0b2f6937-2953-4fc7-90d9-4704b9361e77"},"outputs":[{"data":{"text/plain":["array([[2051,   94],\n","       [ 868,  232]], dtype=int64)"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(y_test, y_pred2_hyper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCcJXGIdz0aS"},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bb6RCrNiz0aT","outputId":"470d4e2a-272f-4f4c-d10d-7cf2d23581b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.96      0.81      2145\n","           1       0.71      0.21      0.33      1100\n","\n","    accuracy                           0.70      3245\n","   macro avg       0.71      0.58      0.57      3245\n","weighted avg       0.71      0.70      0.65      3245\n","\n"]}],"source":["print(classification_report(y_test, y_pred2_hyper))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkQQDbvmz0aT"},"outputs":[],"source":["#from sklearn.metrics import roc_curve,roc_auc_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HB0ukzH7z0aT"},"outputs":[],"source":["# nb_probs =classifier.predict_proba(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HAEUG0cz0aT"},"outputs":[],"source":["# nb_probs=nb_probs[:,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"du8t6Z9iz0aT"},"outputs":[],"source":["# nb_auc = roc_auc_score(y_test, nb_probs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0mAuF7uz0aT","outputId":"6e0cf421-85aa-4d6b-9902-00dc1aa2333c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gaussian: AUROC = 0.582\n"]}],"source":["# print('Gaussian: AUROC = %.3f' % (nb_auc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3hEkdZ1z0aU","outputId":"254790c3-1b83-469b-d821-5c404e96ae40"},"outputs":[{"data":{"text/plain":["array(['1', '0', '1', ..., '0', '0', '1'], dtype=object)"]},"execution_count":132,"metadata":{},"output_type":"execute_result"}],"source":["# y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KU8H30Quz0aU","outputId":"75f0815b-ed73-44b4-ca23-d726ed04a6ff"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n","  UndefinedMetricWarning)\n"]}],"source":["# nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_probs,pos_label=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEbopn-kz0aU","outputId":"e4c518e3-06c1-4dbe-fd76-f323279b10d9"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0xc42a540f08>]"]},"execution_count":131,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# plt.plot(nb_fpr, nb_tpr, marker='.', label='Gaussian (AUROC = %0.3f)' % nb_auc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsUF4lnTz0aU","outputId":"bbeddfa9-16b9-4e36-b5e2-a4d270faf77f"},"outputs":[{"data":{"text/plain":["(16224, 24000)"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["# X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1EqP-18-z0aU","outputId":"f2576726-d037-4881-89f5-f0c8986cd6cb"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ANANDA CHATTERJEE\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n","  UndefinedMetricWarning)\n"]}],"source":["# fpr1, tpr1,thresh1 =roc_curve(y_test, pred_prob1[:,1],pos_label=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZdAe7lYz0aV","outputId":"5ec9fbbe-47b7-4305-e437-e1b5ba147dfa"},"outputs":[{"data":{"text/plain":["array([nan, nan, nan])"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["# tpr1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rN8jtZwz0aV"},"outputs":[],"source":["# import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlEO4oYbz0aV","outputId":"f1176cc4-a1c8-4c34-b48e-3eaec5fa390a"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0xc4010c2708>]"]},"execution_count":114,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Gaussian')"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["3ToMhp1CYX5I","v14CuYe64g8A","JaZLJ5dgBJdS","Z8F8krfMBFvR"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3.9.7 ('env-pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"59556fecfb9e1650310a175ca5cd58c0b942341d9e7f74cbfe1ccb958d377f3d"}},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e4a5ced34f5c46f58ca165095ad40cd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_184b522287ff45238635f4a1d9eb757e","IPY_MODEL_025b7940acb4423cb38c3c5b68d27f63","IPY_MODEL_6eabc0d5bf7b47b7a089d16bd9759bf4"],"layout":"IPY_MODEL_e50b988e4ae643428368d032087e5155"}},"184b522287ff45238635f4a1d9eb757e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3c48789abdf448ca103cae57581a197","placeholder":"​","style":"IPY_MODEL_f57ec88587034553aa453db4bf607079","value":"Downloading config.json: 100%"}},"025b7940acb4423cb38c3c5b68d27f63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_632855bfa1ec45c588318a8c0b462b65","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_554da9014d164eaebc61561b38c950e1","value":481}},"6eabc0d5bf7b47b7a089d16bd9759bf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4260a6b4efa34546865df129dd310ad9","placeholder":"​","style":"IPY_MODEL_a4deefd3771e4cd597a8f3d58824b2b6","value":" 481/481 [00:00&lt;00:00, 12.8kB/s]"}},"e50b988e4ae643428368d032087e5155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c48789abdf448ca103cae57581a197":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f57ec88587034553aa453db4bf607079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"632855bfa1ec45c588318a8c0b462b65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"554da9014d164eaebc61561b38c950e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4260a6b4efa34546865df129dd310ad9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4deefd3771e4cd597a8f3d58824b2b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bfbc004c8534ce58f9554d8280b56d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_653ffa25927a4a80b0dc919f6d712f26","IPY_MODEL_c2aac61a665c4ef890926aec2ea1b4e0","IPY_MODEL_78bae6d4408c4dceaebda81148a48f06"],"layout":"IPY_MODEL_582beae7e972482d988533501efcc700"}},"653ffa25927a4a80b0dc919f6d712f26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9299f27d983e4901abacf9abe0171768","placeholder":"​","style":"IPY_MODEL_346c2dcc06f7408d8e120a39cb41d167","value":"Downloading pytorch_model.bin: 100%"}},"c2aac61a665c4ef890926aec2ea1b4e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f4013d5f5b44f06800567b5abad61ff","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09abef4e77314c96a562645cd7c67679","value":501200538}},"78bae6d4408c4dceaebda81148a48f06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_983c62088d67468fb1edca16a879b74d","placeholder":"​","style":"IPY_MODEL_d9799c2428f9473abcd53d66eaed64ae","value":" 478M/478M [00:12&lt;00:00, 40.7MB/s]"}},"582beae7e972482d988533501efcc700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9299f27d983e4901abacf9abe0171768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"346c2dcc06f7408d8e120a39cb41d167":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f4013d5f5b44f06800567b5abad61ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09abef4e77314c96a562645cd7c67679":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"983c62088d67468fb1edca16a879b74d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9799c2428f9473abcd53d66eaed64ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e46324d2113462595b135beede9edd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9694015f88964b29a09708c3bd297ab4","IPY_MODEL_d2a38192ac224b2f919e2c041c5c97f8","IPY_MODEL_cb483e6281894b1288783bf8eb44f51d"],"layout":"IPY_MODEL_f0f831d180e6415994db3a421bd8a8e6"}},"9694015f88964b29a09708c3bd297ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a007188671664e19b9244ef62772e468","placeholder":"​","style":"IPY_MODEL_8e687629b2a14f039ae2665f095ef34f","value":"Downloading vocab.json: 100%"}},"d2a38192ac224b2f919e2c041c5c97f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e62c026c69044cc988a3d31df7f35cca","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1242f936a54a4c048280b7cd1bd753ff","value":898823}},"cb483e6281894b1288783bf8eb44f51d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7242668ec2d4f1f97cbcc308458d83e","placeholder":"​","style":"IPY_MODEL_984edaf6a8be4505a8362292692ec474","value":" 878k/878k [00:00&lt;00:00, 2.06MB/s]"}},"f0f831d180e6415994db3a421bd8a8e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a007188671664e19b9244ef62772e468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e687629b2a14f039ae2665f095ef34f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e62c026c69044cc988a3d31df7f35cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1242f936a54a4c048280b7cd1bd753ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7242668ec2d4f1f97cbcc308458d83e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"984edaf6a8be4505a8362292692ec474":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91ec98082d02417ea5310671ee9ecc44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53dcbaf6e89d4e0aa996a8e40e3828d4","IPY_MODEL_044cdde97df34fb780c742730d0d29f9","IPY_MODEL_42b857cdf32d4669ad8f180068a3e8e8"],"layout":"IPY_MODEL_f37cdef7d4ac4754af78a3e0739cac19"}},"53dcbaf6e89d4e0aa996a8e40e3828d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a08ec4d2992143f4bef7f83bbe0682ec","placeholder":"​","style":"IPY_MODEL_fad162df46df4feba43cf1c047d05829","value":"Downloading merges.txt: 100%"}},"044cdde97df34fb780c742730d0d29f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16592399f9cc472694a6480464c480a7","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9561c984c364872bb8fa7d9d381be6f","value":456318}},"42b857cdf32d4669ad8f180068a3e8e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffc9ad27532148819e4f866e036cbc42","placeholder":"​","style":"IPY_MODEL_841a7425158e428e8f63dfeacf7749f2","value":" 446k/446k [00:00&lt;00:00, 705kB/s]"}},"f37cdef7d4ac4754af78a3e0739cac19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a08ec4d2992143f4bef7f83bbe0682ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fad162df46df4feba43cf1c047d05829":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16592399f9cc472694a6480464c480a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9561c984c364872bb8fa7d9d381be6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffc9ad27532148819e4f866e036cbc42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"841a7425158e428e8f63dfeacf7749f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71aa44e2a41a4f90843f82d3fbc2132b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9fa122edfd14287aee598bb3fcd0ba0","IPY_MODEL_3eb4c448cff34cc4aa344fe460d3813a","IPY_MODEL_d43b184f1e5a4a9cbbe22f3f6261b110"],"layout":"IPY_MODEL_3022b3e0872b43ecb900d69acd0b000a"}},"c9fa122edfd14287aee598bb3fcd0ba0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4f397f6665b45afa3dfd1960ec834f7","placeholder":"​","style":"IPY_MODEL_449b8ff237f0488abcee530cd814df78","value":"Downloading tokenizer.json: 100%"}},"3eb4c448cff34cc4aa344fe460d3813a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e770a1fa454254ac0c89c4e4dd31af","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfc177c4c8cc46b887f50a325aabe850","value":1355863}},"d43b184f1e5a4a9cbbe22f3f6261b110":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e80c574c50e94a17af91b7b9a9d6b9e4","placeholder":"​","style":"IPY_MODEL_297507b6d38e45e29e96b70ad4a365ba","value":" 1.29M/1.29M [00:00&lt;00:00, 2.34MB/s]"}},"3022b3e0872b43ecb900d69acd0b000a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f397f6665b45afa3dfd1960ec834f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"449b8ff237f0488abcee530cd814df78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52e770a1fa454254ac0c89c4e4dd31af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc177c4c8cc46b887f50a325aabe850":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e80c574c50e94a17af91b7b9a9d6b9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"297507b6d38e45e29e96b70ad4a365ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25daca2230ed4996a4eb376745258c2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_174c2264dde745b2aa13686a9efbfd43","IPY_MODEL_eec227ae3a574e918bc30bb39ff96a29","IPY_MODEL_c72cb4cd7b064230b6322ebdbf4ed464"],"layout":"IPY_MODEL_c0ca6403ee52451fb4263e4ef5ee75c1"}},"174c2264dde745b2aa13686a9efbfd43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1be74d1d020a4faabe72142f1e2c49ff","placeholder":"​","style":"IPY_MODEL_e045a176e827448892c3108df0086476","value":"Downloading config.json: 100%"}},"eec227ae3a574e918bc30bb39ff96a29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f378b8c52b84d49be20ab6eed15a720","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96d489631a9641b4a859fa3dd196d64c","value":481}},"c72cb4cd7b064230b6322ebdbf4ed464":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6640bc287fe542d8b6aedeb2016bf689","placeholder":"​","style":"IPY_MODEL_f77aa13e86c74cb39fab0771e71110b5","value":" 481/481 [00:00&lt;00:00, 17.4kB/s]"}},"c0ca6403ee52451fb4263e4ef5ee75c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1be74d1d020a4faabe72142f1e2c49ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e045a176e827448892c3108df0086476":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f378b8c52b84d49be20ab6eed15a720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d489631a9641b4a859fa3dd196d64c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6640bc287fe542d8b6aedeb2016bf689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f77aa13e86c74cb39fab0771e71110b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33c2f9000699460297974da0c41de9cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c48c28a50f44bfba8a2373e25c8fb8c","IPY_MODEL_bf7d1e889cf140c8a6e2337bac1a68af","IPY_MODEL_dd622ada44634b2491104e074e8af3ae"],"layout":"IPY_MODEL_a325f62544944ddbbd08cb7132483952"}},"8c48c28a50f44bfba8a2373e25c8fb8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056b286cd6054863adae3d2ca38f4190","placeholder":"​","style":"IPY_MODEL_1deb244ed774410eaa506185194e8e57","value":"Downloading pytorch_model.bin: 100%"}},"bf7d1e889cf140c8a6e2337bac1a68af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf8304925b74ee1aeadf5e48bc398ba","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71165554eb254190b6e75bc4be59d324","value":501200538}},"dd622ada44634b2491104e074e8af3ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f316e005c2c744e6ac0ece75654b925a","placeholder":"​","style":"IPY_MODEL_2a819ba59567451b8ccd0ae8b309c944","value":" 478M/478M [00:08&lt;00:00, 61.1MB/s]"}},"a325f62544944ddbbd08cb7132483952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"056b286cd6054863adae3d2ca38f4190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1deb244ed774410eaa506185194e8e57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbf8304925b74ee1aeadf5e48bc398ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71165554eb254190b6e75bc4be59d324":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f316e005c2c744e6ac0ece75654b925a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a819ba59567451b8ccd0ae8b309c944":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4e2387a545548f2b73ee6418b616cc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e68e98b600d475abf29bcd52b4e7a92","IPY_MODEL_143fd23f8c0d46c7b2f93c531066a6be","IPY_MODEL_162714e1ffbe486bad6d16ead26c126f"],"layout":"IPY_MODEL_c536a98664e44bdbbc899ffe16a0cc2c"}},"5e68e98b600d475abf29bcd52b4e7a92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d09bdaf92d640cf8388bc082f91a98e","placeholder":"​","style":"IPY_MODEL_e2a0c2f4942846f486a2bab67a9baf35","value":"Downloading vocab.json: 100%"}},"143fd23f8c0d46c7b2f93c531066a6be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b1a0df2e71845388e236d4adc06bcb4","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c0997f517fa41e6919cf14fbf42d3ae","value":898823}},"162714e1ffbe486bad6d16ead26c126f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d05ed192b1467db20567ddc609f120","placeholder":"​","style":"IPY_MODEL_44811bfaea4e42ce87db295aad70a062","value":" 878k/878k [00:00&lt;00:00, 1.98MB/s]"}},"c536a98664e44bdbbc899ffe16a0cc2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d09bdaf92d640cf8388bc082f91a98e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a0c2f4942846f486a2bab67a9baf35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b1a0df2e71845388e236d4adc06bcb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c0997f517fa41e6919cf14fbf42d3ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8d05ed192b1467db20567ddc609f120":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44811bfaea4e42ce87db295aad70a062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58e6911186d8447098bc1a3c011d844e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc92d55b82004d6fb0c66d12fd57bba4","IPY_MODEL_05226951390b4b08ad80afa8e5adcbe8","IPY_MODEL_d15154e6bf19417d823f5685a9ac21c9"],"layout":"IPY_MODEL_8ab6143bee104912b28fb71c5e4562cc"}},"bc92d55b82004d6fb0c66d12fd57bba4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6fadb9016c64f6690f9854635a35d7b","placeholder":"​","style":"IPY_MODEL_e8fd77311bfe4ce3aea56aa458fe556b","value":"Downloading merges.txt: 100%"}},"05226951390b4b08ad80afa8e5adcbe8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d2fb620c2a14cd7b647faf7e347d95e","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9b503b630a7465a9aa66da4b51921ca","value":456318}},"d15154e6bf19417d823f5685a9ac21c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef881af37a574b4e8e2688ee5c259285","placeholder":"​","style":"IPY_MODEL_98683b5e7afc44da9b548a9da620b3d4","value":" 446k/446k [00:00&lt;00:00, 674kB/s]"}},"8ab6143bee104912b28fb71c5e4562cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6fadb9016c64f6690f9854635a35d7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8fd77311bfe4ce3aea56aa458fe556b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d2fb620c2a14cd7b647faf7e347d95e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9b503b630a7465a9aa66da4b51921ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef881af37a574b4e8e2688ee5c259285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98683b5e7afc44da9b548a9da620b3d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}