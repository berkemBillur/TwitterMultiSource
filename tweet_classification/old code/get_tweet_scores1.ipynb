{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":[],"authorship_tag":"ABX9TyNvUn2DuCLuNPZHCJ7WAZu/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"1e8bcca6ec544530a72704ff790b62ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_814dfc10c76d48ee962ff91cb94016f6","IPY_MODEL_8e275c39bdd84bc784b80a7e6c845b91","IPY_MODEL_bd7600b521f14953a0c22f7110920998"],"layout":"IPY_MODEL_3724e2a3d7ba43b6afc2e1af3e7a9a40"}},"814dfc10c76d48ee962ff91cb94016f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc7645876275460caa8c5050853332ad","placeholder":"​","style":"IPY_MODEL_eed504389ba44b0fb86fcac3e6168a1d","value":"Downloading: 100%"}},"8e275c39bdd84bc784b80a7e6c845b91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd52d2f9fbc4025b931ea774f31c2e5","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_049f8544c13e4abf9000bebd53c5684e","value":481}},"bd7600b521f14953a0c22f7110920998":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9212dc992d7c4e4694471121b4f4dcdf","placeholder":"​","style":"IPY_MODEL_c361f1c1d58b41ca98298e87e5bdb479","value":" 481/481 [00:00&lt;00:00, 18.2kB/s]"}},"3724e2a3d7ba43b6afc2e1af3e7a9a40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc7645876275460caa8c5050853332ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed504389ba44b0fb86fcac3e6168a1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cd52d2f9fbc4025b931ea774f31c2e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"049f8544c13e4abf9000bebd53c5684e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9212dc992d7c4e4694471121b4f4dcdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c361f1c1d58b41ca98298e87e5bdb479":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8b893772264427b81a6cdca8f436b1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94d61af9c5c040be9d8b4c1f76ef59fc","IPY_MODEL_29b43712b65b4b8a8f89e36ab89e854f","IPY_MODEL_c31d7f8d9461425b8e02edae20d0a04f"],"layout":"IPY_MODEL_094ddf7d6c3a4d60950902a84a57da86"}},"94d61af9c5c040be9d8b4c1f76ef59fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb6ae20811374cd8a41d411e6a45b027","placeholder":"​","style":"IPY_MODEL_a7bc1e767ec14f588a08d363e391bc9d","value":"Downloading: 100%"}},"29b43712b65b4b8a8f89e36ab89e854f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f271e8957bd24ef79fe83afb2cc86bd4","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85c4ff56634f4b7d8a76a635e33a7e6e","value":898823}},"c31d7f8d9461425b8e02edae20d0a04f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_601d300280064f3db1d8aba5ee157f1f","placeholder":"​","style":"IPY_MODEL_69d76e1a6497469583f4e091533b1259","value":" 878k/878k [00:00&lt;00:00, 704kB/s]"}},"094ddf7d6c3a4d60950902a84a57da86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb6ae20811374cd8a41d411e6a45b027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7bc1e767ec14f588a08d363e391bc9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f271e8957bd24ef79fe83afb2cc86bd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85c4ff56634f4b7d8a76a635e33a7e6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"601d300280064f3db1d8aba5ee157f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69d76e1a6497469583f4e091533b1259":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c347e0d7ac2b4d399baa35c46611d86c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04d2806680894e16b3174451a24af6fe","IPY_MODEL_044e3b6284d14be68a0d08f61285a5c3","IPY_MODEL_cd749588391e402285fde173a9ff41e1"],"layout":"IPY_MODEL_7d61291bb958467a95f80a1850fc4aa0"}},"04d2806680894e16b3174451a24af6fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f2d6dd69842458dac0fdfc654d82705","placeholder":"​","style":"IPY_MODEL_0cbced40d26c4467a91456d5a1b4c2ca","value":"Downloading: 100%"}},"044e3b6284d14be68a0d08f61285a5c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71ea049923874bb7a23e7a37282a9065","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7dee2c8005b34710889a6bc5090f1964","value":456318}},"cd749588391e402285fde173a9ff41e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c62bce542a304f30a75af6af12a7135e","placeholder":"​","style":"IPY_MODEL_23b7b88c92504d6fa6ffedae44985e07","value":" 446k/446k [00:00&lt;00:00, 578kB/s]"}},"7d61291bb958467a95f80a1850fc4aa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f2d6dd69842458dac0fdfc654d82705":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cbced40d26c4467a91456d5a1b4c2ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71ea049923874bb7a23e7a37282a9065":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dee2c8005b34710889a6bc5090f1964":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c62bce542a304f30a75af6af12a7135e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23b7b88c92504d6fa6ffedae44985e07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a83231ed8f5442f97591e665446d63b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d77834af0bf43f88c256a06a4b4b759","IPY_MODEL_f648046cc78a4e7a9b8ea547b2057cc5","IPY_MODEL_88ff328351d74f4aad0d0d38c2f9fba1"],"layout":"IPY_MODEL_dc9688066c4c477fab8ed5939439055a"}},"0d77834af0bf43f88c256a06a4b4b759":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c6f91d7fb4847939e03f637fdbacbd3","placeholder":"​","style":"IPY_MODEL_4ed66401043147bab2a6dc6224b24385","value":"Downloading: 100%"}},"f648046cc78a4e7a9b8ea547b2057cc5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_888b89f406da4a83a3e904c4b89f78ab","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f4f0e1f6c624f4ba6a472ffa3a550c4","value":1355863}},"88ff328351d74f4aad0d0d38c2f9fba1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_827271df5d094b3d82839df0baadf32d","placeholder":"​","style":"IPY_MODEL_c7fc261d97b547ef927c58255e3bedb8","value":" 1.29M/1.29M [00:00&lt;00:00, 1.37MB/s]"}},"dc9688066c4c477fab8ed5939439055a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c6f91d7fb4847939e03f637fdbacbd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ed66401043147bab2a6dc6224b24385":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"888b89f406da4a83a3e904c4b89f78ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f4f0e1f6c624f4ba6a472ffa3a550c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"827271df5d094b3d82839df0baadf32d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7fc261d97b547ef927c58255e3bedb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9dcf9eebaf7044ee8f354dd5c9296002":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b0bb48330114d57ab0a4e43f892a963","IPY_MODEL_ea2562d266234b818333f685c4d33e45","IPY_MODEL_4277f3a192e048b2969579541a18e648"],"layout":"IPY_MODEL_915fc04f27ae4691a371de844dd8cdbd"}},"8b0bb48330114d57ab0a4e43f892a963":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d962d19ed82044ba98748e9c6a8923f6","placeholder":"​","style":"IPY_MODEL_eab385656cef4055bcd30f92def0a722","value":"Downloading: 100%"}},"ea2562d266234b818333f685c4d33e45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db2753627e8546639152f7807b2cddec","max":1302,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0511099fde84484ab8b3a16cd1c0d10f","value":1302}},"4277f3a192e048b2969579541a18e648":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6e06322a29e4008a7ebde799ab784a0","placeholder":"​","style":"IPY_MODEL_e6ca94781ba14893ae16e2bde67a8ee6","value":" 1.27k/1.27k [00:00&lt;00:00, 46.7kB/s]"}},"915fc04f27ae4691a371de844dd8cdbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d962d19ed82044ba98748e9c6a8923f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eab385656cef4055bcd30f92def0a722":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db2753627e8546639152f7807b2cddec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0511099fde84484ab8b3a16cd1c0d10f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6e06322a29e4008a7ebde799ab784a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6ca94781ba14893ae16e2bde67a8ee6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8f70b2d510e4a359f3e978456ead912":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f5639b5949642c2bee792c166cbb075","IPY_MODEL_ff5d8dacf27f416a8c63d2cc05235df7","IPY_MODEL_20232adcff5b444c91fa19be3639b05e"],"layout":"IPY_MODEL_e22acb1d56064a02bb2270564322c331"}},"2f5639b5949642c2bee792c166cbb075":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1095baa07c9c4011a14f47c40a357a78","placeholder":"​","style":"IPY_MODEL_c67f46a22370444089558d5c1687970e","value":"Downloading: 100%"}},"ff5d8dacf27f416a8c63d2cc05235df7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d18c0ed820e4e9088a07175c08fe24e","max":798293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_123ebf8af6bf4fd89fb380e3f1b4e977","value":798293}},"20232adcff5b444c91fa19be3639b05e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20b0b27c35fc4b70aa6bb8e45a36d452","placeholder":"​","style":"IPY_MODEL_3c60eb654c944eaa8e42b69a969b7802","value":" 780k/780k [00:00&lt;00:00, 1.84MB/s]"}},"e22acb1d56064a02bb2270564322c331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1095baa07c9c4011a14f47c40a357a78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c67f46a22370444089558d5c1687970e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d18c0ed820e4e9088a07175c08fe24e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123ebf8af6bf4fd89fb380e3f1b4e977":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20b0b27c35fc4b70aa6bb8e45a36d452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c60eb654c944eaa8e42b69a969b7802":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53f11ef0cb4c4110a9992b4f586026bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a05bdf5d67f473da88fe87991cec7a6","IPY_MODEL_c260981c1f334cbb89453f231ff8f80c","IPY_MODEL_b2ed4b237af14ba9a3805e48702cd423"],"layout":"IPY_MODEL_0d6403ad77a24ecb9525298a66d744a4"}},"7a05bdf5d67f473da88fe87991cec7a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55ac432e6d4d4c038ad63146bfd1b48c","placeholder":"​","style":"IPY_MODEL_fc2ebaa163d34d3a85a1d0300bb2a8f2","value":"Downloading: 100%"}},"c260981c1f334cbb89453f231ff8f80c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a2e0d1303f14c5b9c0cfc1dcc9824d0","max":456356,"min":0,"orientation":"horizontal","style":"IPY_MODEL_509dd31fbe324d5da67950da8d55653b","value":456356}},"b2ed4b237af14ba9a3805e48702cd423":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_294a4431de0e4b9fb273366ba9e3118d","placeholder":"​","style":"IPY_MODEL_512902fb6d784bd893976b3b6982d0d4","value":" 446k/446k [00:00&lt;00:00, 536kB/s]"}},"0d6403ad77a24ecb9525298a66d744a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55ac432e6d4d4c038ad63146bfd1b48c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc2ebaa163d34d3a85a1d0300bb2a8f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a2e0d1303f14c5b9c0cfc1dcc9824d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509dd31fbe324d5da67950da8d55653b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"294a4431de0e4b9fb273366ba9e3118d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"512902fb6d784bd893976b3b6982d0d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aab22b4db8314690bd52351fa72f654f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a4b087ca0004ab6867d78e0580ad781","IPY_MODEL_8ef147034c2340f9bad0cfecbb2ef63b","IPY_MODEL_87af2b3718994777b5330748a6765bd4"],"layout":"IPY_MODEL_700f24d7eb054b4bb7c3710c32a661e9"}},"6a4b087ca0004ab6867d78e0580ad781":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5f8f891fd548d2ad6cd6cc69d28f3a","placeholder":"​","style":"IPY_MODEL_a8080b62fa944e7baf20e32f620f678b","value":"Downloading: 100%"}},"8ef147034c2340f9bad0cfecbb2ef63b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ec075ecec69419ca4c3d4f640e3d1f9","max":1355881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db597bd479b7492db40a6e48e0e15467","value":1355881}},"87af2b3718994777b5330748a6765bd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2215eeb606984a01a499efcf5b72a164","placeholder":"​","style":"IPY_MODEL_5892326268494d60a0f3143d5027bda3","value":" 1.29M/1.29M [00:00&lt;00:00, 1.84MB/s]"}},"700f24d7eb054b4bb7c3710c32a661e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c5f8f891fd548d2ad6cd6cc69d28f3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8080b62fa944e7baf20e32f620f678b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ec075ecec69419ca4c3d4f640e3d1f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db597bd479b7492db40a6e48e0e15467":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2215eeb606984a01a499efcf5b72a164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5892326268494d60a0f3143d5027bda3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae09868748b49bea9e2d0c67e955cf9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a8bcfd6fd287448b9316e181617eb840","IPY_MODEL_cc73d40675e64037b3fd0551329ed1c8","IPY_MODEL_a31a84150b4a483a81bbf1991e2a4f22"],"layout":"IPY_MODEL_f8abfdf1b1a14537a76e739eb0944e06"}},"a8bcfd6fd287448b9316e181617eb840":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0b9d3afddb245ae88e20cafac6bbc60","placeholder":"​","style":"IPY_MODEL_2dbc4467a70241e2881d1a6904eeb719","value":"Downloading: 100%"}},"cc73d40675e64037b3fd0551329ed1c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3380cf760c84fedbd5c750fa99eb7a3","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d6eaebcabc14490bf69269f6a15ca4e","value":239}},"a31a84150b4a483a81bbf1991e2a4f22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_679349c1eca6447eb312641187806a3c","placeholder":"​","style":"IPY_MODEL_10094c980c5c44adb75fb9a3c9fa20ee","value":" 239/239 [00:00&lt;00:00, 8.83kB/s]"}},"f8abfdf1b1a14537a76e739eb0944e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0b9d3afddb245ae88e20cafac6bbc60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dbc4467a70241e2881d1a6904eeb719":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3380cf760c84fedbd5c750fa99eb7a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d6eaebcabc14490bf69269f6a15ca4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"679349c1eca6447eb312641187806a3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10094c980c5c44adb75fb9a3c9fa20ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7621806febf048af92acaaf2e978e7ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ddb6850c8aa94a5a9a213718545c33a4","IPY_MODEL_b992f5cac33b40c993858bf5d4f8ac34","IPY_MODEL_ffecb9fe147a477cb35ad880f7b0b90f"],"layout":"IPY_MODEL_31ac4172e71941f1b6c17ab83473deaa"}},"ddb6850c8aa94a5a9a213718545c33a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bef130ea0f4d4b6597b45c97c5405529","placeholder":"​","style":"IPY_MODEL_6f824c17752c4dd495be9e2c3aed5090","value":"Downloading: 100%"}},"b992f5cac33b40c993858bf5d4f8ac34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02fb009b28c247c184c9e90fa3d1b694","max":1880,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e667710a65794539af1edca2d5ceffb2","value":1880}},"ffecb9fe147a477cb35ad880f7b0b90f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75f316efb1f243448931a0050d8b1448","placeholder":"​","style":"IPY_MODEL_843997a6adb6414fa6b7820d82c023c7","value":" 1.84k/1.84k [00:00&lt;00:00, 75.9kB/s]"}},"31ac4172e71941f1b6c17ab83473deaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bef130ea0f4d4b6597b45c97c5405529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f824c17752c4dd495be9e2c3aed5090":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02fb009b28c247c184c9e90fa3d1b694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e667710a65794539af1edca2d5ceffb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75f316efb1f243448931a0050d8b1448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"843997a6adb6414fa6b7820d82c023c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b2c5c7fa12745b698549c379af14861":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9da9cb359a774716801778b1005df8f1","IPY_MODEL_6b004101280c4abc83420044d5993a22","IPY_MODEL_87d3a3a16d9c47a7ba825528a5476c9d"],"layout":"IPY_MODEL_196965f148c54a09a3913e5e32385b5c"}},"9da9cb359a774716801778b1005df8f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07b18ce2c2fe454f91ac82f4af4661f7","placeholder":"​","style":"IPY_MODEL_b6539bca8b6645df926832d29447a827","value":"Downloading: 100%"}},"6b004101280c4abc83420044d5993a22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a3f9b2bad8947bd80343b6a72e7e3ba","max":498723565,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ebf1fd5313646488bf43d81d7e8587a","value":498723565}},"87d3a3a16d9c47a7ba825528a5476c9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_135edee677144ccfa906358368f595bf","placeholder":"​","style":"IPY_MODEL_c3e083af0ecd477cb11204d79d4703b7","value":" 476M/476M [00:08&lt;00:00, 61.1MB/s]"}},"196965f148c54a09a3913e5e32385b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07b18ce2c2fe454f91ac82f4af4661f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6539bca8b6645df926832d29447a827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a3f9b2bad8947bd80343b6a72e7e3ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ebf1fd5313646488bf43d81d7e8587a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"135edee677144ccfa906358368f595bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e083af0ecd477cb11204d79d4703b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86d483f9716140559c85e9e076c11be4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_156efc3678d341358b4b762e65d46531","IPY_MODEL_2517fd8dbb8d48b297c9954f3e5aa02e","IPY_MODEL_daac5c84feec41e69ba3c56e98f677bd"],"layout":"IPY_MODEL_b84902c1d87045aeba1fed74d4e2bf4d"}},"156efc3678d341358b4b762e65d46531":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1236affd22974942998187b843648761","placeholder":"​","style":"IPY_MODEL_b8c5fa6afeda4ab183e65bf16f6ed46a","value":"Downloading: 100%"}},"2517fd8dbb8d48b297c9954f3e5aa02e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bbfbd1228b947209b99af4f42372184","max":1160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c96200cf5c854822b61623b6bee283bd","value":1160}},"daac5c84feec41e69ba3c56e98f677bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3c11641f34f4b678f79dbf849733d62","placeholder":"​","style":"IPY_MODEL_ef1193731c2146e086cf0dba5f468c4a","value":" 1.13k/1.13k [00:00&lt;00:00, 43.7kB/s]"}},"b84902c1d87045aeba1fed74d4e2bf4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1236affd22974942998187b843648761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c5fa6afeda4ab183e65bf16f6ed46a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bbfbd1228b947209b99af4f42372184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96200cf5c854822b61623b6bee283bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3c11641f34f4b678f79dbf849733d62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef1193731c2146e086cf0dba5f468c4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"945791dff7d34baa952f86dae96a3ab0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4aee74748d80457eba84a1b10cbc2b03","IPY_MODEL_0b2f14b4b3914f48819705087e250ecb","IPY_MODEL_f0486db3b9a642b083dd970c640bd9c8"],"layout":"IPY_MODEL_78758f06d6d8438688c5fd8beaf75c9f"}},"4aee74748d80457eba84a1b10cbc2b03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e640e6d3401a4b1588e3a60cc85034c1","placeholder":"​","style":"IPY_MODEL_25a9fd86463c4caf8952958c8e0f8cc1","value":"Downloading: 100%"}},"0b2f14b4b3914f48819705087e250ecb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd1925841b3a4127b453a8e538a725db","max":498669805,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cd2764448f3435e940f4196d4230ada","value":498669805}},"f0486db3b9a642b083dd970c640bd9c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6f24c58a3f2478695273ede05eee321","placeholder":"​","style":"IPY_MODEL_0b31cad79f5443e0be97ca7260a922f9","value":" 476M/476M [00:08&lt;00:00, 59.2MB/s]"}},"78758f06d6d8438688c5fd8beaf75c9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e640e6d3401a4b1588e3a60cc85034c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25a9fd86463c4caf8952958c8e0f8cc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd1925841b3a4127b453a8e538a725db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cd2764448f3435e940f4196d4230ada":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6f24c58a3f2478695273ede05eee321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b31cad79f5443e0be97ca7260a922f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e7f5ea2353343afa7698e8748a6ff77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc1d2e5d12454e0fabfb9578707cd885","IPY_MODEL_b560c53281454e7bb89105d4b2fdba64","IPY_MODEL_6ec175606b0140e1a7cc8dd9ab35624e"],"layout":"IPY_MODEL_52ead377e4534b3eba8aad2f15db1785"}},"dc1d2e5d12454e0fabfb9578707cd885":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07c9fdc1fa1c4fc8b67acce61141140a","placeholder":"​","style":"IPY_MODEL_57f282c972eb44d2914a36a432a4d831","value":"Downloading: 100%"}},"b560c53281454e7bb89105d4b2fdba64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d807259a82a84e0094321e1b95776f73","max":589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f10402597d6749098f5d2d49103745f4","value":589}},"6ec175606b0140e1a7cc8dd9ab35624e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99d4bf75f093439782c7ba6379a35b40","placeholder":"​","style":"IPY_MODEL_9e4c7d5558f2401b9d5abb32fae38f04","value":" 589/589 [00:00&lt;00:00, 21.8kB/s]"}},"52ead377e4534b3eba8aad2f15db1785":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07c9fdc1fa1c4fc8b67acce61141140a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57f282c972eb44d2914a36a432a4d831":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d807259a82a84e0094321e1b95776f73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f10402597d6749098f5d2d49103745f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99d4bf75f093439782c7ba6379a35b40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e4c7d5558f2401b9d5abb32fae38f04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9600b9dfaac4f048c124fa81e6175c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb1acdfeee644a83815033c5f6bb3f29","IPY_MODEL_1b4ec5a98c344e27b1db3baad5ada962","IPY_MODEL_040e95b606b443e68ba335a31c5434a4"],"layout":"IPY_MODEL_4364d9660f6a4e8e9325f67ae989d396"}},"eb1acdfeee644a83815033c5f6bb3f29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01c27f5a156b4a1091c94de69ff768dd","placeholder":"​","style":"IPY_MODEL_ef82f2a1d27c4b129c3ed0849bcb0702","value":"Downloading: 100%"}},"1b4ec5a98c344e27b1db3baad5ada962":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c33fce77ba474461827e485035910301","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccaab2ec87504edebffb64f241c9017b","value":898822}},"040e95b606b443e68ba335a31c5434a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8e3eb37964c4394b6218ecf510f2179","placeholder":"​","style":"IPY_MODEL_aa3b9ad00bee4afabd31d221726dd71e","value":" 878k/878k [00:00&lt;00:00, 1.83MB/s]"}},"4364d9660f6a4e8e9325f67ae989d396":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01c27f5a156b4a1091c94de69ff768dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef82f2a1d27c4b129c3ed0849bcb0702":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c33fce77ba474461827e485035910301":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccaab2ec87504edebffb64f241c9017b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8e3eb37964c4394b6218ecf510f2179":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa3b9ad00bee4afabd31d221726dd71e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b35074398ed54302894812487789aeac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_814a2fabb9184dba8df59f210388b944","IPY_MODEL_27d8705ea8f64112bdda2721a67badbe","IPY_MODEL_2498495eb5374e058ac0ffd07abc2fdd"],"layout":"IPY_MODEL_7388e2ac97db4eda88ea3bb37cf261c8"}},"814a2fabb9184dba8df59f210388b944":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b1dee8e929b405c9318862ed7c50bc9","placeholder":"​","style":"IPY_MODEL_e21a6ce0c9bb47339721c2708bdf200d","value":"Downloading: 100%"}},"27d8705ea8f64112bdda2721a67badbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5062f58e0dbe4f2da833d88341a72118","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24a6784fe22a482ea32bcc6dd423d6ea","value":456318}},"2498495eb5374e058ac0ffd07abc2fdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e73c57a38b4c4a878185b3d87de48dec","placeholder":"​","style":"IPY_MODEL_9a3ddb15685249cc93b7f7f79c22532b","value":" 446k/446k [00:00&lt;00:00, 579kB/s]"}},"7388e2ac97db4eda88ea3bb37cf261c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b1dee8e929b405c9318862ed7c50bc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e21a6ce0c9bb47339721c2708bdf200d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5062f58e0dbe4f2da833d88341a72118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24a6784fe22a482ea32bcc6dd423d6ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e73c57a38b4c4a878185b3d87de48dec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a3ddb15685249cc93b7f7f79c22532b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f630256e16b44760a12edc436372a783":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bda157d32495446b9a7fd4ec736289f7","IPY_MODEL_d7ebdc8bca30458e85fdf20361069fff","IPY_MODEL_d789bf7f93bd469dae16ceeb007af9b7"],"layout":"IPY_MODEL_d50b5b4e73ff45c6b5caeb498f7924e6"}},"bda157d32495446b9a7fd4ec736289f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9619d14302244d89495996c986966a8","placeholder":"​","style":"IPY_MODEL_b6376770afdd4ed4b79a8a1681f4d2da","value":"Downloading: 100%"}},"d7ebdc8bca30458e85fdf20361069fff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1076ae02cd83481fac0a1b2a73c5db67","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2fdb63df5c04167a2babd02376f15fc","value":150}},"d789bf7f93bd469dae16ceeb007af9b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709b2e3f628b4760bebce49635ec769b","placeholder":"​","style":"IPY_MODEL_f9b43ed9f19b4547b56963e17382b408","value":" 150/150 [00:00&lt;00:00, 5.60kB/s]"}},"d50b5b4e73ff45c6b5caeb498f7924e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9619d14302244d89495996c986966a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6376770afdd4ed4b79a8a1681f4d2da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1076ae02cd83481fac0a1b2a73c5db67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2fdb63df5c04167a2babd02376f15fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"709b2e3f628b4760bebce49635ec769b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9b43ed9f19b4547b56963e17382b408":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14f492d0fa584b1a8c2047c32eb483c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62c767720b5a462fac00adc7143aa680","IPY_MODEL_4e26466379ee4db6b2639d2f96001b15","IPY_MODEL_68b74467a33e4939a15d19ccbf0ca81b"],"layout":"IPY_MODEL_9587f10c0b0e4bfba234cc90dd60e686"}},"62c767720b5a462fac00adc7143aa680":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3045a5d266b74e159d9446132e9cda11","placeholder":"​","style":"IPY_MODEL_a692ce7eed8f43e7984679914c5c5d68","value":"Downloading: 100%"}},"4e26466379ee4db6b2639d2f96001b15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a670450d54444263bd16ee1047ee9959","max":498676425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47744f0720624e4ca114d1deb1cc42ee","value":498676425}},"68b74467a33e4939a15d19ccbf0ca81b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbaaf8ff6b21481cbdc2f2d85270ab2a","placeholder":"​","style":"IPY_MODEL_424de16e72e640eda4de142a6ae53406","value":" 476M/476M [00:08&lt;00:00, 62.7MB/s]"}},"9587f10c0b0e4bfba234cc90dd60e686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3045a5d266b74e159d9446132e9cda11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a692ce7eed8f43e7984679914c5c5d68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a670450d54444263bd16ee1047ee9959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47744f0720624e4ca114d1deb1cc42ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbaaf8ff6b21481cbdc2f2d85270ab2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"424de16e72e640eda4de142a6ae53406":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92c8be4b22574a4c9da5b5cbfbf81510":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38ea82a173384fbe8285ae8c341f2afe","IPY_MODEL_f2633a296f6245deac5d4caccf1cf701","IPY_MODEL_467f5ee458c948dd82c53b38cdb0d51f"],"layout":"IPY_MODEL_e86f573337684f749cbc440707f7f79d"}},"38ea82a173384fbe8285ae8c341f2afe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cabfa999b57d4fe89cf79d2187200ca2","placeholder":"​","style":"IPY_MODEL_344aec7a3ad445618e3ed0d264f07eda","value":"Downloading: 100%"}},"f2633a296f6245deac5d4caccf1cf701":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_354ae5162bc449939ba1f12f56a46aba","max":1429,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b95e8dbb27d4472fbcce79b7486f4f38","value":1429}},"467f5ee458c948dd82c53b38cdb0d51f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44dd25fa84fb4b6187fb2bc68b4fd0b5","placeholder":"​","style":"IPY_MODEL_6f8c239b96ee419487d039151990229e","value":" 1.40k/1.40k [00:00&lt;00:00, 52.6kB/s]"}},"e86f573337684f749cbc440707f7f79d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cabfa999b57d4fe89cf79d2187200ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"344aec7a3ad445618e3ed0d264f07eda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"354ae5162bc449939ba1f12f56a46aba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b95e8dbb27d4472fbcce79b7486f4f38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44dd25fa84fb4b6187fb2bc68b4fd0b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f8c239b96ee419487d039151990229e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4525aef67a546619976cd1d21ba6941":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb43c3de6a1e487b9ee87ba140f8a546","IPY_MODEL_8e131791d87d48fa8241992d35130b21","IPY_MODEL_8546f0a45dcb4b18bef5455fefb6bad6"],"layout":"IPY_MODEL_a2ef263201d841aa823d10a1038697a4"}},"eb43c3de6a1e487b9ee87ba140f8a546":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47b7ea5f5bb44726af40754ce92d1aff","placeholder":"​","style":"IPY_MODEL_d20c9aa7118d4e269e24e8363c9122c9","value":"Downloading: 100%"}},"8e131791d87d48fa8241992d35130b21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c57887138d64466887ef510933727ba","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_981cea9ee3a44dbda7a4be7f40d60796","value":898822}},"8546f0a45dcb4b18bef5455fefb6bad6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cb9b7777c0347699a387cfc8d3b887b","placeholder":"​","style":"IPY_MODEL_0a25fce6e0e8400b8ca107f17fa9d220","value":" 878k/878k [00:00&lt;00:00, 1.80MB/s]"}},"a2ef263201d841aa823d10a1038697a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47b7ea5f5bb44726af40754ce92d1aff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d20c9aa7118d4e269e24e8363c9122c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c57887138d64466887ef510933727ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"981cea9ee3a44dbda7a4be7f40d60796":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cb9b7777c0347699a387cfc8d3b887b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a25fce6e0e8400b8ca107f17fa9d220":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e897e4ce61e2464c89f88aea3aed5717":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c15925b81bd4570a9f304fe7158b202","IPY_MODEL_2b3a414f46754138b5e7a4bcb813ebb0","IPY_MODEL_4446888226b04ef090085a690d19ebe2"],"layout":"IPY_MODEL_7c91c412ff8348d4a879c7b83d6ca446"}},"8c15925b81bd4570a9f304fe7158b202":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3da60078721048e9b022f0c51aeff984","placeholder":"​","style":"IPY_MODEL_debe0c32ce304457a0df984d9ecd44c7","value":"Downloading: 100%"}},"2b3a414f46754138b5e7a4bcb813ebb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e420a7bb94a341f48ffc55dea9301359","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52e84926a4414b5cb1e3a9befc96db71","value":456318}},"4446888226b04ef090085a690d19ebe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21391db14d284f819ab84485bea81b56","placeholder":"​","style":"IPY_MODEL_a7ab60ead71243ffab4080cbf824f432","value":" 446k/446k [00:00&lt;00:00, 705kB/s]"}},"7c91c412ff8348d4a879c7b83d6ca446":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da60078721048e9b022f0c51aeff984":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"debe0c32ce304457a0df984d9ecd44c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e420a7bb94a341f48ffc55dea9301359":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52e84926a4414b5cb1e3a9befc96db71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21391db14d284f819ab84485bea81b56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7ab60ead71243ffab4080cbf824f432":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8d2806bce2c4dfe96a1d03b8cf8c370":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c09df915594647f2a3ade3b82d870e63","IPY_MODEL_a9d7203a26e848698c182038245acc06","IPY_MODEL_8534f12c20a14a089e2432478c1464ad"],"layout":"IPY_MODEL_01c95f3e64674c9489899fc944895a2d"}},"c09df915594647f2a3ade3b82d870e63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f79f383f17f54c43a31a015ec3211f9a","placeholder":"​","style":"IPY_MODEL_3307647bbc80428ab314d1ea55e45150","value":"Downloading: 100%"}},"a9d7203a26e848698c182038245acc06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76f8e631873f47c7a440a726b53c63be","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57ea72f5e23f4f0cb2b39fd42bdc067e","value":150}},"8534f12c20a14a089e2432478c1464ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_280e1ddf843947eca1695d38f21597b6","placeholder":"​","style":"IPY_MODEL_8bffab14ca8e4116bb9451c0c3e214f8","value":" 150/150 [00:00&lt;00:00, 5.93kB/s]"}},"01c95f3e64674c9489899fc944895a2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79f383f17f54c43a31a015ec3211f9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3307647bbc80428ab314d1ea55e45150":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76f8e631873f47c7a440a726b53c63be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57ea72f5e23f4f0cb2b39fd42bdc067e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"280e1ddf843947eca1695d38f21597b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bffab14ca8e4116bb9451c0c3e214f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e6d40d52dc545198212e4309b216c93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bb93ee340f44a8f97841575995dfe5a","IPY_MODEL_18875ed980b84179aa427ce614f9ced2","IPY_MODEL_d67823b1de2e4ecfabf54ee501dd3341"],"layout":"IPY_MODEL_ff6fce561d1347d5b79469be80f47e02"}},"1bb93ee340f44a8f97841575995dfe5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33b776df64e249f7a598be1b4c97b2ed","placeholder":"​","style":"IPY_MODEL_e3a2adef99ef40ab81ec5f8aff26ed65","value":"Downloading: 100%"}},"18875ed980b84179aa427ce614f9ced2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35f939b833e84ef589d317d3a3e9e8e8","max":498731785,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0190b75c09b74915b919b42ce145b116","value":498731785}},"d67823b1de2e4ecfabf54ee501dd3341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfb28273ee4c4ca9bbcf8cbd71f3a0dd","placeholder":"​","style":"IPY_MODEL_8adcf22ffe1c4cc4bcdfee27620fe7d6","value":" 476M/476M [00:08&lt;00:00, 59.4MB/s]"}},"ff6fce561d1347d5b79469be80f47e02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33b776df64e249f7a598be1b4c97b2ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3a2adef99ef40ab81ec5f8aff26ed65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35f939b833e84ef589d317d3a3e9e8e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0190b75c09b74915b919b42ce145b116":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfb28273ee4c4ca9bbcf8cbd71f3a0dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8adcf22ffe1c4cc4bcdfee27620fe7d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11d27ce79dae45e3be48245e13072cc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a19fc21b0b154e4e818235512eabccf0","IPY_MODEL_43abb041d29d49dd9eb41a9c36542681","IPY_MODEL_2ede2090fd97408c9072b2bd2e8335e1"],"layout":"IPY_MODEL_a7ce58b5bb7e40a2b3b86f079bd50475"}},"a19fc21b0b154e4e818235512eabccf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72fffa1f902640c4849134654cacd6f2","placeholder":"​","style":"IPY_MODEL_d14cd270ba7d46b990ac5e0fe2f643e9","value":"Downloading: 100%"}},"43abb041d29d49dd9eb41a9c36542681":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49fcebb49ba84fbd897f94b16f94052b","max":980,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e094d24453f42c0af9811cac4ae8e86","value":980}},"2ede2090fd97408c9072b2bd2e8335e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbac694e7002418096fd3a7a41e5e743","placeholder":"​","style":"IPY_MODEL_bc43cccf60c8479a92ecc6940825f418","value":" 980/980 [00:00&lt;00:00, 31.5kB/s]"}},"a7ce58b5bb7e40a2b3b86f079bd50475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72fffa1f902640c4849134654cacd6f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14cd270ba7d46b990ac5e0fe2f643e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49fcebb49ba84fbd897f94b16f94052b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e094d24453f42c0af9811cac4ae8e86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbac694e7002418096fd3a7a41e5e743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc43cccf60c8479a92ecc6940825f418":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68c7eb8e6d954fe8b01b7a7098b41ffa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47e1d4b9ba6a4ac9ad7b461f8e9919a6","IPY_MODEL_67595d5e20ad47159c63de8f00580dc1","IPY_MODEL_42fdde2e26434cfc86ccff3e9d3daa95"],"layout":"IPY_MODEL_a89a82c684c04d32a5f6a25b922bce98"}},"47e1d4b9ba6a4ac9ad7b461f8e9919a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea4235d09d62481d8a8aa1781b0bbbdb","placeholder":"​","style":"IPY_MODEL_5bfc03f34e6f479794c90d07f73b3d87","value":"Downloading: 100%"}},"67595d5e20ad47159c63de8f00580dc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68d65ac4113040f2a723195ee0d7b27a","max":539691437,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45ceebe7fa964e049b684aac38a9a3ca","value":539691437}},"42fdde2e26434cfc86ccff3e9d3daa95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85a72a6dd1af46d9ae1efa21147b28c1","placeholder":"​","style":"IPY_MODEL_4113fccdf45e411e99e25607cacfd903","value":" 515M/515M [00:08&lt;00:00, 59.6MB/s]"}},"a89a82c684c04d32a5f6a25b922bce98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea4235d09d62481d8a8aa1781b0bbbdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bfc03f34e6f479794c90d07f73b3d87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68d65ac4113040f2a723195ee0d7b27a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45ceebe7fa964e049b684aac38a9a3ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85a72a6dd1af46d9ae1efa21147b28c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4113fccdf45e411e99e25607cacfd903":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbe3abc18786445fa90a50b06ae6610f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_411e41613c184b61aa6ab54315b7f65c","IPY_MODEL_8d8662caa54b407b90b44fa7ad769655","IPY_MODEL_72f5b008faf14a739dd60249b23c522c"],"layout":"IPY_MODEL_ed9c1d09756c44e581c37c48dba0be89"}},"411e41613c184b61aa6ab54315b7f65c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71e61fe462c348baa1eeb6784e501bd0","placeholder":"​","style":"IPY_MODEL_0672f0f454cf423f9202f8776bd46964","value":"Downloading: 100%"}},"8d8662caa54b407b90b44fa7ad769655":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f3b3fd4ab8447ef98ffa39b6257e554","max":335,"min":0,"orientation":"horizontal","style":"IPY_MODEL_becabb81727448f89ba7d9f906591cce","value":335}},"72f5b008faf14a739dd60249b23c522c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55ae0e0ddd454ef29e86c0cff07e05cc","placeholder":"​","style":"IPY_MODEL_33c94d79237443ce8d58b82c55e57799","value":" 335/335 [00:00&lt;00:00, 11.7kB/s]"}},"ed9c1d09756c44e581c37c48dba0be89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71e61fe462c348baa1eeb6784e501bd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0672f0f454cf423f9202f8776bd46964":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f3b3fd4ab8447ef98ffa39b6257e554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"becabb81727448f89ba7d9f906591cce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55ae0e0ddd454ef29e86c0cff07e05cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33c94d79237443ce8d58b82c55e57799":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e05b5216ebd4c108b1c1e14b116f6d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef8e1e41ac7e4dad9e0e501e30e97175","IPY_MODEL_2be53c27788045e098d28ab920d26b73","IPY_MODEL_11b8ec2d04874e209bc04ae9ed7a7274"],"layout":"IPY_MODEL_e72b6ab8a6c64d4d9df520e412c9334d"}},"ef8e1e41ac7e4dad9e0e501e30e97175":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1911e17fc8414b1286b10444efab50e6","placeholder":"​","style":"IPY_MODEL_67a23237a36140cbb324876d4c98c58d","value":"Downloading: 100%"}},"2be53c27788045e098d28ab920d26b73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2b4bc353b3148659e8352bf21e37782","max":843438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7eefc44955bd402a8e591aa82f8d2124","value":843438}},"11b8ec2d04874e209bc04ae9ed7a7274":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_450df2723a724f70b1dad6b760601ce2","placeholder":"​","style":"IPY_MODEL_5b5a88dd937b463f82fc07f0fcc3b6c2","value":" 824k/824k [00:00&lt;00:00, 665kB/s]"}},"e72b6ab8a6c64d4d9df520e412c9334d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1911e17fc8414b1286b10444efab50e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67a23237a36140cbb324876d4c98c58d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2b4bc353b3148659e8352bf21e37782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eefc44955bd402a8e591aa82f8d2124":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"450df2723a724f70b1dad6b760601ce2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b5a88dd937b463f82fc07f0fcc3b6c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a83e1bb253ca4def87758334faee6044":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f70a776c7eba44c5be7286296f7935a8","IPY_MODEL_7c1f17fc58f24f78ad620f0513933dd6","IPY_MODEL_e2b38437a9b24a81bce160b050a3e570"],"layout":"IPY_MODEL_79bfbd9706e14c2cbfe396fa4759bc7c"}},"f70a776c7eba44c5be7286296f7935a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8acd3b92231042409bda794623622a1b","placeholder":"​","style":"IPY_MODEL_90a727850f6942b3a3823c9c31d41df6","value":"Downloading: 100%"}},"7c1f17fc58f24f78ad620f0513933dd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f35f4b8e877e4e49ad881adb166572ad","max":1078931,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16f1c4dee39b47e0ab1edeffebca9f65","value":1078931}},"e2b38437a9b24a81bce160b050a3e570":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_350b22d0b0cb4be88462ba82fa0550e0","placeholder":"​","style":"IPY_MODEL_e2bc98b75c9845559333f910d4f95b13","value":" 1.03M/1.03M [00:00&lt;00:00, 2.00MB/s]"}},"79bfbd9706e14c2cbfe396fa4759bc7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8acd3b92231042409bda794623622a1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90a727850f6942b3a3823c9c31d41df6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f35f4b8e877e4e49ad881adb166572ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16f1c4dee39b47e0ab1edeffebca9f65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"350b22d0b0cb4be88462ba82fa0550e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2bc98b75c9845559333f910d4f95b13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"052a16d6875b44bea85173f0233a247a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69719c9355ab4c469d648b8fd66e33d3","IPY_MODEL_b1052d287dac4392b5e99b61e93c8338","IPY_MODEL_00f249aa33384b0589296d6b09f1a324"],"layout":"IPY_MODEL_23886942a73f471bbafb0ac2c5c464a2"}},"69719c9355ab4c469d648b8fd66e33d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e1b47c5a2e5404db774057ee9dc7fb5","placeholder":"​","style":"IPY_MODEL_02256998cc0848209164767e704d27ad","value":"Downloading: 100%"}},"b1052d287dac4392b5e99b61e93c8338":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12cc0ac3e5784da99456a90dbca41bbf","max":17,"min":0,"orientation":"horizontal","style":"IPY_MODEL_415693a84871445eb484108d075c0a26","value":17}},"00f249aa33384b0589296d6b09f1a324":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c3eb7fc59f04b208a8d50151e5e4cfb","placeholder":"​","style":"IPY_MODEL_8b8281ef6574442292da03a05be4b464","value":" 17.0/17.0 [00:00&lt;00:00, 680B/s]"}},"23886942a73f471bbafb0ac2c5c464a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e1b47c5a2e5404db774057ee9dc7fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02256998cc0848209164767e704d27ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12cc0ac3e5784da99456a90dbca41bbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"415693a84871445eb484108d075c0a26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c3eb7fc59f04b208a8d50151e5e4cfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b8281ef6574442292da03a05be4b464":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1280ad989a03407f992e18531a831b08":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e217a16ef9f428ab8eeb0853d5c89e9","IPY_MODEL_b5fdbbff8e234978a45e8fbc1eb75bd2","IPY_MODEL_c5c45f507bb6466bba00c4f6c6584871"],"layout":"IPY_MODEL_7250a83e27524a9fb1f9eadaa27b1c40"}},"0e217a16ef9f428ab8eeb0853d5c89e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9083ec2d535446a188ad635471165573","placeholder":"​","style":"IPY_MODEL_ea92e0a90eaa4094b1c516845028997f","value":"Downloading: 100%"}},"b5fdbbff8e234978a45e8fbc1eb75bd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f5315e928dc4092aa78e61b140cb0b7","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aad3f902f5974e7c95632e6b72dbbcc2","value":150}},"c5c45f507bb6466bba00c4f6c6584871":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96341b5327a744f5a140e3dbce661c92","placeholder":"​","style":"IPY_MODEL_49bb7bce3c24417ca94248c2f957e207","value":" 150/150 [00:00&lt;00:00, 5.43kB/s]"}},"7250a83e27524a9fb1f9eadaa27b1c40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9083ec2d535446a188ad635471165573":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea92e0a90eaa4094b1c516845028997f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f5315e928dc4092aa78e61b140cb0b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad3f902f5974e7c95632e6b72dbbcc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96341b5327a744f5a140e3dbce661c92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49bb7bce3c24417ca94248c2f957e207":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca001386b14b4e308ceec8da2236479d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e558c27f3654436a3fa2f965aff92d5","IPY_MODEL_ed328dad63274a7ab72542389666ce04","IPY_MODEL_530cb215e097480ca7579feef5810719"],"layout":"IPY_MODEL_5d66bf1604c24454917fb2acf7ea16f4"}},"1e558c27f3654436a3fa2f965aff92d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cad5a418ffe488d86dfb7f0b9d2c90e","placeholder":"​","style":"IPY_MODEL_cf4cea6334ed423ab44e6d0159953fde","value":"Downloading: 100%"}},"ed328dad63274a7ab72542389666ce04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cee15b894de746edbbb17914aed165cd","max":999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35975d06c6ee49ff8bcacebbd27ad1b6","value":999}},"530cb215e097480ca7579feef5810719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6146acd516cd4421a066689b291f31cf","placeholder":"​","style":"IPY_MODEL_c62cf33a27024dc3b4cf4f701e61091f","value":" 999/999 [00:00&lt;00:00, 31.4kB/s]"}},"5d66bf1604c24454917fb2acf7ea16f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cad5a418ffe488d86dfb7f0b9d2c90e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf4cea6334ed423ab44e6d0159953fde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cee15b894de746edbbb17914aed165cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35975d06c6ee49ff8bcacebbd27ad1b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6146acd516cd4421a066689b291f31cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c62cf33a27024dc3b4cf4f701e61091f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd6c608aaff542aea478edabb82bbe6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5aef6eb395d4020b2c5301c132d11d0","IPY_MODEL_da442f509c5e4e14925a5fd2157b61cb","IPY_MODEL_67e64b8e475d4a3fac703228e2ffb19f"],"layout":"IPY_MODEL_66935b526227410a88f8b9e8b7e1c447"}},"b5aef6eb395d4020b2c5301c132d11d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3986e74ecff40b2b7a5b1900e483253","placeholder":"​","style":"IPY_MODEL_aac5f6dd661d47888c5cb4b353d01975","value":"Downloading: 100%"}},"da442f509c5e4e14925a5fd2157b61cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34431e140e0e41e3832aa9be59d5a893","max":539706835,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c8cdb244cfa477e8a08eab9fe4c64ed","value":539706835}},"67e64b8e475d4a3fac703228e2ffb19f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e32bac526be24e94a51dceeee870d62b","placeholder":"​","style":"IPY_MODEL_8d485de520eb4c4f9fd5695595ced6f0","value":" 515M/515M [00:08&lt;00:00, 63.4MB/s]"}},"66935b526227410a88f8b9e8b7e1c447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3986e74ecff40b2b7a5b1900e483253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aac5f6dd661d47888c5cb4b353d01975":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34431e140e0e41e3832aa9be59d5a893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c8cdb244cfa477e8a08eab9fe4c64ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e32bac526be24e94a51dceeee870d62b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d485de520eb4c4f9fd5695595ced6f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f136618fd0549b898dcfa38cb465cf9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0bf74843adb24287a5cd80b4f8a14817","IPY_MODEL_b04adc9615f64957bfa1e16689550cbf","IPY_MODEL_b414b551e01e4c98a314e0e5baef4181"],"layout":"IPY_MODEL_bb2605d87f6f486c957568394560ed42"}},"0bf74843adb24287a5cd80b4f8a14817":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5695ee0f1c3445c92ac30967bdec0b4","placeholder":"​","style":"IPY_MODEL_e63da8b0477848f0bac46d60289a43ad","value":"Downloading: 100%"}},"b04adc9615f64957bfa1e16689550cbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_264e2297223a4729acb050dad3341f77","max":295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0936bf385ac4de0b26e0bd26e7621b3","value":295}},"b414b551e01e4c98a314e0e5baef4181":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05fc08d03555472faf58e959c25acd12","placeholder":"​","style":"IPY_MODEL_192de79e584940d789edc196af1afd39","value":" 295/295 [00:00&lt;00:00, 11.8kB/s]"}},"bb2605d87f6f486c957568394560ed42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5695ee0f1c3445c92ac30967bdec0b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e63da8b0477848f0bac46d60289a43ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"264e2297223a4729acb050dad3341f77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0936bf385ac4de0b26e0bd26e7621b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05fc08d03555472faf58e959c25acd12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"192de79e584940d789edc196af1afd39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"868fb4b8dcc04f00b9d304597e04d31f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f4224b753054b9fafa6d22442d46190","IPY_MODEL_3a0498c705a54ec88e0098af8beb7805","IPY_MODEL_ed1b1e91e00248ca9adc65625ce0a1ac"],"layout":"IPY_MODEL_563a8ee40438418cb7cab4e12a3ddc69"}},"3f4224b753054b9fafa6d22442d46190":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84ffbafd0f1b48578ef79b9a9990d8da","placeholder":"​","style":"IPY_MODEL_02e5a58892ed482a80cd092c416ac660","value":"Downloading: 100%"}},"3a0498c705a54ec88e0098af8beb7805":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7f60e5e2f514e08b64a681d7f3a2d4d","max":843438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_949bfce1b16442f0bd3e70e0cba1c7b8","value":843438}},"ed1b1e91e00248ca9adc65625ce0a1ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68f02f44858240a98af74b8ac88cb834","placeholder":"​","style":"IPY_MODEL_f34586b4efdd4e0b9e7b5d3465f5e070","value":" 824k/824k [00:00&lt;00:00, 1.70MB/s]"}},"563a8ee40438418cb7cab4e12a3ddc69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84ffbafd0f1b48578ef79b9a9990d8da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02e5a58892ed482a80cd092c416ac660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7f60e5e2f514e08b64a681d7f3a2d4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"949bfce1b16442f0bd3e70e0cba1c7b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68f02f44858240a98af74b8ac88cb834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f34586b4efdd4e0b9e7b5d3465f5e070":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cda245baa5df44b4a4ae8e17a2889b8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d31441515f5a42ffa6a481708f2ccfce","IPY_MODEL_6f16373c93e644408fa3b2cf985348df","IPY_MODEL_0ad79761f72b4eb6b4627bf11ed9ec71"],"layout":"IPY_MODEL_c414af8c34ef4372b20a1e943d5b4a17"}},"d31441515f5a42ffa6a481708f2ccfce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3471efd7603e41d08b95516f47267439","placeholder":"​","style":"IPY_MODEL_d031c730f7d44262b40165d9383c1952","value":"Downloading: 100%"}},"6f16373c93e644408fa3b2cf985348df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c156fc1d54e4c119f5f106c60e0e5d3","max":1078931,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a2cdc0ac4d54560a05920f51f969428","value":1078931}},"0ad79761f72b4eb6b4627bf11ed9ec71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f660eac20fe34a9e92aad5710f1a29ab","placeholder":"​","style":"IPY_MODEL_df432533ff434ae79ebaf6a9a8a1bc1e","value":" 1.03M/1.03M [00:00&lt;00:00, 1.16MB/s]"}},"c414af8c34ef4372b20a1e943d5b4a17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3471efd7603e41d08b95516f47267439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d031c730f7d44262b40165d9383c1952":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c156fc1d54e4c119f5f106c60e0e5d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a2cdc0ac4d54560a05920f51f969428":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f660eac20fe34a9e92aad5710f1a29ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df432533ff434ae79ebaf6a9a8a1bc1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deba63c55514483f8b101070b69e2ddf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a5fe420c2454be1a1334dc73128044d","IPY_MODEL_5942e0aa1d484a6dbc249520a068ae08","IPY_MODEL_49c1110bd1aa4f73be03fcdf3cb8dc31"],"layout":"IPY_MODEL_913d1ec8784045049fdccecfae4df75a"}},"0a5fe420c2454be1a1334dc73128044d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b625a9fa1a154e8fb0216c86df209729","placeholder":"​","style":"IPY_MODEL_0069442251914347ace826b69affa619","value":"Downloading: 100%"}},"5942e0aa1d484a6dbc249520a068ae08":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5591984ed5514c7996b55be803c75f09","max":17,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6712bd3e695a4c4986a17796aebfb9e8","value":17}},"49c1110bd1aa4f73be03fcdf3cb8dc31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_540b2ccc8a8248dcb89f3e0f7e71b687","placeholder":"​","style":"IPY_MODEL_ca79b46addba4a76af3dd8de6bbd21a3","value":" 17.0/17.0 [00:00&lt;00:00, 621B/s]"}},"913d1ec8784045049fdccecfae4df75a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b625a9fa1a154e8fb0216c86df209729":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0069442251914347ace826b69affa619":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5591984ed5514c7996b55be803c75f09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6712bd3e695a4c4986a17796aebfb9e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"540b2ccc8a8248dcb89f3e0f7e71b687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca79b46addba4a76af3dd8de6bbd21a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a27f809097f4011bd4362208766c28f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28af47f03e734bf58a3b9ada3b3da72b","IPY_MODEL_c22bde16e6544ce48efcacd7d52bf75d","IPY_MODEL_d546088dae044c36b7a24770eab591ce"],"layout":"IPY_MODEL_a246d855b9ed458a947d848e7fd8e3f6"}},"28af47f03e734bf58a3b9ada3b3da72b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ce51032fabe4a30bb432f20c78f9362","placeholder":"​","style":"IPY_MODEL_7e692a49cf5e469d9db93e4fbc64f122","value":"Downloading: 100%"}},"c22bde16e6544ce48efcacd7d52bf75d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44eb9619edf643fa98b94e12827b6360","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fed498ea3e4c46398a4b20d8cd310625","value":150}},"d546088dae044c36b7a24770eab591ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06f6373a7dfd40479e09d07f464ff01d","placeholder":"​","style":"IPY_MODEL_c66a82f9c9eb4b76a3ac790fabd6374d","value":" 150/150 [00:00&lt;00:00, 5.63kB/s]"}},"a246d855b9ed458a947d848e7fd8e3f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ce51032fabe4a30bb432f20c78f9362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e692a49cf5e469d9db93e4fbc64f122":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44eb9619edf643fa98b94e12827b6360":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fed498ea3e4c46398a4b20d8cd310625":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06f6373a7dfd40479e09d07f464ff01d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c66a82f9c9eb4b76a3ac790fabd6374d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"4MdwUck88MEI"},"source":["## MOUNT"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20797,"status":"ok","timestamp":1662851875902,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"njrEJjvc8DnR","outputId":"982448a2-ebac-4462-ad46-0df9817e0d32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/MSc_project/.MAIN\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/MSc_project/.MAIN"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92105,"status":"ok","timestamp":1662851967997,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"ZO-PczKG8gPC","outputId":"42aa71ee-1970-4fd6-f9ba-6a6983ad9427"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 15.0 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 88.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 82.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 87.6 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 89.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 huggingface-hub-0.9.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting language_tool_python\n","  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from language_tool_python) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from language_tool_python) (4.64.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (1.25.11)\n","Installing collected packages: language-tool-python\n","Successfully installed language-tool-python-2.7.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting install\n","  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n","Collecting tweet-preprocessor\n","  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n","Installing collected packages: tweet-preprocessor, install\n","Successfully installed install-1.3.5 tweet-preprocessor-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pycountry\n","  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 14.9 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pycountry) (57.4.0)\n","Building wheels for collected packages: pycountry\n","  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681845 sha256=3c7d3e0db9096f11c6d253fe804edc6cc6ad2ae8b3ba4ed8295ccec57ef28a72\n","  Stored in directory: /root/.cache/pip/wheels/0e/06/e8/7ee176e95ea9a8a8c3b3afcb1869f20adbd42413d4611c6eb4\n","Successfully built pycountry\n","Installing collected packages: pycountry\n","Successfully installed pycountry-22.3.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandas==1.2.3\n","  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 16.4 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2022.2.1)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.3) (1.15.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","Successfully installed pandas-1.2.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 15.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 73.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.12.1 transformers-4.21.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement mislib (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for mislib\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=e8a9f284189894133476e9104821acd4dd7f808ca1dd1dfa05785353d958c379\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting readability\n","  Downloading readability-0.3.1.tar.gz (34 kB)\n","Building wheels for collected packages: readability\n","  Building wheel for readability (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for readability: filename=readability-0.3.1-py3-none-any.whl size=35475 sha256=a8804bed667386869937659cb78a5de84a20b812b60d1dc7bcfd244fae680f5f\n","  Stored in directory: /root/.cache/pip/wheels/b9/8b/5a/ba40b81d8e91c7bc1d4226fa51d7b5943d147be122df515c19\n","Successfully built readability\n","Installing collected packages: readability\n","Successfully installed readability-0.3.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pysentimiento\n","  Downloading pysentimiento-0.4.2-py3-none-any.whl (30 kB)\n","Collecting transformers==4.13\n","  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 23.7 MB/s \n","\u001b[?25hCollecting datasets<2.0.0,>=1.13.3\n","  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 90.7 MB/s \n","\u001b[?25hRequirement already satisfied: torch<2.0.0,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pysentimiento) (1.12.1+cu113)\n","Collecting emoji<2.0.0,>=1.6.1\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 90.8 MB/s \n","\u001b[?25hCollecting sklearn<0.1,>=0.0\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (4.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (0.9.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 72.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 73.3 MB/s \n","\u001b[?25hRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.18.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (1.2.3)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (2022.8.1)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.3.5.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (3.8.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.70.13)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (4.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (6.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.8.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (4.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13->pysentimiento) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (3.0.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn<0.1,>=0.0->pysentimiento) (1.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13->pysentimiento) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13->pysentimiento) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13->pysentimiento) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (3.1.0)\n","Building wheels for collected packages: emoji, sklearn, sacremoses\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=c1c62d386781fb7699dbdcc525d919e2cd85e3d3ea32546ccf5ceba600123068\n","  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=e1f1c0111067144fb19eb836b83c30c2eca0e5a19903ead19834790516537f1a\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=f1b46f96f5d66c1dfffd5d7a5f4e0732a7ef2b7e7675a690d566e446afdf2136\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built emoji sklearn sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers, sklearn, emoji, datasets, pysentimiento\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.3\n","    Uninstalling transformers-4.21.3:\n","      Successfully uninstalled transformers-4.21.3\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.4.0\n","    Uninstalling datasets-2.4.0:\n","      Successfully uninstalled datasets-2.4.0\n","Successfully installed datasets-1.18.4 emoji-1.7.0 pysentimiento-0.4.2 sacremoses-0.0.53 sklearn-0.0 tokenizers-0.10.3 transformers-4.13.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=09434af2360b00a9b586abeccb42071569371f214f6efd64f07d0d2ccb97f21b\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","\u001b[K     |████████████████████████████████| 793 kB 14.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 66.9 MB/s \n","\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n","Automatic pdb calling has been turned ON\n"]}],"source":["!pip install datasets\n","!pip install language_tool_python\n","!pip install pip install tweet-preprocessor\n","!pip install pycountry\n","!pip install pandas==1.2.3\n","!pip install transformers\n","!pip install xgboost\n","!pip install torch\n","!pip install mislib\n","!pip install langdetect\n","!pip install readability\n","!pip install pysentimiento\n","!pip install wget\n","!pip install -Uqq ipdb\n","# import ipdb\n","%pdb on"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8906,"status":"ok","timestamp":1662851976885,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"7-nOwlLj7iAp","outputId":"b9af9376-6c4e-42c9-895b-9b1149854a9d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}],"source":["from textblob import TextBlob\n","import sys\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import os\n","import os.path\n","import nltk\n","import nltk.data\n","import time\n","import string\n","from datasets import load_dataset\n","\n","nltk.download('vader_lexicon')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","import json\n","import pickle\n","import joblib\n","\n","import language_tool_python\n","import preprocessor as p\n","\n","import pycountry\n","import re\n","import string\n","from wordcloud import WordCloud, STOPWORDS\n","from PIL import Image\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from nltk import tokenize\n","from langdetect import detect\n","from nltk.stem import SnowballStemmer\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import os\n","import readability\n","\n","## DATA\n","from datasets import Dataset\n","\n","### POLITENESS\n","from politeness.polite_script import *\n","\n","### topic modelling\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","import numpy as np\n","from scipy.special import expit\n","\n","### irony\n","import urllib.request\n","from scipy.special import softmax\n","import csv\n","\n","## offensiveness\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","\n","#hate\n","from pysentimiento import create_analyzer\n","from pysentimiento.preprocessing import preprocess_tweet\n","\n","# user genders \n","import torch\n","from transformers import BertTokenizer\n","from collections import defaultdict\n","\n","nltk.download('omw-1.4')\n","import time\n","\n","# if 'google.colab' in str(get_ipython()):\n","#   print('Running on CoLab')\n","# else:\n","#   print('Not running on CoLab')\n","#   os.chdir('G:\\My Drive\\MSc_project\\.MAIN\\offensiveness')\n"]},{"cell_type":"markdown","metadata":{"id":"uPxXEHpX8TGw"},"source":["## FUNC"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QADqBoM58VPo","executionInfo":{"status":"ok","timestamp":1662851977265,"user_tz":-60,"elapsed":406,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"outputs":[],"source":["class Analyzer(object):\n","    def __init__(self, hashtag):\n","\n","        self.hashtag = hashtag\n","        self.save_path = f'informer_results{os.path.sep}{hashtag}'\n","        self.tool = language_tool_python.LanguageTool('en-US')\n","        self.max_len = 160\n","\n","    def load_existing(self):\n","        save_path = f'tweets/{self.hashtag}/{self.hashtag}_TWEETS_scores.csv'\n","        df =  pd.read_csv(save_path)\n","        tweet_ids = df['tweet_id'].copy().astype(str).tolist()\n","        user_ids = df['user_id'].copy().astype(str).tolist()\n","        return tweet_ids,user_ids,df\n","\n","    def get_device(self):\n","        if torch.cuda.is_available():    \n","\n","            # Tell PyTorch to use the GPU.    \n","            self.device = torch.device(\"cuda\")\n","\n","            print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","            print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","        # If not...\n","        else:\n","            print('No GPU available, using the CPU instead.')\n","            self.device = torch.device(\"cpu\")\n","\n","    def load_informer_data(self):\n","        path = f'tweets{os.path.sep}{self.hashtag}{os.path.sep}{self.hashtag}_ms_cases.json'\n","        with open(path) as jf:\n","            data = json.load(jf)\n","        return data\n","\n","    def load_user_feeds(self):\n","        path = f'tweets/{self.hashtag}/100_feeds'\n","        jsons = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n","        all_js = {}\n","        for file in jsons:\n","            with open(os.path.join(f'{path}/' + file)) as jf:\n","                all_js = { **all_js, **json.load(jf) }\n","        print(f'pulled data on {len(all_js)} users')\n","        return all_js\n","\n","\n","    @staticmethod\n","    def get_the_tweets(database):\n","        all_tweets = {}\n","        for key,value in database.items():\n","            #store tweets by tweet id\n","            all_tweets.update( {str(key):{'text':value['tweet-text'],'user_id':str(value['user-id']),'tweet_id':str(key)}} ) # target tweet\n","\n","            inf = value['infector-info']\n","            k = list(inf.keys())[0]\n","            infector = inf[k]\n","\n","            all_tweets.update( {str(infector['id']):{'text':infector['tweet-text'],'user_id':str(infector['user-id']),'tweet_id':str(infector['id'])}} )\n","\n","            for informer in value['informers-data']:\n","                all_tweets.update( {str(informer['id']):{'text':informer['tweet-text'],'user_id':str(informer['user-id']),'tweet_id':str(informer['id'])}} )\n","        return all_tweets\n","\n","    @staticmethod\n","    def store_by_tweets(database):\n","        all_tweets = {}\n","        for key,value in database.items():\n","            if value in all_tweets:\n","                new = all_tweets[value].append(key)\n","                all_tweets[value] = new\n","            else:\n","                all_tweets[value] = [key]\n","\n","        return all_tweets\n","\n","    @staticmethod\n","    def get_users(database):\n","        users = {}\n","        for key,value in database.items():\n","            users.update( { str(value['user-id']):{'description': value['description'], 'feed':[]} } )\n","            infector = value['infector-info']\n","            i = [k for k in infector]\n","            infector = infector[i[0]]\n","            users.update(  { str(infector['user-id']):{'description': infector['description'],'feed':[] } } )\n","            for informer in value['informers-data']:\n","                users.update( { str(informer['user-id']):{'description': informer['description'],'feed':[] } } )\n","        return users\n","\n","    def add_feeds(self,users):\n","        feeds = self.load_user_feeds()\n","        pulled_feeds = feeds.keys()\n","        users_got = users.keys()\n","        users_needed = list(set(pulled_feeds) & set(users_got))\n","        tweet_ids = []\n","        for id in users_needed:\n","            users[id]['feed'] = feeds[id]\n","            tweet_ids.extend( tw['id'] for tw in feeds[id]  )\n","        return users,tweet_ids\n","\n","    @staticmethod\n","    def sort_by_tweet(all_tweets): \n","\n","        df = pd.DataFrame.from_dict(all_tweets, orient='index', columns= ['text','user_id'])\n","        sorted_tweets = {}\n","        for row,index in df.groupby('text').groups.items():\n","            key = tuple(index.values.tolist())\n","            sorted_tweets.update({key:row})\n","\n","        new_df = pd.DataFrame.from_dict(sorted_tweets, orient='index', columns= ['text'])\n","        \n","        return new_df\n","\n","\n","\n","###########################################\n","#######         PREPROCESSING       #######\n","###########################################\n","\n","        \n","    def tweet_cleaner(self,tw_list):\n","        remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n","        rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n","        hash = lambda x: re.sub(r'#', \"\", x)\n","        amp = lambda x: re.sub(r'&amp', \"\", x)\n","\n","\n","        tw_list['grammartext'] = tw_list.text.map(remove_rt).map(rt)\n","        tw_list['clean_text'] = tw_list.text.map(remove_rt).map(rt)\n","        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.HASHTAG)\n","        tw_list[\"grammartext\"] = tw_list.grammartext.map(p.clean)\n","        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.NUMBER)\n","        tw_list[\"clean_text\"] = tw_list.clean_text.map(p.clean).map(hash).map(amp)\n","        tw_list[\"clean_text\"] = tw_list.clean_text.str.lower()\n","\n","        #Calculating tweet's lenght and word count\n","        tw_list['text_len'] = tw_list['clean_text'].astype(str).apply(len)\n","        tw_list['text_word_count'] = tw_list['clean_text'].apply(lambda x: len(str(x).split()))\n","        tw_list['punct'] = tw_list['clean_text'].apply(lambda x: self.remove_punct(x))\n","        tw_list['tokenized'] = tw_list['punct'].apply(lambda x: self.tokenization(x.lower()))\n","        tw_list['nonstop'] = tw_list['tokenized'].apply(lambda x: self.remove_stopwords(x))\n","        tw_list['stemmed'] = tw_list['nonstop'].apply(lambda x: self.stemming(x))\n","        return tw_list\n","\n","    @staticmethod\n","    def hugging_preprocess(text):\n","        new_text = []\n","        for t in text.split(\" \"):\n","            t = '@user' if t.startswith('@') and len(t) > 1 else t\n","            t = 'http' if t.startswith('http') else t\n","            new_text.append(t)\n","        return \" \".join(new_text)\n","\n","    def remove_punct(self,text):\n","        text = \"\".join([char for char in text if char not in string.punctuation])\n","        text = re.sub('[0–9]+', '', text)\n","        return text\n","\n","\n","    def remove_stopwords(self,text):\n","        self.stopword = nltk.corpus.stopwords.words('english')\n","        text = [word for word in text if word not in self.stopword]\n","        return text\n","\n","    def stemming(self,text):\n","        self.ps = nltk.PorterStemmer()\n","        text = [self.ps.stem(word) for word in text]\n","        return text\n","\n","    def clean_text(self,text):\n","        text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n","        text_rc = re.sub('[0-9]+', '', text_lc)\n","        tokens = re.split('\\W+', text_rc)    # tokenization\n","        text = [self.ps.stem(word) for word in tokens if word not in self.stopword]  # remove stopwords and stemming\n","        return text\n","\n","    @staticmethod\n","    def tokenization(text):\n","        text = re.split('\\W+', text)\n","        return text\n","\n","################################################################################################\n","################################################################################################\n","############################                 METRICS                ############################\n","################################################################################################\n","################################################################################################\n","\n","    @staticmethod\n","    def get_sentiment(df,index,row):\n","        score = SentimentIntensityAnalyzer().polarity_scores(row.clean_text)\n","        neg = score['neg']\n","        neu = score['neu']\n","        pos = score['pos']\n","        comp = score['compound']\n","        if neg > pos:\n","            df.loc[index, 'sentiment'] = \"negative\"\n","        elif pos > neg:\n","            df.loc[index, 'sentiment'] = \"positive\"\n","        else:\n","            df.loc[index, 'sentiment'] = \"neutral\"\n","        df.loc[index, 'neg'] = neg\n","        df.loc[index, 'neu'] = neu\n","        df.loc[index, 'pos'] = pos\n","        df.loc[index, 'compound'] = comp\n","\n","    def get_grammar(self,df,index, row):\n","        # https://michaeljanz-data.science/deepllearning/natural-language-processing/scoring-texts-by-their-grammar-in-python/\n","        scores_word_based_sentence = []\n","        scores_sentence_based_sentence = []\n","        s1 = time.perf_counter()\n","        sentences = nltk.tokenize.sent_tokenize(row.grammartext)\n","        e1 = time.perf_counter()\n","        # sentences = self.split_into_sentences(row)\n","        for sentence in sentences:\n","        # for sentence in helpers.text_to_sentences(text):\n","            matches = self.tool.check(sentence)\n","            count_errors = len(matches)\n","            # only check if the sentence is correct or not\n","            scores_sentence_based_sentence.append(np.min([count_errors, 1]))\n","            scores_word_based_sentence.append(count_errors)\n","            \n","        word_count = len(nltk.tokenize.word_tokenize(row.grammartext))\n","        sum_count_errors_word_based = np.sum(scores_word_based_sentence)\n","        score_word_based = 1 - (sum_count_errors_word_based / word_count)\n","        \n","        sentence_count = len(sentences)       \n","        sum_count_errors_sentence_based = np.sum(scores_sentence_based_sentence)\n","        score_sentence_based = 1 - np.sum(sum_count_errors_sentence_based / sentence_count)\n","\n","        df.loc[index, 'grammar-word-score'] = score_word_based\n","        df.loc[index, 'grammar-sentence-score'] = score_sentence_based\n","\n","    @staticmethod\n","    def get_readability(df,index,row):\n","        if not row.clean_text:\n","            a=9\n","            # print('sentence has no real text')\n","        else:\n","            results = readability.getmeasures(row.clean_text,lang='en')\n","            # [ df.loc[index, score] = results['readability grades'][score] for score in \\\n","            #  ['Kincaid','ARI', 'Coleman-Liau', 'FleschReadingEase', 'GunningFogIndex', \\\n","            #   'LIX', 'SMOGIndex', 'RIX', 'DaleChallIndex'] ]\n","                    \n","            # readability grades\n","            df.loc[index, 'Kincaid'] = results['readability grades']['Kincaid']\n","            df.loc[index, 'ARI'] = results['readability grades']['ARI']\n","            df.loc[index, 'Coleman-Liau'] = results['readability grades']['Coleman-Liau']\n","            df.loc[index, 'FleschReadingEase'] = results['readability grades']['FleschReadingEase']\n","            df.loc[index, 'GunningFogIndex'] = results['readability grades']['GunningFogIndex']\n","            df.loc[index, 'LIX'] = results['readability grades']['LIX']\n","            df.loc[index, 'SMOGIndex'] = results['readability grades']['SMOGIndex']\n","            df.loc[index, 'RIX'] = results['readability grades']['RIX']\n","            df.loc[index, 'DaleChallIndex'] = results['readability grades']['DaleChallIndex']\n","            # sentence info\n","            # self.df.loc[index,'characters_per_word'] = results['sentence info']['characters_per_word']\n","            # self.df.loc[index,'syll_per_word'] = results['sentence info']['syll_per_word']\n","            # self.df.loc[index,'words_per_sentence'] = results['sentence info']['words_per_sentence']\n","            # self.df.loc[index,'sentences_per_paragraph'] = results['sentence info']['sentences_per_paragraph']\n","            # self.df.loc[index,'type_token_ratio'] = results['sentence info']['type_token_ratio']\n","            # self.df.loc[index,'characters'] = results['sentence info']['characters']\n","            # self.df.loc[index,'syllables'] = results['sentence info']['syllables']\n","            # self.df.loc[index,'words'] = results['sentence info']['words']\n","            # self.df.loc[index,'wordtypes'] = results['sentence info']['wordtypes']\n","            # self.df.loc[index,'long_words'] = results['sentence info']['long_words']\n","            df.loc[index,'complex_words'] = results['sentence info']['complex_words']\n","            df.loc[index,'complex_words_dc'] = results['sentence info']['complex_words_dc']\n","\n","\n","    def get_topic(self,df,index,row):\n","        # tokens = self.topic_tokenizer(row.clean_text,return_tensors='pt')\n","        output = self.topic_model(**row.topic_tokens.to(self.device))\n","        scores = output[0][0].detach().cpu().numpy()\n","        scores = expit(scores)\n","        pred = np.argmax(scores)\n","\n","        df.loc[index,'topic'] = pred\n","\n","        for i in range(19):\n","            label = str(self.topic_classes[i])\n","            df.loc[index, label] = scores[i]\n","\n","    def get_topic_single(self,df,index,row):\n","        # tokens = self.topic_tokenizer(row.clean_text,return_tensors='pt')\n","        output = self.topic_model_single(**row.topic_tokens.to(self.device))\n","        scores = output[0][0].detach().cpu().numpy()\n","        scores = expit(scores)\n","        pred = np.argmax(scores)\n","\n","        df.loc[index,'topic_single'] = pred\n","\n","        for i in range(6):\n","            label = str(self.topic_classes_single[i])\n","            df.loc[index, label] = scores[i]\n","\n","    def get_politeness(self,df,index,row):\n","        df.loc[index, 'politeness'] = row.politeness    \n","\n","    def get_offensive(self,df,index,row):\n","        df.loc[index, 'offensive'] = row.offensive  \n","\n","    def get_irony(self,df,index,row):\n","        output = self.irony_model(**row.cardiff_tokens.to(self.device))\n","        scores = output[0][0].detach().cpu().numpy()\n","        scores = softmax(scores)\n","\n","        ranking = np.argsort(scores)\n","        ranking = ranking[::-1]\n","\n","        df.loc[index, 'irony'] = ranking[0]\n","\n","    def get_emoji(self,df,index,row):\n","        output = self.emoji_model(**row.cardiff_tokens.to(self.device))\n","        scores = output[0][0].detach().cpu().numpy()\n","        scores = softmax(scores)\n","\n","        ranking = np.argsort(scores)\n","        ranking = ranking[::-1]\n","\n","        df.loc[index, 'emoji'] = ranking[0] \n","\n","    def get_hate(self,df,index,row):\n","        for i in range(3):\n","            df.loc[index, self.hate_labels[i]] = row.hate_output.probas[self.hate_labels[i]]\n","\n","    def get_emotion(self,df,index,row):\n","        for i in range(6):\n","            df.loc[index, self.emo_labels[i]] = row.emo_output.probas[self.emo_labels[i]]\n","\n","    @staticmethod\n","    def get_gender_model(df):\n","        path = 'user_gender_class/model/logistic_gender'\n","        mod = joblib.load(path)\n","        predictions = mod.predict(df)\n","        return predictions\n","\n","\n","####################################################################################################\n","############################                 LOAD MODELS            ################################\n","####################################################################################################\n","\n","    def load_gender_model(self,tweet_ids,user_ids,feed_ids):\n","        from nltk.corpus import stopwords\n","        stop_words = stopwords.words('english')\n","        stop_words.extend(['u', 'wa', 'ha', 'would', 'com'])\n","        print('starting user gender classification')\n","        remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n","        rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n","        print('now cleaning')\n","        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.NUMBER)\n","        self.user_feeds['cln_description'] = self.user_feeds.description.map(remove_rt).map(rt).map(p.clean).str.lower()\n","        self.user_feeds['cln_text'] = self.user_feeds.text.map(remove_rt).map(rt).map(p.clean).str.lower()\n","        n = len(self.user_feeds)\n","\n","        # call the user feeds df to df just for ease\n","        df = self.user_feeds.copy()\n","\n","        print(df.columns)\n","        df['sep'] = ['.' for i in range(n)]\n","        df['txt'] = df['cln_description'] + df['sep'] + df['cln_text']\n","        df['txt'] = df['txt'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n","        user_info = df.txt\n","        print('finished cleaning')\n","\n","        print('now predicting the gender of each tweet and descrption')\n","        text_predictions = self.get_gender_model(user_info)\n","        print('model finished predicting gender')\n","\n","        df['gender'] = text_predictions\n","        male_txt = df[df['gender']==1]\n","        female_txt = df[df['gender']!=1]\n","        print(df.columns)\n","        print('male tweets')\n","        print(len(male_txt))\n","        print('female tweets')\n","        print(len(female_txt))\n","        # both these contain the users feeds and their feeds\n","\n","        self.df.reset_index(drop=False)\n","        self.df.set_index('user_id',inplace=True)\n","\n","        self.df['gender'] = np.nan\n","        self.df['num_male'] = np.nan\n","        self.df['num_female'] = np.nan\n","\n","        for id in user_ids:\n","            info_user = df[df['user_id']==id]\n","            rows = info_user['user_id'].astype(str).tolist()\n","            if info_user.empty:\n","                print('dont have useres feeds')\n","            else:\n","                gen = info_user['gender'].mode().values[0]\n","\n","                # self.df.loc[id,'gender'] = gen\n","                # self.df.loc[id,'num_male'] = len(info_user[info_user['gender']==1])\n","                # self.df.loc[id,'num_female'] = len(info_user[info_user['gender']!=1])\n","\n","                self.df.loc[rows,'gender'] = gen\n","                self.df.loc[rows,'num_male'] = len(info_user[info_user['gender']==1])\n","                self.df.loc[rows,'num_female'] = len(info_user[info_user['gender']!=1])\n","                \n","\n","        self.df.reset_index(drop=False)\n","\n","        try:\n","            self.df.set_index('tweet_id',inplace=True)\n","            print('SELF.DF INDEX HAS NOW BEEN RESET BACK TO TWEET IDS')\n","        except:\n","            print('tweet_id is already the index')\n","\n","        if 'user_id' not in self.df:\n","            self.df['user_id'] = user_ids\n","            print('\\n\\n\\n added the user ideas \\n\\n\\n')\n","\n","        if 'tweet_id' not in self.df:\n","            self.df['tweet_id'] = tweet_ids\n","\n","        del df\n","        print('gender results')\n","        male_usr = self.df[self.df['gender']==1]\n","        female_usr = self.df[self.df['gender']!=1]\n","        print('male users')\n","        print(len(male_usr))\n","        print('female users')\n","        print(len(female_usr))\n","        print('finished gender')\n","        print('---------\\n---------\\n')\n","        \n","\n","    def load_topic_model(self):\n","\n","        MODEL = f\"cardiffnlp/tweet-topic-21-multi\"\n","        tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","\n","        tokens = self.tweet_df.text.apply(lambda row: tokenizer(row, return_tensors='pt'))\n","        with torch.no_grad():\n","            self.topic_model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(self.device)\n","\n","        self.topic_classes = self.topic_model.config.id2label\n","\n","        s_MODEL = f\"cardiffnlp/tweet-topic-21-single\"\n","        with torch.no_grad():\n","            self.topic_model_single = AutoModelForSequenceClassification.from_pretrained(s_MODEL).to(self.device)\n","        self.topic_classes_single = self.topic_model_single.config.id2label\n","\n","        self.tweet_df['topic_tokens'] = tokens\n","        print('loaded topic model')\n","        \n","        \n","\n","    @staticmethod\n","    def run_offensive_model(test):\n","        current = os.getcwd()\n","        new_dir = current+'/offensiveness'\n","\n","        os.chdir(new_dir)\n","        df_scraped = pd.read_csv('labeled_tweets.csv')\n","        df_public = pd.read_csv('public_data_labeled.csv')\n","        df_scraped.drop_duplicates(inplace = True)\n","        df_scraped.drop('id', axis = 'columns', inplace = True)\n","        df_public.drop_duplicates(inplace = True)\n","        df = pd.concat([df_scraped, df_public])\n","        df['label'] = df.label.map({'Offensive': 1, 'Non-offensive': 0})\n","        X_train, X_test, y_train, y_test = train_test_split(df['full_text'], \n","                                                    df['label'], \n","                                                    random_state=42)\n","\n","        os.chdir(current)\n","        # Instantiate the CountVectorizer method\n","        count_vector = CountVectorizer(stop_words = 'english', lowercase = True)\n","\n","        # Fit the training data and then return the matrix\n","        training_data = count_vector.fit_transform(X_train)\n","        testing_data = count_vector.transform(test)\n","        model = SGDClassifier()\n","        model.fit(training_data, y_train)\n","        preds = model.predict(testing_data)\n","        return preds\n","    \n","\n","    def load_offensive_model(self):\n","        test_data = self.tweet_df.text\n","        preds = self.run_offensive_model(test_data)\n","        self.tweet_df['offensive'] = preds\n","        print('loaded offensive model')\n","\n","\n","    def load_irony_model(self):\n","        task='irony'\n","        MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n","        tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","        tokens = self.tweet_df.text.apply(lambda row: tokenizer(row, return_tensors='pt'))\n","        # download label mapping\n","        mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n","        with urllib.request.urlopen(mapping_link) as f:\n","            html = f.read().decode('utf-8').split(\"\\n\")\n","            csvreader = csv.reader(html, delimiter='\\t')\n","        self.irony_labels = [row[1] for row in csvreader if len(row) > 1]\n","        # PT\n","        with torch.no_grad():\n","            self.irony_model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(self.device)\n","        self.tweet_df['cardiff_tokens'] = tokens\n","        print('loaded irony model for tweets')\n","\n","\n","\n","    def load_emoji_model(self):\n","        task='emoji'\n","        MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n","        tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","        # download label mapping\n","        mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n","        with urllib.request.urlopen(mapping_link) as f:\n","            html = f.read().decode('utf-8').split(\"\\n\")\n","            csvreader = csv.reader(html, delimiter='\\t')\n","        self.emoji_labels = [row[1] for row in csvreader if len(row) > 1]\n","        with torch.no_grad():\n","            self.emoji_model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(self.device)\n","        print('loaded emoji model')\n","        print('---------\\n---------\\n')\n","\n","    def load_politeness(self):\n","        ## Scoring each tweet based on politeness \n","        class SimpleDataset:\n","            def __init__(self, tokenized_texts):\n","                self.tokenized_texts = tokenized_texts\n","            \n","            def __len__(self):\n","                return len(self.tokenized_texts[\"input_ids\"])\n","            \n","            def __getitem__(self, idx):\n","                return {k: v[idx] for k, v in self.tokenized_texts.items()}\n","        from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","\n","\n","        # Tokenize same way as training data\n","        model_name = 'roberta-base'\n","        path = f'politeness{os.path.sep}results/checkpoint-52500/'\n","        print('loaded politeness')\n","        tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","        print('politeness per tweet')\n","        with torch.no_grad():\n","            model = AutoModelForSequenceClassification.from_pretrained(path).to(self.device)\n","        tweets = self.tweet_df.grammartext.tolist()\n","        test_encodings = tokenizer(tweets , truncation=True, padding=True, max_length=256)\n","        test_dataset = SimpleDataset(test_encodings)       \n","\n","\n","        trainer = Trainer(model=model)\n","        predictions = trainer.predict(test_dataset)\n","        self.tweet_df['politeness'] = predictions[0]\n","        print('loaded politeness model for tweets')\n","        print('---------\\n---------\\n')\n","\n","        \n","\n","    def load_psysentimento_model(self):\n","            \n","        tweets = self.tweet_df.text.to_list()\n","\n","        # hateful\n","        analyzer = create_analyzer(task=\"hate_speech\", lang=\"en\")\n","        self.hate_labels = ['hateful', 'targeted', 'aggressive']\n","\n","        predictions = [ analyzer.predict(preprocess_tweet(txt)) for txt in tweets ]\n","        print('predicted hate of tweets')\n","        # predictions = process_(analyzer,tweets)\n","        self.tweet_df['hate_output'] = predictions\n","        \n","        print('loaded hate model')\n","\n","        #emotion\n","        e_analyzer = create_analyzer(task=\"emotion\", lang=\"en\")\n","        self.emo_labels = ['joy','sadness','others','anger','surprise','disgust','fear']     \n","\n","        # e_predictions = process_(e_analyzer,tweets)\n","        e_predictions = [ e_analyzer.predict(preprocess_tweet(txt)) for txt in tweets ]\n","        print('predicted emotion of tweets')\n","        self.tweet_df['emo_output'] = e_predictions\n","\n","        print('loaded emotion model')\n","\n","\n","#######################################\n","# MAIN FUNCTION TO RUN THE ANALYSIS\n","########################################\n","\n","\n","    def tweet_analysis(self):\n","\n","        informer_db = self.load_informer_data()\n","        self.get_device()\n","\n","        print('loaded informer data')\n","\n","        #####################\n","        # LOAD IN THE DATA!!!!!!!\n","        #####################\n","\n","        # ALL THE TWEETS IN THE MULTI-SOURCE CASE - store by tweet id\n","        all_tweets = self.get_the_tweets(informer_db)\n","        self.df = pd.DataFrame.from_dict(all_tweets, orient='index')\n","        self.df.drop_duplicates()\n","        user_ids = self.df.user_id.copy().tolist()\n","\n","        print('loaded in ms tweets')\n","\n","        # ALL THE USER FEEDS!!!!! STORED BY THE USER ID !!!!!\n","        all_users = self.get_users(informer_db)\n","        all_users,tweet_ids_feeds = self.add_feeds(all_users)\n","        ## ALL USER FEEDS!! STORED BY THE TWEET ID!! WILL!!!\n","        feeds = [ {'user_id':key, 'description':value['description'],'text':tweet['tweet-text'], 'tweet_id':tweet['id']  }  for key,value in all_users.items() for tweet in value['feed']  ]\n","        self.user_feeds = pd.DataFrame(feeds)\n","        self.user_feeds['tweet_ids'] = tweet_ids_feeds\n","        self.user_feeds.set_index('tweet_ids', inplace=True)\n","        print(f'\\n\\n\\n raw feed len {len(self.user_feeds)}')\n","        self.user_feeds.drop_duplicates()\n","        print(f'\\n\\n\\n feed len after drop duplibats {len(self.user_feeds)}' )\n","        self.user_feeds = self.user_feeds.loc[self.user_feeds['user_id'].isin(user_ids)]\n","        print(f'\\n\\n\\n feed len after not considering the feeds we didnt pull {len(self.user_feeds)}' )\n","\n","        print('loaded in necessary data')\n","\n","        #####################\n","        #####################\n","        ##############################################################################################################################\n","        ####################################################################################\n","        ############################################################################################################################################################################################################################################################\n","        # TO TEST FOR A SUBSET OF TWEETS\n","\n","        # # remove existing\n","\n","        done_ids, done_users, og_df = self.load_existing()\n","        print(f'\\n\\n\\nalready done {len(done_ids)} tweets')\n","        self.df = self.df[~self.df.index.isin(done_ids)]\n","        print(f'\\n\\n\\ now have {len(self.df)} tweets left to analyse')\n","\n","\n","        yusers = self.df['user_id'].tolist()\n","        \n","        user_ids =yusers\n","\n","\n","        # print(f'\\n\\n\\ reduced user feeds from {len(self.user_feeds)} ')\n","        # self.user_feeds = self.user_feeds.copy()[self.user_feeds.user_id.isin(user_ids)]\n","        # print(f'to {len(self.user_feeds)} ')\n","\n","\n","        ##################\n","        # DROPPING DUPLICATE TWEETS FROM BOTH DATAFRAMES....\n","        \n","        print(f'have {len(self.df)} tweets loaded in')\n","        self.df = self.df.copy()[~self.df.index.duplicated(keep='first')]\n","        print(f'now considering {len(self.df)} tweets')\n","\n","\n","        print(f'have {len(self.user_feeds)} tweets loaded in')\n","        self.user_feeds = self.user_feeds.copy()[~self.user_feeds.index.duplicated(keep='first')]\n","        print(f'now considering {len(self.user_feeds)} tweets')\n","\n","\n","        print('loading test data')\n","        ## END\n","        ##########################################\n","\n","        # load in ids\n","        feed_tweet_ids = list(self.user_feeds.index.values)\n","        tweet_ids = list(self.df.index.values)\n","        feed_user_ids = list(self.user_feeds['user_id'].astype(str))\n","\n","        self.df[['polarity', 'subjectivity']] = self.df['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n","        self.user_feeds[['polarity', 'subjectivity']] = self.user_feeds['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n","        self.user_feeds = self.tweet_cleaner(self.user_feeds)\n","\n","        self.tweet_df = self.tweet_cleaner(self.df.copy())\n","\n","        ##########################################################################\n","        ##########################################################################\n","        ### LOADING IN NECESSARY MODELS\n","\n","        \n","        if 'tweet_id' not in self.df:\n","            self.df['tweet_id'] = tweet_ids\n","\n","        if 'tweet_id' not in self.user_feeds:\n","            self.df['tweet_id'] = feed_tweet_ids\n","\n","        print('put tweet ids back in')\n","\n","        self.load_gender_model(tweet_ids,user_ids,feed_tweet_ids)\n","\n","        print('loaded gender ')\n","\n","\n","        loaders = [self.load_politeness, self.load_topic_model, self.load_irony_model, self.load_offensive_model, self.load_emoji_model, self.load_psysentimento_model]\n","\n","        [load() for load in loaders]\n","\n","        self.df = self.tweet_df.copy()\n","        del self.tweet_df\n","\n","        ########################################################################\n","        ### SAVE!!!! ################\n","\n","        save_path_t = f'tweets/{self.hashtag}/{self.hashtag}_infector_scores.csv'\n","        # save_path_t = f'tweet_analysis/output/{self.hashtag}_tweets_classified2'\n","\n","        ########################################################################\n","\n","        del self.user_feeds # delete so code runs smooth\n","\n","        ########################################################################\n","        ########################################################################\n","        # CLASSIFY EACH TWEET IN MS\n","        ########################################################################\n","\n","        score_funcs = [ self.get_sentiment, self.get_grammar, self.get_readability, self.get_politeness, self.get_offensive, self.get_topic, self.get_topic_single, self.get_irony, self.get_emoji, self.get_emotion, self.get_hate ]\n","\n","        # SCORE EACH TWEET IN THE MULTI-SOURCE EVENT\n","\n","        tweet_df = self.df.copy()\n","\n","        t1 = time.time()\n","\n","        [ func(self.df,index,row) for func in score_funcs for index, row in tweet_df.iterrows() ]\n","\n","        t2 = time.time()\n","        print(f'finshed scoring tweets in {(t2-t1)/3600} hours')\n","        print('-------')\n","        print('---------------------')\n","        print('-------------------------------------------------')\n","        print('finished classifying all the tweets')\n","        print('-------------------------------------------------')\n","        print('---------------------')\n","        print('-------')\n","        #################################\n","\n","        ### SAVE AFTER CLASSIFYING ALL TWEETS\n","        ################################\n","        self.df.to_csv(save_path_t)\n","        \n","        print(f'DONE WITH {self.hashtag}')\n"]},{"cell_type":"markdown","metadata":{"id":"x27JS-gN8X-o"},"source":["## RUN"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bbwJ9GEpucoO","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1e8bcca6ec544530a72704ff790b62ee","814dfc10c76d48ee962ff91cb94016f6","8e275c39bdd84bc784b80a7e6c845b91","bd7600b521f14953a0c22f7110920998","3724e2a3d7ba43b6afc2e1af3e7a9a40","fc7645876275460caa8c5050853332ad","eed504389ba44b0fb86fcac3e6168a1d","7cd52d2f9fbc4025b931ea774f31c2e5","049f8544c13e4abf9000bebd53c5684e","9212dc992d7c4e4694471121b4f4dcdf","c361f1c1d58b41ca98298e87e5bdb479","b8b893772264427b81a6cdca8f436b1b","94d61af9c5c040be9d8b4c1f76ef59fc","29b43712b65b4b8a8f89e36ab89e854f","c31d7f8d9461425b8e02edae20d0a04f","094ddf7d6c3a4d60950902a84a57da86","eb6ae20811374cd8a41d411e6a45b027","a7bc1e767ec14f588a08d363e391bc9d","f271e8957bd24ef79fe83afb2cc86bd4","85c4ff56634f4b7d8a76a635e33a7e6e","601d300280064f3db1d8aba5ee157f1f","69d76e1a6497469583f4e091533b1259","c347e0d7ac2b4d399baa35c46611d86c","04d2806680894e16b3174451a24af6fe","044e3b6284d14be68a0d08f61285a5c3","cd749588391e402285fde173a9ff41e1","7d61291bb958467a95f80a1850fc4aa0","4f2d6dd69842458dac0fdfc654d82705","0cbced40d26c4467a91456d5a1b4c2ca","71ea049923874bb7a23e7a37282a9065","7dee2c8005b34710889a6bc5090f1964","c62bce542a304f30a75af6af12a7135e","23b7b88c92504d6fa6ffedae44985e07","5a83231ed8f5442f97591e665446d63b","0d77834af0bf43f88c256a06a4b4b759","f648046cc78a4e7a9b8ea547b2057cc5","88ff328351d74f4aad0d0d38c2f9fba1","dc9688066c4c477fab8ed5939439055a","6c6f91d7fb4847939e03f637fdbacbd3","4ed66401043147bab2a6dc6224b24385","888b89f406da4a83a3e904c4b89f78ab","2f4f0e1f6c624f4ba6a472ffa3a550c4","827271df5d094b3d82839df0baadf32d","c7fc261d97b547ef927c58255e3bedb8","9dcf9eebaf7044ee8f354dd5c9296002","8b0bb48330114d57ab0a4e43f892a963","ea2562d266234b818333f685c4d33e45","4277f3a192e048b2969579541a18e648","915fc04f27ae4691a371de844dd8cdbd","d962d19ed82044ba98748e9c6a8923f6","eab385656cef4055bcd30f92def0a722","db2753627e8546639152f7807b2cddec","0511099fde84484ab8b3a16cd1c0d10f","b6e06322a29e4008a7ebde799ab784a0","e6ca94781ba14893ae16e2bde67a8ee6","c8f70b2d510e4a359f3e978456ead912","2f5639b5949642c2bee792c166cbb075","ff5d8dacf27f416a8c63d2cc05235df7","20232adcff5b444c91fa19be3639b05e","e22acb1d56064a02bb2270564322c331","1095baa07c9c4011a14f47c40a357a78","c67f46a22370444089558d5c1687970e","3d18c0ed820e4e9088a07175c08fe24e","123ebf8af6bf4fd89fb380e3f1b4e977","20b0b27c35fc4b70aa6bb8e45a36d452","3c60eb654c944eaa8e42b69a969b7802","53f11ef0cb4c4110a9992b4f586026bf","7a05bdf5d67f473da88fe87991cec7a6","c260981c1f334cbb89453f231ff8f80c","b2ed4b237af14ba9a3805e48702cd423","0d6403ad77a24ecb9525298a66d744a4","55ac432e6d4d4c038ad63146bfd1b48c","fc2ebaa163d34d3a85a1d0300bb2a8f2","4a2e0d1303f14c5b9c0cfc1dcc9824d0","509dd31fbe324d5da67950da8d55653b","294a4431de0e4b9fb273366ba9e3118d","512902fb6d784bd893976b3b6982d0d4","aab22b4db8314690bd52351fa72f654f","6a4b087ca0004ab6867d78e0580ad781","8ef147034c2340f9bad0cfecbb2ef63b","87af2b3718994777b5330748a6765bd4","700f24d7eb054b4bb7c3710c32a661e9","5c5f8f891fd548d2ad6cd6cc69d28f3a","a8080b62fa944e7baf20e32f620f678b","7ec075ecec69419ca4c3d4f640e3d1f9","db597bd479b7492db40a6e48e0e15467","2215eeb606984a01a499efcf5b72a164","5892326268494d60a0f3143d5027bda3","cae09868748b49bea9e2d0c67e955cf9","a8bcfd6fd287448b9316e181617eb840","cc73d40675e64037b3fd0551329ed1c8","a31a84150b4a483a81bbf1991e2a4f22","f8abfdf1b1a14537a76e739eb0944e06","b0b9d3afddb245ae88e20cafac6bbc60","2dbc4467a70241e2881d1a6904eeb719","d3380cf760c84fedbd5c750fa99eb7a3","5d6eaebcabc14490bf69269f6a15ca4e","679349c1eca6447eb312641187806a3c","10094c980c5c44adb75fb9a3c9fa20ee","7621806febf048af92acaaf2e978e7ee","ddb6850c8aa94a5a9a213718545c33a4","b992f5cac33b40c993858bf5d4f8ac34","ffecb9fe147a477cb35ad880f7b0b90f","31ac4172e71941f1b6c17ab83473deaa","bef130ea0f4d4b6597b45c97c5405529","6f824c17752c4dd495be9e2c3aed5090","02fb009b28c247c184c9e90fa3d1b694","e667710a65794539af1edca2d5ceffb2","75f316efb1f243448931a0050d8b1448","843997a6adb6414fa6b7820d82c023c7","5b2c5c7fa12745b698549c379af14861","9da9cb359a774716801778b1005df8f1","6b004101280c4abc83420044d5993a22","87d3a3a16d9c47a7ba825528a5476c9d","196965f148c54a09a3913e5e32385b5c","07b18ce2c2fe454f91ac82f4af4661f7","b6539bca8b6645df926832d29447a827","9a3f9b2bad8947bd80343b6a72e7e3ba","2ebf1fd5313646488bf43d81d7e8587a","135edee677144ccfa906358368f595bf","c3e083af0ecd477cb11204d79d4703b7","86d483f9716140559c85e9e076c11be4","156efc3678d341358b4b762e65d46531","2517fd8dbb8d48b297c9954f3e5aa02e","daac5c84feec41e69ba3c56e98f677bd","b84902c1d87045aeba1fed74d4e2bf4d","1236affd22974942998187b843648761","b8c5fa6afeda4ab183e65bf16f6ed46a","8bbfbd1228b947209b99af4f42372184","c96200cf5c854822b61623b6bee283bd","c3c11641f34f4b678f79dbf849733d62","ef1193731c2146e086cf0dba5f468c4a","945791dff7d34baa952f86dae96a3ab0","4aee74748d80457eba84a1b10cbc2b03","0b2f14b4b3914f48819705087e250ecb","f0486db3b9a642b083dd970c640bd9c8","78758f06d6d8438688c5fd8beaf75c9f","e640e6d3401a4b1588e3a60cc85034c1","25a9fd86463c4caf8952958c8e0f8cc1","dd1925841b3a4127b453a8e538a725db","1cd2764448f3435e940f4196d4230ada","f6f24c58a3f2478695273ede05eee321","0b31cad79f5443e0be97ca7260a922f9","3e7f5ea2353343afa7698e8748a6ff77","dc1d2e5d12454e0fabfb9578707cd885","b560c53281454e7bb89105d4b2fdba64","6ec175606b0140e1a7cc8dd9ab35624e","52ead377e4534b3eba8aad2f15db1785","07c9fdc1fa1c4fc8b67acce61141140a","57f282c972eb44d2914a36a432a4d831","d807259a82a84e0094321e1b95776f73","f10402597d6749098f5d2d49103745f4","99d4bf75f093439782c7ba6379a35b40","9e4c7d5558f2401b9d5abb32fae38f04","d9600b9dfaac4f048c124fa81e6175c6","eb1acdfeee644a83815033c5f6bb3f29","1b4ec5a98c344e27b1db3baad5ada962","040e95b606b443e68ba335a31c5434a4","4364d9660f6a4e8e9325f67ae989d396","01c27f5a156b4a1091c94de69ff768dd","ef82f2a1d27c4b129c3ed0849bcb0702","c33fce77ba474461827e485035910301","ccaab2ec87504edebffb64f241c9017b","e8e3eb37964c4394b6218ecf510f2179","aa3b9ad00bee4afabd31d221726dd71e","b35074398ed54302894812487789aeac","814a2fabb9184dba8df59f210388b944","27d8705ea8f64112bdda2721a67badbe","2498495eb5374e058ac0ffd07abc2fdd","7388e2ac97db4eda88ea3bb37cf261c8","7b1dee8e929b405c9318862ed7c50bc9","e21a6ce0c9bb47339721c2708bdf200d","5062f58e0dbe4f2da833d88341a72118","24a6784fe22a482ea32bcc6dd423d6ea","e73c57a38b4c4a878185b3d87de48dec","9a3ddb15685249cc93b7f7f79c22532b","f630256e16b44760a12edc436372a783","bda157d32495446b9a7fd4ec736289f7","d7ebdc8bca30458e85fdf20361069fff","d789bf7f93bd469dae16ceeb007af9b7","d50b5b4e73ff45c6b5caeb498f7924e6","a9619d14302244d89495996c986966a8","b6376770afdd4ed4b79a8a1681f4d2da","1076ae02cd83481fac0a1b2a73c5db67","f2fdb63df5c04167a2babd02376f15fc","709b2e3f628b4760bebce49635ec769b","f9b43ed9f19b4547b56963e17382b408","14f492d0fa584b1a8c2047c32eb483c6","62c767720b5a462fac00adc7143aa680","4e26466379ee4db6b2639d2f96001b15","68b74467a33e4939a15d19ccbf0ca81b","9587f10c0b0e4bfba234cc90dd60e686","3045a5d266b74e159d9446132e9cda11","a692ce7eed8f43e7984679914c5c5d68","a670450d54444263bd16ee1047ee9959","47744f0720624e4ca114d1deb1cc42ee","cbaaf8ff6b21481cbdc2f2d85270ab2a","424de16e72e640eda4de142a6ae53406","92c8be4b22574a4c9da5b5cbfbf81510","38ea82a173384fbe8285ae8c341f2afe","f2633a296f6245deac5d4caccf1cf701","467f5ee458c948dd82c53b38cdb0d51f","e86f573337684f749cbc440707f7f79d","cabfa999b57d4fe89cf79d2187200ca2","344aec7a3ad445618e3ed0d264f07eda","354ae5162bc449939ba1f12f56a46aba","b95e8dbb27d4472fbcce79b7486f4f38","44dd25fa84fb4b6187fb2bc68b4fd0b5","6f8c239b96ee419487d039151990229e","c4525aef67a546619976cd1d21ba6941","eb43c3de6a1e487b9ee87ba140f8a546","8e131791d87d48fa8241992d35130b21","8546f0a45dcb4b18bef5455fefb6bad6","a2ef263201d841aa823d10a1038697a4","47b7ea5f5bb44726af40754ce92d1aff","d20c9aa7118d4e269e24e8363c9122c9","8c57887138d64466887ef510933727ba","981cea9ee3a44dbda7a4be7f40d60796","5cb9b7777c0347699a387cfc8d3b887b","0a25fce6e0e8400b8ca107f17fa9d220","e897e4ce61e2464c89f88aea3aed5717","8c15925b81bd4570a9f304fe7158b202","2b3a414f46754138b5e7a4bcb813ebb0","4446888226b04ef090085a690d19ebe2","7c91c412ff8348d4a879c7b83d6ca446","3da60078721048e9b022f0c51aeff984","debe0c32ce304457a0df984d9ecd44c7","e420a7bb94a341f48ffc55dea9301359","52e84926a4414b5cb1e3a9befc96db71","21391db14d284f819ab84485bea81b56","a7ab60ead71243ffab4080cbf824f432","d8d2806bce2c4dfe96a1d03b8cf8c370","c09df915594647f2a3ade3b82d870e63","a9d7203a26e848698c182038245acc06","8534f12c20a14a089e2432478c1464ad","01c95f3e64674c9489899fc944895a2d","f79f383f17f54c43a31a015ec3211f9a","3307647bbc80428ab314d1ea55e45150","76f8e631873f47c7a440a726b53c63be","57ea72f5e23f4f0cb2b39fd42bdc067e","280e1ddf843947eca1695d38f21597b6","8bffab14ca8e4116bb9451c0c3e214f8","3e6d40d52dc545198212e4309b216c93","1bb93ee340f44a8f97841575995dfe5a","18875ed980b84179aa427ce614f9ced2","d67823b1de2e4ecfabf54ee501dd3341","ff6fce561d1347d5b79469be80f47e02","33b776df64e249f7a598be1b4c97b2ed","e3a2adef99ef40ab81ec5f8aff26ed65","35f939b833e84ef589d317d3a3e9e8e8","0190b75c09b74915b919b42ce145b116","bfb28273ee4c4ca9bbcf8cbd71f3a0dd","8adcf22ffe1c4cc4bcdfee27620fe7d6","11d27ce79dae45e3be48245e13072cc4","a19fc21b0b154e4e818235512eabccf0","43abb041d29d49dd9eb41a9c36542681","2ede2090fd97408c9072b2bd2e8335e1","a7ce58b5bb7e40a2b3b86f079bd50475","72fffa1f902640c4849134654cacd6f2","d14cd270ba7d46b990ac5e0fe2f643e9","49fcebb49ba84fbd897f94b16f94052b","4e094d24453f42c0af9811cac4ae8e86","fbac694e7002418096fd3a7a41e5e743","bc43cccf60c8479a92ecc6940825f418","68c7eb8e6d954fe8b01b7a7098b41ffa","47e1d4b9ba6a4ac9ad7b461f8e9919a6","67595d5e20ad47159c63de8f00580dc1","42fdde2e26434cfc86ccff3e9d3daa95","a89a82c684c04d32a5f6a25b922bce98","ea4235d09d62481d8a8aa1781b0bbbdb","5bfc03f34e6f479794c90d07f73b3d87","68d65ac4113040f2a723195ee0d7b27a","45ceebe7fa964e049b684aac38a9a3ca","85a72a6dd1af46d9ae1efa21147b28c1","4113fccdf45e411e99e25607cacfd903","dbe3abc18786445fa90a50b06ae6610f","411e41613c184b61aa6ab54315b7f65c","8d8662caa54b407b90b44fa7ad769655","72f5b008faf14a739dd60249b23c522c","ed9c1d09756c44e581c37c48dba0be89","71e61fe462c348baa1eeb6784e501bd0","0672f0f454cf423f9202f8776bd46964","4f3b3fd4ab8447ef98ffa39b6257e554","becabb81727448f89ba7d9f906591cce","55ae0e0ddd454ef29e86c0cff07e05cc","33c94d79237443ce8d58b82c55e57799","7e05b5216ebd4c108b1c1e14b116f6d0","ef8e1e41ac7e4dad9e0e501e30e97175","2be53c27788045e098d28ab920d26b73","11b8ec2d04874e209bc04ae9ed7a7274","e72b6ab8a6c64d4d9df520e412c9334d","1911e17fc8414b1286b10444efab50e6","67a23237a36140cbb324876d4c98c58d","f2b4bc353b3148659e8352bf21e37782","7eefc44955bd402a8e591aa82f8d2124","450df2723a724f70b1dad6b760601ce2","5b5a88dd937b463f82fc07f0fcc3b6c2","a83e1bb253ca4def87758334faee6044","f70a776c7eba44c5be7286296f7935a8","7c1f17fc58f24f78ad620f0513933dd6","e2b38437a9b24a81bce160b050a3e570","79bfbd9706e14c2cbfe396fa4759bc7c","8acd3b92231042409bda794623622a1b","90a727850f6942b3a3823c9c31d41df6","f35f4b8e877e4e49ad881adb166572ad","16f1c4dee39b47e0ab1edeffebca9f65","350b22d0b0cb4be88462ba82fa0550e0","e2bc98b75c9845559333f910d4f95b13","052a16d6875b44bea85173f0233a247a","69719c9355ab4c469d648b8fd66e33d3","b1052d287dac4392b5e99b61e93c8338","00f249aa33384b0589296d6b09f1a324","23886942a73f471bbafb0ac2c5c464a2","9e1b47c5a2e5404db774057ee9dc7fb5","02256998cc0848209164767e704d27ad","12cc0ac3e5784da99456a90dbca41bbf","415693a84871445eb484108d075c0a26","6c3eb7fc59f04b208a8d50151e5e4cfb","8b8281ef6574442292da03a05be4b464","1280ad989a03407f992e18531a831b08","0e217a16ef9f428ab8eeb0853d5c89e9","b5fdbbff8e234978a45e8fbc1eb75bd2","c5c45f507bb6466bba00c4f6c6584871","7250a83e27524a9fb1f9eadaa27b1c40","9083ec2d535446a188ad635471165573","ea92e0a90eaa4094b1c516845028997f","2f5315e928dc4092aa78e61b140cb0b7","aad3f902f5974e7c95632e6b72dbbcc2","96341b5327a744f5a140e3dbce661c92","49bb7bce3c24417ca94248c2f957e207","ca001386b14b4e308ceec8da2236479d","1e558c27f3654436a3fa2f965aff92d5","ed328dad63274a7ab72542389666ce04","530cb215e097480ca7579feef5810719","5d66bf1604c24454917fb2acf7ea16f4","8cad5a418ffe488d86dfb7f0b9d2c90e","cf4cea6334ed423ab44e6d0159953fde","cee15b894de746edbbb17914aed165cd","35975d06c6ee49ff8bcacebbd27ad1b6","6146acd516cd4421a066689b291f31cf","c62cf33a27024dc3b4cf4f701e61091f","dd6c608aaff542aea478edabb82bbe6a","b5aef6eb395d4020b2c5301c132d11d0","da442f509c5e4e14925a5fd2157b61cb","67e64b8e475d4a3fac703228e2ffb19f","66935b526227410a88f8b9e8b7e1c447","a3986e74ecff40b2b7a5b1900e483253","aac5f6dd661d47888c5cb4b353d01975","34431e140e0e41e3832aa9be59d5a893","6c8cdb244cfa477e8a08eab9fe4c64ed","e32bac526be24e94a51dceeee870d62b","8d485de520eb4c4f9fd5695595ced6f0","3f136618fd0549b898dcfa38cb465cf9","0bf74843adb24287a5cd80b4f8a14817","b04adc9615f64957bfa1e16689550cbf","b414b551e01e4c98a314e0e5baef4181","bb2605d87f6f486c957568394560ed42","d5695ee0f1c3445c92ac30967bdec0b4","e63da8b0477848f0bac46d60289a43ad","264e2297223a4729acb050dad3341f77","d0936bf385ac4de0b26e0bd26e7621b3","05fc08d03555472faf58e959c25acd12","192de79e584940d789edc196af1afd39","868fb4b8dcc04f00b9d304597e04d31f","3f4224b753054b9fafa6d22442d46190","3a0498c705a54ec88e0098af8beb7805","ed1b1e91e00248ca9adc65625ce0a1ac","563a8ee40438418cb7cab4e12a3ddc69","84ffbafd0f1b48578ef79b9a9990d8da","02e5a58892ed482a80cd092c416ac660","e7f60e5e2f514e08b64a681d7f3a2d4d","949bfce1b16442f0bd3e70e0cba1c7b8","68f02f44858240a98af74b8ac88cb834","f34586b4efdd4e0b9e7b5d3465f5e070","cda245baa5df44b4a4ae8e17a2889b8e","d31441515f5a42ffa6a481708f2ccfce","6f16373c93e644408fa3b2cf985348df","0ad79761f72b4eb6b4627bf11ed9ec71","c414af8c34ef4372b20a1e943d5b4a17","3471efd7603e41d08b95516f47267439","d031c730f7d44262b40165d9383c1952","2c156fc1d54e4c119f5f106c60e0e5d3","3a2cdc0ac4d54560a05920f51f969428","f660eac20fe34a9e92aad5710f1a29ab","df432533ff434ae79ebaf6a9a8a1bc1e","deba63c55514483f8b101070b69e2ddf","0a5fe420c2454be1a1334dc73128044d","5942e0aa1d484a6dbc249520a068ae08","49c1110bd1aa4f73be03fcdf3cb8dc31","913d1ec8784045049fdccecfae4df75a","b625a9fa1a154e8fb0216c86df209729","0069442251914347ace826b69affa619","5591984ed5514c7996b55be803c75f09","6712bd3e695a4c4986a17796aebfb9e8","540b2ccc8a8248dcb89f3e0f7e71b687","ca79b46addba4a76af3dd8de6bbd21a3","2a27f809097f4011bd4362208766c28f","28af47f03e734bf58a3b9ada3b3da72b","c22bde16e6544ce48efcacd7d52bf75d","d546088dae044c36b7a24770eab591ce","a246d855b9ed458a947d848e7fd8e3f6","8ce51032fabe4a30bb432f20c78f9362","7e692a49cf5e469d9db93e4fbc64f122","44eb9619edf643fa98b94e12827b6360","fed498ea3e4c46398a4b20d8cd310625","06f6373a7dfd40479e09d07f464ff01d","c66a82f9c9eb4b76a3ac790fabd6374d"]},"executionInfo":{"status":"ok","timestamp":1662854286632,"user_tz":-60,"elapsed":2309371,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"f3da91ec-e2ea-41d9-cb87-d2c4100a26a7"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading LanguageTool 5.7: 100%|██████████| 225M/225M [00:03<00:00, 62.3MB/s]\n","INFO:language_tool_python.download_lt:Unzipping /tmp/tmpdikbp865.zip to /root/.cache/language_tool_python.\n","INFO:language_tool_python.download_lt:Downloaded https://www.languagetool.org/download/LanguageTool-5.7.zip to /root/.cache/language_tool_python.\n"]},{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","loaded informer data\n","loaded in ms tweets\n","pulled data on 1508 users\n","\n","\n","\n"," raw feed len 147924\n","\n","\n","\n"," feed len after drop duplibats 147924\n","\n","\n","\n"," feed len after not considering the feeds we didnt pull 147924\n","loaded in necessary data\n","\n","\n","\n","already done 2450 tweets\n","\n","\n","\\ now have 46 tweets left to analyse\n","have 46 tweets loaded in\n","now considering 46 tweets\n","have 147924 tweets loaded in\n","now considering 147924 tweets\n","loading test data\n","put tweet ids back in\n","starting user gender classification\n","now cleaning\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text'],\n","      dtype='object')\n","finished cleaning\n","now predicting the gender of each tweet and descrption\n","model finished predicting gender\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text', 'sep', 'txt', 'gender'],\n","      dtype='object')\n","male tweets\n","90926\n","female tweets\n","56998\n","SELF.DF INDEX HAS NOW BEEN RESET BACK TO TWEET IDS\n","\n","\n","\n"," added the user ideas \n","\n","\n","\n","gender results\n","male users\n","38\n","female users\n","8\n","finished gender\n","---------\n","---------\n","\n","loaded gender \n","loaded politeness\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e8bcca6ec544530a72704ff790b62ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b893772264427b81a6cdca8f436b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c347e0d7ac2b4d399baa35c46611d86c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a83231ed8f5442f97591e665446d63b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["politeness per tweet\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 46\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6/6 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loaded politeness model for tweets\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmhtma66v\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dcf9eebaf7044ee8f354dd5c9296002"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/50a78d02314329fbddfef47fdd5e1a3c7caf505195bf06f4d8263648bc56ceaa.fe0807eede1fcfc7436be17cbcc9a0bc5a06769ccb408c587f0ce6ae666b586b\n","creating metadata file for /root/.cache/huggingface/transformers/50a78d02314329fbddfef47fdd5e1a3c7caf505195bf06f4d8263648bc56ceaa.fe0807eede1fcfc7436be17cbcc9a0bc5a06769ccb408c587f0ce6ae666b586b\n","https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnq3t1c41\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f70b2d510e4a359f3e978456ead912"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/1daf1d394b649e9ab6c0bfc37629115ed7766cb32e0be8821110820610ba0980.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","creating metadata file for /root/.cache/huggingface/transformers/1daf1d394b649e9ab6c0bfc37629115ed7766cb32e0be8821110820610ba0980.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmptvkktjhn\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f11ef0cb4c4110a9992b4f586026bf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/88006e159b7014116256e91ec1595ca77cffffd2b060ee2b91bf7aed41644875.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","creating metadata file for /root/.cache/huggingface/transformers/88006e159b7014116256e91ec1595ca77cffffd2b060ee2b91bf7aed41644875.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmppx1_3r0u\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aab22b4db8314690bd52351fa72f654f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/047625f13f02ecae088036957c64a40f7bebb93fd2d2ad6324af4fc378fff90a.9f68d0ce76c33cdd199a6beeede63d9293d6005f826c0702d530ccefbcd221b7\n","creating metadata file for /root/.cache/huggingface/transformers/047625f13f02ecae088036957c64a40f7bebb93fd2d2ad6324af4fc378fff90a.9f68d0ce76c33cdd199a6beeede63d9293d6005f826c0702d530ccefbcd221b7\n","https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpguemmyq9\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae09868748b49bea9e2d0c67e955cf9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/86f379e4ef5dad9037395318b3d4cc8685000af32c64d37ab4158e8df91169cc.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","creating metadata file for /root/.cache/huggingface/transformers/86f379e4ef5dad9037395318b3d4cc8685000af32c64d37ab4158e8df91169cc.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/1daf1d394b649e9ab6c0bfc37629115ed7766cb32e0be8821110820610ba0980.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/88006e159b7014116256e91ec1595ca77cffffd2b060ee2b91bf7aed41644875.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/047625f13f02ecae088036957c64a40f7bebb93fd2d2ad6324af4fc378fff90a.9f68d0ce76c33cdd199a6beeede63d9293d6005f826c0702d530ccefbcd221b7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/86f379e4ef5dad9037395318b3d4cc8685000af32c64d37ab4158e8df91169cc.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/50a78d02314329fbddfef47fdd5e1a3c7caf505195bf06f4d8263648bc56ceaa.fe0807eede1fcfc7436be17cbcc9a0bc5a06769ccb408c587f0ce6ae666b586b\n","https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpp4x1kt9j\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7621806febf048af92acaaf2e978e7ee"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/ec25f52502749311e85eceb137b282f352376f01108c928c77b2e8d75bb645ad.520359c92ca91013f02967e1f505f9e5f0d0f0385ac8f908ea0ff68e670bb3ed\n","creating metadata file for /root/.cache/huggingface/transformers/ec25f52502749311e85eceb137b282f352376f01108c928c77b2e8d75bb645ad.520359c92ca91013f02967e1f505f9e5f0d0f0385ac8f908ea0ff68e670bb3ed\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec25f52502749311e85eceb137b282f352376f01108c928c77b2e8d75bb645ad.520359c92ca91013f02967e1f505f9e5f0d0f0385ac8f908ea0ff68e670bb3ed\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-multi\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"celebrity_&_pop_culture\",\n","    \"3\": \"diaries_&_daily_life\",\n","    \"4\": \"family\",\n","    \"5\": \"fashion_&_style\",\n","    \"6\": \"film_tv_&_video\",\n","    \"7\": \"fitness_&_health\",\n","    \"8\": \"food_&_dining\",\n","    \"9\": \"gaming\",\n","    \"10\": \"learning_&_educational\",\n","    \"11\": \"music\",\n","    \"12\": \"news_&_social_concern\",\n","    \"13\": \"other_hobbies\",\n","    \"14\": \"relationships\",\n","    \"15\": \"science_&_technology\",\n","    \"16\": \"sports\",\n","    \"17\": \"travel_&_adventure\",\n","    \"18\": \"youth_&_student_life\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"celebrity_&_pop_culture\": 2,\n","    \"diaries_&_daily_life\": 3,\n","    \"family\": 4,\n","    \"fashion_&_style\": 5,\n","    \"film_tv_&_video\": 6,\n","    \"fitness_&_health\": 7,\n","    \"food_&_dining\": 8,\n","    \"gaming\": 9,\n","    \"learning_&_educational\": 10,\n","    \"music\": 11,\n","    \"news_&_social_concern\": 12,\n","    \"other_hobbies\": 13,\n","    \"relationships\": 14,\n","    \"science_&_technology\": 15,\n","    \"sports\": 16,\n","    \"travel_&_adventure\": 17,\n","    \"youth_&_student_life\": 18\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpcxxd5elm\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2c5c7fa12745b698549c379af14861"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/09afae9646637ab82d1dfb71d31cd16d501f2520a5f947a4ae4d73de72f9dc71.fa54640b8d4deedaa096846028a1859f456664089266047b8bdfe4d6f5f7a046\n","creating metadata file for /root/.cache/huggingface/transformers/09afae9646637ab82d1dfb71d31cd16d501f2520a5f947a4ae4d73de72f9dc71.fa54640b8d4deedaa096846028a1859f456664089266047b8bdfe4d6f5f7a046\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/09afae9646637ab82d1dfb71d31cd16d501f2520a5f947a4ae4d73de72f9dc71.fa54640b8d4deedaa096846028a1859f456664089266047b8bdfe4d6f5f7a046\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-multi.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpn7cjgbqf\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d483f9716140559c85e9e076c11be4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/75582225ef99aad8073e1f62926777a1d8591adfa379597a8f3238dc1e24da74.8ded2a309dd799fbcdc6866cfad8a01c39b528cf15db85181bd13bba4763ac4a\n","creating metadata file for /root/.cache/huggingface/transformers/75582225ef99aad8073e1f62926777a1d8591adfa379597a8f3238dc1e24da74.8ded2a309dd799fbcdc6866cfad8a01c39b528cf15db85181bd13bba4763ac4a\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/75582225ef99aad8073e1f62926777a1d8591adfa379597a8f3238dc1e24da74.8ded2a309dd799fbcdc6866cfad8a01c39b528cf15db85181bd13bba4763ac4a\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-single\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"pop_culture\",\n","    \"3\": \"daily_life\",\n","    \"4\": \"sports_&_gaming\",\n","    \"5\": \"science_&_technology\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"daily_life\": 3,\n","    \"pop_culture\": 2,\n","    \"science_&_technology\": 5,\n","    \"sports_&_gaming\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpa_2spnn8\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945791dff7d34baa952f86dae96a3ab0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/041520af8ed380b8a62c28b0dbee222f5f7769b4ab43170e4ac03a56e5d64a8c.b4cb49f6ea070108f051e820bd3a9167e581a6a0f7cbf7a9bed80348689a2da3\n","creating metadata file for /root/.cache/huggingface/transformers/041520af8ed380b8a62c28b0dbee222f5f7769b4ab43170e4ac03a56e5d64a8c.b4cb49f6ea070108f051e820bd3a9167e581a6a0f7cbf7a9bed80348689a2da3\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/041520af8ed380b8a62c28b0dbee222f5f7769b4ab43170e4ac03a56e5d64a8c.b4cb49f6ea070108f051e820bd3a9167e581a6a0f7cbf7a9bed80348689a2da3\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-single.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded topic model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpn_tak6kg\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/589 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e7f5ea2353343afa7698e8748a6ff77"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","creating metadata file for /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3i_t21sj\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9600b9dfaac4f048c124fa81e6175c6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/804ed6d345e57fbb81c571128419b9e03a05038bec4340a98cd2b597136021a2.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","creating metadata file for /root/.cache/huggingface/transformers/804ed6d345e57fbb81c571128419b9e03a05038bec4340a98cd2b597136021a2.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpozp8jv3t\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b35074398ed54302894812487789aeac"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/2b61f296c8a50bacb1fbdcd9e64be78b1d4f46171c428a93e47139a97e9f853e.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","creating metadata file for /root/.cache/huggingface/transformers/2b61f296c8a50bacb1fbdcd9e64be78b1d4f46171c428a93e47139a97e9f853e.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpq5kzsvui\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f630256e16b44760a12edc436372a783"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/3718e2a2e89d3035d901e13462e6b3c48c7bf6b9ea912a54db4659015afef575.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","creating metadata file for /root/.cache/huggingface/transformers/3718e2a2e89d3035d901e13462e6b3c48c7bf6b9ea912a54db4659015afef575.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/804ed6d345e57fbb81c571128419b9e03a05038bec4340a98cd2b597136021a2.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/2b61f296c8a50bacb1fbdcd9e64be78b1d4f46171c428a93e47139a97e9f853e.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/3718e2a2e89d3035d901e13462e6b3c48c7bf6b9ea912a54db4659015afef575.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpt1z2tjz_\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14f492d0fa584b1a8c2047c32eb483c6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/2a0369351c138b3da55b7f1fcc060312292b9ec9f7a2f7935ce6247e12254329.993814007b1f009124e7b60fe354c67847f928d7bf198740bd12c32c8973c226\n","creating metadata file for /root/.cache/huggingface/transformers/2a0369351c138b3da55b7f1fcc060312292b9ec9f7a2f7935ce6247e12254329.993814007b1f009124e7b60fe354c67847f928d7bf198740bd12c32c8973c226\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/2a0369351c138b3da55b7f1fcc060312292b9ec9f7a2f7935ce6247e12254329.993814007b1f009124e7b60fe354c67847f928d7bf198740bd12c32c8973c226\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-irony.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded irony model for tweets\n","loaded offensive model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpoo1ohs8i\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c8be4b22574a4c9da5b5cbfbf81510"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","creating metadata file for /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp343wy50j\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4525aef67a546619976cd1d21ba6941"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/0e40ef8a24b0daf57a06685c69fa598582f9d045584d225e91ff2fe75e2df2c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","creating metadata file for /root/.cache/huggingface/transformers/0e40ef8a24b0daf57a06685c69fa598582f9d045584d225e91ff2fe75e2df2c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7cz3xzv_\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e897e4ce61e2464c89f88aea3aed5717"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/69f23586c2a42dbfaf335dff098f67f647e10b14ad6e3ddd4103d37a2048dfd9.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","creating metadata file for /root/.cache/huggingface/transformers/69f23586c2a42dbfaf335dff098f67f647e10b14ad6e3ddd4103d37a2048dfd9.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpuih1bxy5\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8d2806bce2c4dfe96a1d03b8cf8c370"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/df98b00b444e134464564ea04b555eb0a8057041e0fffea3838c2a766083bb59.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","creating metadata file for /root/.cache/huggingface/transformers/df98b00b444e134464564ea04b555eb0a8057041e0fffea3838c2a766083bb59.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/0e40ef8a24b0daf57a06685c69fa598582f9d045584d225e91ff2fe75e2df2c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/69f23586c2a42dbfaf335dff098f67f647e10b14ad6e3ddd4103d37a2048dfd9.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/df98b00b444e134464564ea04b555eb0a8057041e0fffea3838c2a766083bb59.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpjxs0_4zj\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6d40d52dc545198212e4309b216c93"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/4a168f05bd25772b9488bbdc011e5f45a99a95848a7d7b61b7320ae01d8e8ec9.1fe591f243c628bc0828384432f0fee747d800e489ab124309feadd5e70d7537\n","creating metadata file for /root/.cache/huggingface/transformers/4a168f05bd25772b9488bbdc011e5f45a99a95848a7d7b61b7320ae01d8e8ec9.1fe591f243c628bc0828384432f0fee747d800e489ab124309feadd5e70d7537\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4a168f05bd25772b9488bbdc011e5f45a99a95848a7d7b61b7320ae01d8e8ec9.1fe591f243c628bc0828384432f0fee747d800e489ab124309feadd5e70d7537\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emoji.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded emoji model\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpc8_2zlp4\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/980 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d27ce79dae45e3be48245e13072cc4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/0c8f98b89844cfd90c61b9671ab81f30f6d2ffd807131275cc3d9fa6c8061b04.92562558566fffb3ff2db6e6250351c34cb7206924b30d0b25bc6447925d32c1\n","creating metadata file for /root/.cache/huggingface/transformers/0c8f98b89844cfd90c61b9671ab81f30f6d2ffd807131275cc3d9fa6c8061b04.92562558566fffb3ff2db6e6250351c34cb7206924b30d0b25bc6447925d32c1\n","loading configuration file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0c8f98b89844cfd90c61b9671ab81f30f6d2ffd807131275cc3d9fa6c8061b04.92562558566fffb3ff2db6e6250351c34cb7206924b30d0b25bc6447925d32c1\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"pysentimiento/bertweet-hate-speech\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"hateful\",\n","    \"1\": \"targeted\",\n","    \"2\": \"aggressive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"aggressive\": 2,\n","    \"hateful\": 0,\n","    \"targeted\": 1\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp45yanbsp\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/515M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68c7eb8e6d954fe8b01b7a7098b41ffa"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/b1b28641afa821c55bf1216f931286a1e2d6f2bdf6ce43893b82fd118ff62542.742154f1fb0df2aeaab5e0f8ce81baeb42a062ffddff7febde2369888239bf57\n","creating metadata file for /root/.cache/huggingface/transformers/b1b28641afa821c55bf1216f931286a1e2d6f2bdf6ce43893b82fd118ff62542.742154f1fb0df2aeaab5e0f8ce81baeb42a062ffddff7febde2369888239bf57\n","loading weights file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b1b28641afa821c55bf1216f931286a1e2d6f2bdf6ce43893b82fd118ff62542.742154f1fb0df2aeaab5e0f8ce81baeb42a062ffddff7febde2369888239bf57\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/bertweet-hate-speech.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmptf8j0gok\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/335 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbe3abc18786445fa90a50b06ae6610f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/9eec04ca3ab9bdc071fafcf37e270203d932078b7715016c2df05a0f3bd1bf07.7cf9bfd7af087e7e2ea689b159647c3c8a45e7f0b92609dce7bca18d806905da\n","creating metadata file for /root/.cache/huggingface/transformers/9eec04ca3ab9bdc071fafcf37e270203d932078b7715016c2df05a0f3bd1bf07.7cf9bfd7af087e7e2ea689b159647c3c8a45e7f0b92609dce7bca18d806905da\n","https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpik55ylxu\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e05b5216ebd4c108b1c1e14b116f6d0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/af97f2d33aa35c368f65a032c5f6b065e8b88d9bdef502fbc2ce78e04579a0fa.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","creating metadata file for /root/.cache/huggingface/transformers/af97f2d33aa35c368f65a032c5f6b065e8b88d9bdef502fbc2ce78e04579a0fa.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/bpe.codes not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmhcr8x36\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a83e1bb253ca4def87758334faee6044"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/bpe.codes in cache at /root/.cache/huggingface/transformers/c50391b2daa6a8c1be706382b1cd8d7f4996b5664c2a0bbab6c15097305ae731.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","creating metadata file for /root/.cache/huggingface/transformers/c50391b2daa6a8c1be706382b1cd8d7f4996b5664c2a0bbab6c15097305ae731.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/added_tokens.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2ksbwnsr\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052a16d6875b44bea85173f0233a247a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/added_tokens.json in cache at /root/.cache/huggingface/transformers/8715836fc39b559eca950b73d5a4651bf34ab8d3acb1d0b81aae6d76e1a38fac.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","creating metadata file for /root/.cache/huggingface/transformers/8715836fc39b559eca950b73d5a4651bf34ab8d3acb1d0b81aae6d76e1a38fac.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpromcw4bv\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1280ad989a03407f992e18531a831b08"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/fdf2edf9c4b32d36848f3a7f4b9edd83fe65a7caa032a01e30f72cd87b62affc.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","creating metadata file for /root/.cache/huggingface/transformers/fdf2edf9c4b32d36848f3a7f4b9edd83fe65a7caa032a01e30f72cd87b62affc.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/af97f2d33aa35c368f65a032c5f6b065e8b88d9bdef502fbc2ce78e04579a0fa.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/c50391b2daa6a8c1be706382b1cd8d7f4996b5664c2a0bbab6c15097305ae731.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/8715836fc39b559eca950b73d5a4651bf34ab8d3acb1d0b81aae6d76e1a38fac.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fdf2edf9c4b32d36848f3a7f4b9edd83fe65a7caa032a01e30f72cd87b62affc.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/9eec04ca3ab9bdc071fafcf37e270203d932078b7715016c2df05a0f3bd1bf07.7cf9bfd7af087e7e2ea689b159647c3c8a45e7f0b92609dce7bca18d806905da\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer.json from cache at None\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted hate of tweets\n","loaded hate model\n"]},{"output_type":"stream","name":"stderr","text":["https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpiwcbcf01\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/999 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca001386b14b4e308ceec8da2236479d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","creating metadata file for /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpoho4c9xq\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/515M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd6c608aaff542aea478edabb82bbe6a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/61c5894a0aca5ed63159e2ec6a5501db48124c1e6de287b82bc634334f031203.9c3c4c16d0dd174434d42471b9d4670734d982be506a06fc3111c12bee4380c7\n","creating metadata file for /root/.cache/huggingface/transformers/61c5894a0aca5ed63159e2ec6a5501db48124c1e6de287b82bc634334f031203.9c3c4c16d0dd174434d42471b9d4670734d982be506a06fc3111c12bee4380c7\n","loading weights file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/61c5894a0aca5ed63159e2ec6a5501db48124c1e6de287b82bc634334f031203.9c3c4c16d0dd174434d42471b9d4670734d982be506a06fc3111c12bee4380c7\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-emotion-analysis.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnmbzzm81\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/295 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f136618fd0549b898dcfa38cb465cf9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/1740697312c59fe96586f476c7765cd6f08516a6102ea96f22ffee64f7553234.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n","creating metadata file for /root/.cache/huggingface/transformers/1740697312c59fe96586f476c7765cd6f08516a6102ea96f22ffee64f7553234.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpexsz4u41\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"868fb4b8dcc04f00b9d304597e04d31f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/b7837213513a9f3852dcb04048f70c13cbd0590be030e534734ffd42cbdcf45a.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","creating metadata file for /root/.cache/huggingface/transformers/b7837213513a9f3852dcb04048f70c13cbd0590be030e534734ffd42cbdcf45a.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/bpe.codes not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpr2b1dl13\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda245baa5df44b4a4ae8e17a2889b8e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/bpe.codes in cache at /root/.cache/huggingface/transformers/76e357e2554ebe053d1c4c613506bc2cc19d66ae27fec8218261a7f73c6456b9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","creating metadata file for /root/.cache/huggingface/transformers/76e357e2554ebe053d1c4c613506bc2cc19d66ae27fec8218261a7f73c6456b9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/added_tokens.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp4n9n8w0d\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deba63c55514483f8b101070b69e2ddf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/added_tokens.json in cache at /root/.cache/huggingface/transformers/c4b7522f44ed8adb95e62288c6458da591654f7466e3ce2f9c730bb4087411d2.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","creating metadata file for /root/.cache/huggingface/transformers/c4b7522f44ed8adb95e62288c6458da591654f7466e3ce2f9c730bb4087411d2.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpw5_lgltt\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a27f809097f4011bd4362208766c28f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/01581144d9bf96cb9c7d8a77ee93c8b1f1095af5c1204b1b038a8cb0e3247aa8.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","creating metadata file for /root/.cache/huggingface/transformers/01581144d9bf96cb9c7d8a77ee93c8b1f1095af5c1204b1b038a8cb0e3247aa8.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/b7837213513a9f3852dcb04048f70c13cbd0590be030e534734ffd42cbdcf45a.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/76e357e2554ebe053d1c4c613506bc2cc19d66ae27fec8218261a7f73c6456b9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/c4b7522f44ed8adb95e62288c6458da591654f7466e3ce2f9c730bb4087411d2.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/01581144d9bf96cb9c7d8a77ee93c8b1f1095af5c1204b1b038a8cb0e3247aa8.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/1740697312c59fe96586f476c7765cd6f08516a6102ea96f22ffee64f7553234.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer.json from cache at None\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted emotion of tweets\n","loaded emotion model\n","finshed scoring tweets in 0.005372653272416856 hours\n","-------\n","---------------------\n","-------------------------------------------------\n","finished classifying all the tweets\n","-------------------------------------------------\n","---------------------\n","-------\n","DONE WITH avengers\n","----------------\n","DONE \n","avengershashtag  \n","----------------\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","loaded informer data\n","loaded in ms tweets\n","pulled data on 4773 users\n","\n","\n","\n"," raw feed len 474122\n","\n","\n","\n"," feed len after drop duplibats 474122\n","\n","\n","\n"," feed len after not considering the feeds we didnt pull 474122\n","loaded in necessary data\n","\n","\n","\n","already done 6457 tweets\n","\n","\n","\\ now have 215 tweets left to analyse\n","have 215 tweets loaded in\n","now considering 215 tweets\n","have 474122 tweets loaded in\n","now considering 474122 tweets\n","loading test data\n","put tweet ids back in\n","starting user gender classification\n","now cleaning\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text'],\n","      dtype='object')\n","finished cleaning\n","now predicting the gender of each tweet and descrption\n","model finished predicting gender\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text', 'sep', 'txt', 'gender'],\n","      dtype='object')\n","male tweets\n","252204\n","female tweets\n","221918\n","dont have useres feeds\n","SELF.DF INDEX HAS NOW BEEN RESET BACK TO TWEET IDS\n","\n","\n","\n"," added the user ideas \n","\n","\n","\n","gender results\n","male users\n","166\n","female users\n","49\n","finished gender\n","---------\n","---------\n","\n","loaded gender \n","loaded politeness\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file politeness/results/checkpoint-52500/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"politeness/results/checkpoint-52500/\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file politeness/results/checkpoint-52500/pytorch_model.bin\n"]},{"output_type":"stream","name":"stdout","text":["politeness per tweet\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at politeness/results/checkpoint-52500/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 215\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27/27 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loaded politeness model for tweets\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/1daf1d394b649e9ab6c0bfc37629115ed7766cb32e0be8821110820610ba0980.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/88006e159b7014116256e91ec1595ca77cffffd2b060ee2b91bf7aed41644875.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/047625f13f02ecae088036957c64a40f7bebb93fd2d2ad6324af4fc378fff90a.9f68d0ce76c33cdd199a6beeede63d9293d6005f826c0702d530ccefbcd221b7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/86f379e4ef5dad9037395318b3d4cc8685000af32c64d37ab4158e8df91169cc.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/50a78d02314329fbddfef47fdd5e1a3c7caf505195bf06f4d8263648bc56ceaa.fe0807eede1fcfc7436be17cbcc9a0bc5a06769ccb408c587f0ce6ae666b586b\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec25f52502749311e85eceb137b282f352376f01108c928c77b2e8d75bb645ad.520359c92ca91013f02967e1f505f9e5f0d0f0385ac8f908ea0ff68e670bb3ed\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-multi\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"celebrity_&_pop_culture\",\n","    \"3\": \"diaries_&_daily_life\",\n","    \"4\": \"family\",\n","    \"5\": \"fashion_&_style\",\n","    \"6\": \"film_tv_&_video\",\n","    \"7\": \"fitness_&_health\",\n","    \"8\": \"food_&_dining\",\n","    \"9\": \"gaming\",\n","    \"10\": \"learning_&_educational\",\n","    \"11\": \"music\",\n","    \"12\": \"news_&_social_concern\",\n","    \"13\": \"other_hobbies\",\n","    \"14\": \"relationships\",\n","    \"15\": \"science_&_technology\",\n","    \"16\": \"sports\",\n","    \"17\": \"travel_&_adventure\",\n","    \"18\": \"youth_&_student_life\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"celebrity_&_pop_culture\": 2,\n","    \"diaries_&_daily_life\": 3,\n","    \"family\": 4,\n","    \"fashion_&_style\": 5,\n","    \"film_tv_&_video\": 6,\n","    \"fitness_&_health\": 7,\n","    \"food_&_dining\": 8,\n","    \"gaming\": 9,\n","    \"learning_&_educational\": 10,\n","    \"music\": 11,\n","    \"news_&_social_concern\": 12,\n","    \"other_hobbies\": 13,\n","    \"relationships\": 14,\n","    \"science_&_technology\": 15,\n","    \"sports\": 16,\n","    \"travel_&_adventure\": 17,\n","    \"youth_&_student_life\": 18\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/09afae9646637ab82d1dfb71d31cd16d501f2520a5f947a4ae4d73de72f9dc71.fa54640b8d4deedaa096846028a1859f456664089266047b8bdfe4d6f5f7a046\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-multi.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/75582225ef99aad8073e1f62926777a1d8591adfa379597a8f3238dc1e24da74.8ded2a309dd799fbcdc6866cfad8a01c39b528cf15db85181bd13bba4763ac4a\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-single\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"pop_culture\",\n","    \"3\": \"daily_life\",\n","    \"4\": \"sports_&_gaming\",\n","    \"5\": \"science_&_technology\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"daily_life\": 3,\n","    \"pop_culture\": 2,\n","    \"science_&_technology\": 5,\n","    \"sports_&_gaming\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/041520af8ed380b8a62c28b0dbee222f5f7769b4ab43170e4ac03a56e5d64a8c.b4cb49f6ea070108f051e820bd3a9167e581a6a0f7cbf7a9bed80348689a2da3\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-single.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded topic model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/804ed6d345e57fbb81c571128419b9e03a05038bec4340a98cd2b597136021a2.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/2b61f296c8a50bacb1fbdcd9e64be78b1d4f46171c428a93e47139a97e9f853e.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/3718e2a2e89d3035d901e13462e6b3c48c7bf6b9ea912a54db4659015afef575.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/2a0369351c138b3da55b7f1fcc060312292b9ec9f7a2f7935ce6247e12254329.993814007b1f009124e7b60fe354c67847f928d7bf198740bd12c32c8973c226\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-irony.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded irony model for tweets\n","loaded offensive model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/0e40ef8a24b0daf57a06685c69fa598582f9d045584d225e91ff2fe75e2df2c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/69f23586c2a42dbfaf335dff098f67f647e10b14ad6e3ddd4103d37a2048dfd9.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/df98b00b444e134464564ea04b555eb0a8057041e0fffea3838c2a766083bb59.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4a168f05bd25772b9488bbdc011e5f45a99a95848a7d7b61b7320ae01d8e8ec9.1fe591f243c628bc0828384432f0fee747d800e489ab124309feadd5e70d7537\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emoji.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded emoji model\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0c8f98b89844cfd90c61b9671ab81f30f6d2ffd807131275cc3d9fa6c8061b04.92562558566fffb3ff2db6e6250351c34cb7206924b30d0b25bc6447925d32c1\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"pysentimiento/bertweet-hate-speech\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"hateful\",\n","    \"1\": \"targeted\",\n","    \"2\": \"aggressive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"aggressive\": 2,\n","    \"hateful\": 0,\n","    \"targeted\": 1\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b1b28641afa821c55bf1216f931286a1e2d6f2bdf6ce43893b82fd118ff62542.742154f1fb0df2aeaab5e0f8ce81baeb42a062ffddff7febde2369888239bf57\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/bertweet-hate-speech.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/af97f2d33aa35c368f65a032c5f6b065e8b88d9bdef502fbc2ce78e04579a0fa.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/c50391b2daa6a8c1be706382b1cd8d7f4996b5664c2a0bbab6c15097305ae731.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/8715836fc39b559eca950b73d5a4651bf34ab8d3acb1d0b81aae6d76e1a38fac.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fdf2edf9c4b32d36848f3a7f4b9edd83fe65a7caa032a01e30f72cd87b62affc.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/9eec04ca3ab9bdc071fafcf37e270203d932078b7715016c2df05a0f3bd1bf07.7cf9bfd7af087e7e2ea689b159647c3c8a45e7f0b92609dce7bca18d806905da\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer.json from cache at None\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted hate of tweets\n","loaded hate model\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/61c5894a0aca5ed63159e2ec6a5501db48124c1e6de287b82bc634334f031203.9c3c4c16d0dd174434d42471b9d4670734d982be506a06fc3111c12bee4380c7\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-emotion-analysis.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/b7837213513a9f3852dcb04048f70c13cbd0590be030e534734ffd42cbdcf45a.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/76e357e2554ebe053d1c4c613506bc2cc19d66ae27fec8218261a7f73c6456b9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/c4b7522f44ed8adb95e62288c6458da591654f7466e3ce2f9c730bb4087411d2.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/01581144d9bf96cb9c7d8a77ee93c8b1f1095af5c1204b1b038a8cb0e3247aa8.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/1740697312c59fe96586f476c7765cd6f08516a6102ea96f22ffee64f7553234.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer.json from cache at None\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted emotion of tweets\n","loaded emotion model\n","finshed scoring tweets in 0.02121840324666765 hours\n","-------\n","---------------------\n","-------------------------------------------------\n","finished classifying all the tweets\n","-------------------------------------------------\n","---------------------\n","-------\n","DONE WITH blm\n","----------------\n","DONE \n","blmhashtag  \n","----------------\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","loaded informer data\n","loaded in ms tweets\n","pulled data on 3911 users\n","\n","\n","\n"," raw feed len 389053\n","\n","\n","\n"," feed len after drop duplibats 389053\n","\n","\n","\n"," feed len after not considering the feeds we didnt pull 389053\n","loaded in necessary data\n","\n","\n","\n","already done 5711 tweets\n","\n","\n","\\ now have 114 tweets left to analyse\n","have 114 tweets loaded in\n","now considering 114 tweets\n","have 389053 tweets loaded in\n","now considering 389053 tweets\n","loading test data\n","put tweet ids back in\n","starting user gender classification\n","now cleaning\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text'],\n","      dtype='object')\n","finished cleaning\n","now predicting the gender of each tweet and descrption\n","model finished predicting gender\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text', 'sep', 'txt', 'gender'],\n","      dtype='object')\n","male tweets\n","223271\n","female tweets\n","165782\n","dont have useres feeds\n","dont have useres feeds\n","dont have useres feeds\n","dont have useres feeds\n","dont have useres feeds\n","dont have useres feeds\n","SELF.DF INDEX HAS NOW BEEN RESET BACK TO TWEET IDS\n","\n","\n","\n"," added the user ideas \n","\n","\n","\n","gender results\n","male users\n","49\n","female users\n","65\n","finished gender\n","---------\n","---------\n","\n","loaded gender \n","loaded politeness\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file politeness/results/checkpoint-52500/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"politeness/results/checkpoint-52500/\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file politeness/results/checkpoint-52500/pytorch_model.bin\n"]},{"output_type":"stream","name":"stdout","text":["politeness per tweet\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at politeness/results/checkpoint-52500/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 114\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15/15 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loaded politeness model for tweets\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/1daf1d394b649e9ab6c0bfc37629115ed7766cb32e0be8821110820610ba0980.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/88006e159b7014116256e91ec1595ca77cffffd2b060ee2b91bf7aed41644875.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/047625f13f02ecae088036957c64a40f7bebb93fd2d2ad6324af4fc378fff90a.9f68d0ce76c33cdd199a6beeede63d9293d6005f826c0702d530ccefbcd221b7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/86f379e4ef5dad9037395318b3d4cc8685000af32c64d37ab4158e8df91169cc.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/50a78d02314329fbddfef47fdd5e1a3c7caf505195bf06f4d8263648bc56ceaa.fe0807eede1fcfc7436be17cbcc9a0bc5a06769ccb408c587f0ce6ae666b586b\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec25f52502749311e85eceb137b282f352376f01108c928c77b2e8d75bb645ad.520359c92ca91013f02967e1f505f9e5f0d0f0385ac8f908ea0ff68e670bb3ed\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-multi\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"celebrity_&_pop_culture\",\n","    \"3\": \"diaries_&_daily_life\",\n","    \"4\": \"family\",\n","    \"5\": \"fashion_&_style\",\n","    \"6\": \"film_tv_&_video\",\n","    \"7\": \"fitness_&_health\",\n","    \"8\": \"food_&_dining\",\n","    \"9\": \"gaming\",\n","    \"10\": \"learning_&_educational\",\n","    \"11\": \"music\",\n","    \"12\": \"news_&_social_concern\",\n","    \"13\": \"other_hobbies\",\n","    \"14\": \"relationships\",\n","    \"15\": \"science_&_technology\",\n","    \"16\": \"sports\",\n","    \"17\": \"travel_&_adventure\",\n","    \"18\": \"youth_&_student_life\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"celebrity_&_pop_culture\": 2,\n","    \"diaries_&_daily_life\": 3,\n","    \"family\": 4,\n","    \"fashion_&_style\": 5,\n","    \"film_tv_&_video\": 6,\n","    \"fitness_&_health\": 7,\n","    \"food_&_dining\": 8,\n","    \"gaming\": 9,\n","    \"learning_&_educational\": 10,\n","    \"music\": 11,\n","    \"news_&_social_concern\": 12,\n","    \"other_hobbies\": 13,\n","    \"relationships\": 14,\n","    \"science_&_technology\": 15,\n","    \"sports\": 16,\n","    \"travel_&_adventure\": 17,\n","    \"youth_&_student_life\": 18\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/09afae9646637ab82d1dfb71d31cd16d501f2520a5f947a4ae4d73de72f9dc71.fa54640b8d4deedaa096846028a1859f456664089266047b8bdfe4d6f5f7a046\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-multi.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/75582225ef99aad8073e1f62926777a1d8591adfa379597a8f3238dc1e24da74.8ded2a309dd799fbcdc6866cfad8a01c39b528cf15db85181bd13bba4763ac4a\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-single\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"pop_culture\",\n","    \"3\": \"daily_life\",\n","    \"4\": \"sports_&_gaming\",\n","    \"5\": \"science_&_technology\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"daily_life\": 3,\n","    \"pop_culture\": 2,\n","    \"science_&_technology\": 5,\n","    \"sports_&_gaming\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/041520af8ed380b8a62c28b0dbee222f5f7769b4ab43170e4ac03a56e5d64a8c.b4cb49f6ea070108f051e820bd3a9167e581a6a0f7cbf7a9bed80348689a2da3\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-single.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded topic model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/804ed6d345e57fbb81c571128419b9e03a05038bec4340a98cd2b597136021a2.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/2b61f296c8a50bacb1fbdcd9e64be78b1d4f46171c428a93e47139a97e9f853e.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/3718e2a2e89d3035d901e13462e6b3c48c7bf6b9ea912a54db4659015afef575.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/2a0369351c138b3da55b7f1fcc060312292b9ec9f7a2f7935ce6247e12254329.993814007b1f009124e7b60fe354c67847f928d7bf198740bd12c32c8973c226\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-irony.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded irony model for tweets\n","loaded offensive model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/0e40ef8a24b0daf57a06685c69fa598582f9d045584d225e91ff2fe75e2df2c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/69f23586c2a42dbfaf335dff098f67f647e10b14ad6e3ddd4103d37a2048dfd9.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/df98b00b444e134464564ea04b555eb0a8057041e0fffea3838c2a766083bb59.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4a168f05bd25772b9488bbdc011e5f45a99a95848a7d7b61b7320ae01d8e8ec9.1fe591f243c628bc0828384432f0fee747d800e489ab124309feadd5e70d7537\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emoji.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded emoji model\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0c8f98b89844cfd90c61b9671ab81f30f6d2ffd807131275cc3d9fa6c8061b04.92562558566fffb3ff2db6e6250351c34cb7206924b30d0b25bc6447925d32c1\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"pysentimiento/bertweet-hate-speech\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"hateful\",\n","    \"1\": \"targeted\",\n","    \"2\": \"aggressive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"aggressive\": 2,\n","    \"hateful\": 0,\n","    \"targeted\": 1\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b1b28641afa821c55bf1216f931286a1e2d6f2bdf6ce43893b82fd118ff62542.742154f1fb0df2aeaab5e0f8ce81baeb42a062ffddff7febde2369888239bf57\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/bertweet-hate-speech.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/af97f2d33aa35c368f65a032c5f6b065e8b88d9bdef502fbc2ce78e04579a0fa.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/c50391b2daa6a8c1be706382b1cd8d7f4996b5664c2a0bbab6c15097305ae731.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/8715836fc39b559eca950b73d5a4651bf34ab8d3acb1d0b81aae6d76e1a38fac.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fdf2edf9c4b32d36848f3a7f4b9edd83fe65a7caa032a01e30f72cd87b62affc.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/9eec04ca3ab9bdc071fafcf37e270203d932078b7715016c2df05a0f3bd1bf07.7cf9bfd7af087e7e2ea689b159647c3c8a45e7f0b92609dce7bca18d806905da\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer.json from cache at None\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted hate of tweets\n","loaded hate model\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/61c5894a0aca5ed63159e2ec6a5501db48124c1e6de287b82bc634334f031203.9c3c4c16d0dd174434d42471b9d4670734d982be506a06fc3111c12bee4380c7\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-emotion-analysis.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/b7837213513a9f3852dcb04048f70c13cbd0590be030e534734ffd42cbdcf45a.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/76e357e2554ebe053d1c4c613506bc2cc19d66ae27fec8218261a7f73c6456b9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/c4b7522f44ed8adb95e62288c6458da591654f7466e3ce2f9c730bb4087411d2.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/01581144d9bf96cb9c7d8a77ee93c8b1f1095af5c1204b1b038a8cb0e3247aa8.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/1740697312c59fe96586f476c7765cd6f08516a6102ea96f22ffee64f7553234.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer.json from cache at None\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted emotion of tweets\n","loaded emotion model\n","finshed scoring tweets in 0.011773520906766255 hours\n","-------\n","---------------------\n","-------------------------------------------------\n","finished classifying all the tweets\n","-------------------------------------------------\n","---------------------\n","-------\n","DONE WITH borisjohnson\n","----------------\n","DONE \n","borisjohnsonhashtag  \n","----------------\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","loaded informer data\n","loaded in ms tweets\n","pulled data on 4394 users\n","\n","\n","\n"," raw feed len 437128\n","\n","\n","\n"," feed len after drop duplibats 437128\n","\n","\n","\n"," feed len after not considering the feeds we didnt pull 437128\n","loaded in necessary data\n","\n","\n","\n","already done 6224 tweets\n","\n","\n","\\ now have 121 tweets left to analyse\n","have 121 tweets loaded in\n","now considering 121 tweets\n","have 437128 tweets loaded in\n","now considering 437128 tweets\n","loading test data\n","put tweet ids back in\n","starting user gender classification\n","now cleaning\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text'],\n","      dtype='object')\n","finished cleaning\n","now predicting the gender of each tweet and descrption\n","model finished predicting gender\n","Index(['user_id', 'description', 'text', 'tweet_id', 'polarity',\n","       'subjectivity', 'grammartext', 'clean_text', 'text_len',\n","       'text_word_count', 'punct', 'tokenized', 'nonstop', 'stemmed',\n","       'cln_description', 'cln_text', 'sep', 'txt', 'gender'],\n","      dtype='object')\n","male tweets\n","262696\n","female tweets\n","174432\n","SELF.DF INDEX HAS NOW BEEN RESET BACK TO TWEET IDS\n","\n","\n","\n"," added the user ideas \n","\n","\n","\n","gender results\n","male users\n","82\n","female users\n","39\n","finished gender\n","---------\n","---------\n","\n","loaded gender \n","loaded politeness\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file politeness/results/checkpoint-52500/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"politeness/results/checkpoint-52500/\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file politeness/results/checkpoint-52500/pytorch_model.bin\n"]},{"output_type":"stream","name":"stdout","text":["politeness per tweet\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at politeness/results/checkpoint-52500/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 121\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [16/16 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loaded politeness model for tweets\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/1daf1d394b649e9ab6c0bfc37629115ed7766cb32e0be8821110820610ba0980.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/88006e159b7014116256e91ec1595ca77cffffd2b060ee2b91bf7aed41644875.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/047625f13f02ecae088036957c64a40f7bebb93fd2d2ad6324af4fc378fff90a.9f68d0ce76c33cdd199a6beeede63d9293d6005f826c0702d530ccefbcd221b7\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/86f379e4ef5dad9037395318b3d4cc8685000af32c64d37ab4158e8df91169cc.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","loading file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/50a78d02314329fbddfef47fdd5e1a3c7caf505195bf06f4d8263648bc56ceaa.fe0807eede1fcfc7436be17cbcc9a0bc5a06769ccb408c587f0ce6ae666b586b\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec25f52502749311e85eceb137b282f352376f01108c928c77b2e8d75bb645ad.520359c92ca91013f02967e1f505f9e5f0d0f0385ac8f908ea0ff68e670bb3ed\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-multi\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"celebrity_&_pop_culture\",\n","    \"3\": \"diaries_&_daily_life\",\n","    \"4\": \"family\",\n","    \"5\": \"fashion_&_style\",\n","    \"6\": \"film_tv_&_video\",\n","    \"7\": \"fitness_&_health\",\n","    \"8\": \"food_&_dining\",\n","    \"9\": \"gaming\",\n","    \"10\": \"learning_&_educational\",\n","    \"11\": \"music\",\n","    \"12\": \"news_&_social_concern\",\n","    \"13\": \"other_hobbies\",\n","    \"14\": \"relationships\",\n","    \"15\": \"science_&_technology\",\n","    \"16\": \"sports\",\n","    \"17\": \"travel_&_adventure\",\n","    \"18\": \"youth_&_student_life\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"celebrity_&_pop_culture\": 2,\n","    \"diaries_&_daily_life\": 3,\n","    \"family\": 4,\n","    \"fashion_&_style\": 5,\n","    \"film_tv_&_video\": 6,\n","    \"fitness_&_health\": 7,\n","    \"food_&_dining\": 8,\n","    \"gaming\": 9,\n","    \"learning_&_educational\": 10,\n","    \"music\": 11,\n","    \"news_&_social_concern\": 12,\n","    \"other_hobbies\": 13,\n","    \"relationships\": 14,\n","    \"science_&_technology\": 15,\n","    \"sports\": 16,\n","    \"travel_&_adventure\": 17,\n","    \"youth_&_student_life\": 18\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-multi/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/09afae9646637ab82d1dfb71d31cd16d501f2520a5f947a4ae4d73de72f9dc71.fa54640b8d4deedaa096846028a1859f456664089266047b8bdfe4d6f5f7a046\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-multi.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading configuration file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/75582225ef99aad8073e1f62926777a1d8591adfa379597a8f3238dc1e24da74.8ded2a309dd799fbcdc6866cfad8a01c39b528cf15db85181bd13bba4763ac4a\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/tweet-topic-21-single\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"arts_&_culture\",\n","    \"1\": \"business_&_entrepreneurs\",\n","    \"2\": \"pop_culture\",\n","    \"3\": \"daily_life\",\n","    \"4\": \"sports_&_gaming\",\n","    \"5\": \"science_&_technology\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"arts_&_culture\": 0,\n","    \"business_&_entrepreneurs\": 1,\n","    \"daily_life\": 3,\n","    \"pop_culture\": 2,\n","    \"science_&_technology\": 5,\n","    \"sports_&_gaming\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/tweet-topic-21-single/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/041520af8ed380b8a62c28b0dbee222f5f7769b4ab43170e4ac03a56e5d64a8c.b4cb49f6ea070108f051e820bd3a9167e581a6a0f7cbf7a9bed80348689a2da3\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/tweet-topic-21-single.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded topic model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/804ed6d345e57fbb81c571128419b9e03a05038bec4340a98cd2b597136021a2.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/2b61f296c8a50bacb1fbdcd9e64be78b1d4f46171c428a93e47139a97e9f853e.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/3718e2a2e89d3035d901e13462e6b3c48c7bf6b9ea912a54db4659015afef575.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b318877b5e8f6efe46df15ea1f284fe87c4f0f4d7990da954a56a7f93da3e887.d526c7548113da2236674baa2b82e3bc598efb72510d3d6cdbc3ede3d2fe08bb\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-irony\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-irony/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/2a0369351c138b3da55b7f1fcc060312292b9ec9f7a2f7935ce6247e12254329.993814007b1f009124e7b60fe354c67847f928d7bf198740bd12c32c8973c226\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-irony.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded irony model for tweets\n","loaded offensive model\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/0e40ef8a24b0daf57a06685c69fa598582f9d045584d225e91ff2fe75e2df2c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/69f23586c2a42dbfaf335dff098f67f647e10b14ad6e3ddd4103d37a2048dfd9.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/df98b00b444e134464564ea04b555eb0a8057041e0fffea3838c2a766083bb59.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/13caedf051daa06346e381f819924d2ad6ac5ef01602b614ab7669effc5e9982.60ac9bc11a600708d9aef4c0ad14f218936a1e4899d0b5db248e04e93b1b65c8\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emoji\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4a168f05bd25772b9488bbdc011e5f45a99a95848a7d7b61b7320ae01d8e8ec9.1fe591f243c628bc0828384432f0fee747d800e489ab124309feadd5e70d7537\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emoji.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["loaded emoji model\n","---------\n","---------\n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0c8f98b89844cfd90c61b9671ab81f30f6d2ffd807131275cc3d9fa6c8061b04.92562558566fffb3ff2db6e6250351c34cb7206924b30d0b25bc6447925d32c1\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"pysentimiento/bertweet-hate-speech\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"hateful\",\n","    \"1\": \"targeted\",\n","    \"2\": \"aggressive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"aggressive\": 2,\n","    \"hateful\": 0,\n","    \"targeted\": 1\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"multi_label_classification\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b1b28641afa821c55bf1216f931286a1e2d6f2bdf6ce43893b82fd118ff62542.742154f1fb0df2aeaab5e0f8ce81baeb42a062ffddff7febde2369888239bf57\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/bertweet-hate-speech.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/af97f2d33aa35c368f65a032c5f6b065e8b88d9bdef502fbc2ce78e04579a0fa.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/c50391b2daa6a8c1be706382b1cd8d7f4996b5664c2a0bbab6c15097305ae731.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/8715836fc39b559eca950b73d5a4651bf34ab8d3acb1d0b81aae6d76e1a38fac.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fdf2edf9c4b32d36848f3a7f4b9edd83fe65a7caa032a01e30f72cd87b62affc.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/9eec04ca3ab9bdc071fafcf37e270203d932078b7715016c2df05a0f3bd1bf07.7cf9bfd7af087e7e2ea689b159647c3c8a45e7f0b92609dce7bca18d806905da\n","loading file https://huggingface.co/pysentimiento/bertweet-hate-speech/resolve/main/tokenizer.json from cache at None\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted hate of tweets\n","loaded hate model\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/61c5894a0aca5ed63159e2ec6a5501db48124c1e6de287b82bc634334f031203.9c3c4c16d0dd174434d42471b9d4670734d982be506a06fc3111c12bee4380c7\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-emotion-analysis.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/b7837213513a9f3852dcb04048f70c13cbd0590be030e534734ffd42cbdcf45a.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/76e357e2554ebe053d1c4c613506bc2cc19d66ae27fec8218261a7f73c6456b9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/c4b7522f44ed8adb95e62288c6458da591654f7466e3ce2f9c730bb4087411d2.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/01581144d9bf96cb9c7d8a77ee93c8b1f1095af5c1204b1b038a8cb0e3247aa8.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/1740697312c59fe96586f476c7765cd6f08516a6102ea96f22ffee64f7553234.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n","loading file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/tokenizer.json from cache at None\n","loading configuration file https://huggingface.co/finiteautomata/bertweet-base-emotion-analysis/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c246eed05359b1a49c45955b0265b488e35b0cbd2628e3ead7dd54c8815162ee.a2dff24b4e0a884c6d58a09968c5b68e7391e749eb698ad92541818d420fd01b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"finiteautomata/bertweet-base-emotion-analysis\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"others\",\n","    \"1\": \"joy\",\n","    \"2\": \"sadness\",\n","    \"3\": \"anger\",\n","    \"4\": \"surprise\",\n","    \"5\": \"disgust\",\n","    \"6\": \"fear\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"anger\": 3,\n","    \"disgust\": 5,\n","    \"fear\": 6,\n","    \"joy\": 1,\n","    \"others\": 0,\n","    \"sadness\": 2,\n","    \"surprise\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 130,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertweetTokenizer\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","Adding <mask> to the vocabulary\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["predicted emotion of tweets\n","loaded emotion model\n","finshed scoring tweets in 0.009040605227152507 hours\n","-------\n","---------------------\n","-------------------------------------------------\n","finished classifying all the tweets\n","-------------------------------------------------\n","---------------------\n","-------\n","DONE WITH brexit\n","----------------\n","DONE \n","brexithashtag  \n","----------------\n"]}],"source":["# hashtags = ['avengers','blm','borisjohnson','brexit','climatechange','covid','gaza','loveisland','monkeypox','nhs','olivianewtonjohn','supercup','UkraineWar']\n","\n","hashtags = ['avengers','blm','borisjohnson','brexit']\n","\n","# hashtags = ['blm','borisjohnson','brexit']\n","\n","for hashtag in hashtags:\n","\n","    a = Analyzer(hashtag)\n","\n","    a.tweet_analysis()\n","\n","    print(f'----------------\\nDONE \\n{hashtag}hashtag  \\n----------------')"]}]}