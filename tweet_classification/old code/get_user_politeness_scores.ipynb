{"cells":[{"cell_type":"markdown","metadata":{"id":"4MdwUck88MEI"},"source":["## MOUNT"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17387,"status":"ok","timestamp":1663494497124,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"njrEJjvc8DnR","outputId":"1010042f-1e7c-473c-ad53-0ee01c5b6321"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/MSc_project/.MAIN\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/MSc_project/.MAIN"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":171000,"status":"ok","timestamp":1663494668107,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"ZO-PczKG8gPC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6c89c30-ae80-421d-cc55-f08a60180974"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting install\n","  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n","Collecting tweet-preprocessor\n","  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n","Installing collected packages: tweet-preprocessor, install\n","Successfully installed install-1.3.5 tweet-preprocessor-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pycountry\n","  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 15.5 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pycountry) (57.4.0)\n","Building wheels for collected packages: pycountry\n","  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681845 sha256=76d713be860aa86632584ed97963d9e757dcceb49679054771744a0a4a0a5918\n","  Stored in directory: /root/.cache/pip/wheels/0e/06/e8/7ee176e95ea9a8a8c3b3afcb1869f20adbd42413d4611c6eb4\n","Successfully built pycountry\n","Installing collected packages: pycountry\n","Successfully installed pycountry-22.3.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandas==1.2.3\n","  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 15.2 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (2022.2.1)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.3) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.3) (1.15.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","Successfully installed pandas-1.2.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 14.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 75.4 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement mislib (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for mislib\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 15.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=50ddcbc828b9621ae513382925d54166bf1471b09894f11f090de3eb68bbf980\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting readability\n","  Downloading readability-0.3.1.tar.gz (34 kB)\n","Building wheels for collected packages: readability\n","  Building wheel for readability (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for readability: filename=readability-0.3.1-py3-none-any.whl size=35475 sha256=8cb42f553690b7c907a552680e90c9cb7c59166f2dbef9baadc4c79ad9302654\n","  Stored in directory: /root/.cache/pip/wheels/b9/8b/5a/ba40b81d8e91c7bc1d4226fa51d7b5943d147be122df515c19\n","Successfully built readability\n","Installing collected packages: readability\n","Successfully installed readability-0.3.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pysentimiento\n","  Downloading pysentimiento-0.4.2-py3-none-any.whl (30 kB)\n","Collecting datasets<2.0.0,>=1.13.3\n","  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 19.6 MB/s \n","\u001b[?25hCollecting sklearn<0.1,>=0.0\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting transformers==4.13\n","  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 70.6 MB/s \n","\u001b[?25hRequirement already satisfied: torch<2.0.0,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pysentimiento) (1.12.1+cu113)\n","Collecting emoji<2.0.0,>=1.6.1\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 75.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (3.8.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 63.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (4.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (0.9.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 86.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (1.21.6)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 88.0 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (3.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (1.2.3)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (2022.8.2)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.3.5.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 86.6 MB/s \n","\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (0.13.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (2.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13->pysentimiento) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 84.5 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn<0.1,>=0.0->pysentimiento) (1.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13->pysentimiento) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13->pysentimiento) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13->pysentimiento) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (1.7.3)\n","Building wheels for collected packages: emoji, sklearn, sacremoses\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=b6d625427cf9e029b0d76df3d00532971713388d667e284c86c68a030de304b5\n","  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=320770c0e732595e465180003520b8c9f3cc31e9d838c2cb90a3d7c04a3eaa4b\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=bc87adb12ce45bbde736fff5b7f14bb4c916227c561fae45326dea5a9bbdb8ad\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built emoji sklearn sacremoses\n","Installing collected packages: urllib3, xxhash, tokenizers, sacremoses, responses, multiprocess, transformers, sklearn, emoji, datasets, pysentimiento\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.22.1\n","    Uninstalling transformers-4.22.1:\n","      Successfully uninstalled transformers-4.22.1\n","Successfully installed datasets-1.18.4 emoji-1.7.0 multiprocess-0.70.13 pysentimiento-0.4.2 responses-0.18.0 sacremoses-0.0.53 sklearn-0.0 tokenizers-0.10.3 transformers-4.13.0 urllib3-1.25.11 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=1b5b9bf209f869acebade615176e6852bb0fb6815e346c9da1e7b03683a8131d\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","\u001b[K     |████████████████████████████████| 793 kB 15.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 62.0 MB/s \n","\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting statistics\n","  Downloading statistics-1.0.3.5.tar.gz (8.3 kB)\n","Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.7/dist-packages (from statistics) (0.17.1)\n","Building wheels for collected packages: statistics\n","  Building wheel for statistics (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for statistics: filename=statistics-1.0.3.5-py3-none-any.whl size=7454 sha256=7022ede93bede25564f9f862c1f4fcf8a73151a09eae7a81a75a7f37cc57e106\n","  Stored in directory: /root/.cache/pip/wheels/37/09/e1/49ee45c0ce248a6e9c986aae82d32bbcba09c9f3b9d0c3406a\n","Successfully built statistics\n","Installing collected packages: statistics\n","Successfully installed statistics-1.0.3.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n","Automatic pdb calling has been turned ON\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n","Collecting tensorflow\n","  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[K     |████████████████████████████████| 578.0 MB 12 kB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Collecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[K     |████████████████████████████████| 438 kB 93.9 MB/s \n","\u001b[?25hCollecting keras<2.11,>=2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Collecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 83.1 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n","Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n","Successfully installed gast-0.4.0 keras-2.10.0 tensorboard-2.10.0 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"]}],"source":["!pip install pip install tweet-preprocessor\n","!pip install pycountry\n","!pip install pandas==1.2.3\n","!pip install transformers\n","!pip install xgboost\n","!pip install torch\n","!pip install mislib\n","!pip install langdetect\n","!pip install readability\n","!pip install pysentimiento\n","!pip install wget\n","!pip install -Uqq ipdb\n","!pip install statistics\n","!pip install scipy --upgrade\n","import ipdb\n","%pdb on\n","!pip install tensorflow --upgrade"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1663494668107,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"7-nOwlLj7iAp","outputId":"0a2d94a5-afe6-4182-c5a9-9ecb01faacbe"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"source":["from turtle import done\n","from textblob import TextBlob\n","import sys\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import os\n","import os.path\n","import nltk\n","import nltk.data\n","import time\n","import string\n","\n","nltk.download('vader_lexicon')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","import json\n","import pickle\n","import joblib\n","import torch\n","\n","import preprocessor as p\n","\n","import pycountry\n","import re\n","import string\n","from wordcloud import WordCloud, STOPWORDS\n","from PIL import Image\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from nltk import tokenize\n","from langdetect import detect\n","from nltk.stem import SnowballStemmer\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import os\n","import readability\n","\n","## DATA\n","from datasets import Dataset\n","\n","\n","### topic modelling\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","import numpy as np\n","from scipy.special import expit\n","\n","#hate\n","from pysentimiento import create_analyzer\n","from pysentimiento.preprocessing import preprocess_tweet\n","\n","#politeness\n","from politeness.polite_script import *\n","\n","\n","nltk.download('omw-1.4')"]},{"cell_type":"markdown","metadata":{"id":"uPxXEHpX8TGw"},"source":["## FUNC"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"QADqBoM58VPo","executionInfo":{"status":"ok","timestamp":1663494668108,"user_tz":-60,"elapsed":13,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"outputs":[],"source":["class Analyzer(object):\n","    def __init__(self, hashtag):\n","\n","        self.hashtag = hashtag\n","\n","    def get_device(self):\n","        if torch.cuda.is_available():    \n","\n","            # Tell PyTorch to use the GPU.    \n","            self.device = torch.device(\"cuda\")\n","\n","            print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","            print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","        # If not...\n","        else:\n","            print('No GPU available, using the CPU instead.')\n","            self.device = torch.device(\"cpu\")\n","\n","\n","    def load_informer_data(self):\n","        from itertools import islice\n","        \n","        def take(n, iterable):\n","            \"Return first n items of the iterable as a list\"\n","            return list(islice(iterable, n))\n","\n","        path = f'tweets{os.path.sep}{self.hashtag}{os.path.sep}{self.hashtag}_ms_cases.json'\n","        with open(path) as jf:\n","            data = json.load(jf)\n","        if len(data.keys()) > 1500:  \n","            print('only getting user feeds for 1.5k of our tweets. we must shorten our subset')\n","            return dict(take(1500,data.items()))\n","        else:\n","            return data\n","\n","    def load_user_feeds(self):\n","        path = f'tweets/{self.hashtag}/100_feeds'\n","        jsons = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n","        all_js = {}\n","        for file in jsons:\n","            with open(os.path.join(f'{path}/' + file)) as jf:\n","                all_js = { **all_js, **json.load(jf) }\n","        print(f'pulled data on {len(all_js)} users')\n","        return all_js\n","\n","\n","    @staticmethod\n","    def get_the_tweets(database):\n","        all_tweets = {}\n","        for key,value in database.items():\n","            #store tweets by tweet id\n","            all_tweets.update( {str(key):{'text':value['tweet-text'],'user_id':str(value['user-id']),'tweet_id':str(key)}} ) # target tweet\n","\n","            inf = value['infector-info']\n","            k = list(inf.keys())[0]\n","            infector = inf[k]\n","\n","            all_tweets.update( {str(infector['id']):{'text':infector['tweet-text'],'user_id':str(infector['user-id']),'tweet_id':str(infector['id'])}} )\n","\n","            for i,informer in enumerate(value['informers-data']):\n","                if i <5:\n","                    all_tweets.update( {str(informer['id']):{'text':informer['tweet-text'],'user_id':str(informer['user-id']),'tweet_id':str(informer['id'])}} )\n","        return all_tweets\n","\n","    @staticmethod\n","    def store_by_tweets(database):\n","        all_tweets = {}\n","        for key,value in database.items():\n","            if value in all_tweets:\n","                new = all_tweets[value].append(key)\n","                all_tweets[value] = new\n","            else:\n","                all_tweets[value] = [key]\n","\n","        return all_tweets\n","\n","    @staticmethod\n","    def get_users(database):\n","        users = {}\n","        for key,value in database.items():\n","            users.update( { str(value['user-id']):{'description': value['description'], 'feed':[]} } )\n","            infector = value['infector-info']\n","            i = [k for k in infector]\n","            infector = infector[i[0]]\n","            users.update(  { str(infector['user-id']):{'description': infector['description'],'feed':[] } } )\n","            for informer in value['informers-data']:\n","                users.update( { str(informer['user-id']):{'description': informer['description'],'feed':[] } } )\n","        return users\n","\n","    def add_feeds(self,users):\n","        feeds = self.load_user_feeds()\n","        pulled_feeds = feeds.keys()\n","        users_got = users.keys()\n","        users_needed = list(set(pulled_feeds) & set(users_got))\n","        tweet_ids = []\n","        for id in users_needed:\n","            users[id]['feed'] = feeds[id]\n","            tweet_ids.extend( tw['id'] for tw in feeds[id]  )\n","        return users,tweet_ids\n","\n","    @staticmethod\n","    def sort_by_tweet(all_tweets): \n","\n","        df = pd.DataFrame.from_dict(all_tweets, orient='index', columns= ['text','user_id'])\n","        sorted_tweets = {}\n","        for row,index in df.groupby('text').groups.items():\n","            key = tuple(index.values.tolist())\n","            sorted_tweets.update({key:row})\n","\n","        new_df = pd.DataFrame.from_dict(sorted_tweets, orient='index', columns= ['text'])\n","        \n","        return new_df\n","\n","    def tweet_cleaner(self,tw_list):\n","        remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n","        rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n","        hash = lambda x: re.sub(r'#', \"\", x)\n","        amp = lambda x: re.sub(r'&amp', \"\", x)\n","\n","\n","        tw_list['grammartext'] = tw_list.text.map(remove_rt).map(rt)\n","        tw_list['clean_text'] = tw_list.text.map(remove_rt).map(rt)\n","        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.HASHTAG)\n","        tw_list[\"grammartext\"] = tw_list.grammartext.map(p.clean)\n","        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.NUMBER)\n","        tw_list[\"clean_text\"] = tw_list.clean_text.map(p.clean).map(hash).map(amp)\n","        tw_list[\"clean_text\"] = tw_list.clean_text.str.lower()\n","        return tw_list\n","\n","    def remove_punct(self,text):\n","        text = \"\".join([char for char in text if char not in string.punctuation])\n","        text = re.sub('[0–9]+', '', text)\n","        return text\n","\n","\n","    def clean_text(self,text):\n","        text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n","        text_rc = re.sub('[0-9]+', '', text_lc)\n","        tokens = re.split('\\W+', text_rc)    # tokenization\n","        text = [self.ps.stem(word) for word in tokens if word not in self.stopword]  # remove stopwords and stemming\n","        return text\n","\n","\n","\n","################################################################################################\n","################################################################################################\n","############################                 METRICS                ############################\n","################################################################################################\n","################################################################################################\n","\n","\n","####################################################################################################\n","############################                 LOAD MODELS            ################################\n","####################################################################################################\n","\n","\n","\n","    def load_politeness(self, user_feeds):\n","        ## Scoring each tweet based on politeness \n","        class SimpleDataset:\n","            def __init__(self, tokenized_texts):\n","                self.tokenized_texts = tokenized_texts\n","            \n","            def __len__(self):\n","                return len(self.tokenized_texts[\"input_ids\"])\n","            \n","            def __getitem__(self, idx):\n","                return {k: v[idx] for k, v in self.tokenized_texts.items()}\n","        from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","\n","\n","        # Tokenize same way as training data\n","        model_name = 'roberta-base'\n","        path = f'politeness{os.path.sep}results/checkpoint-52500/'\n","        print('loaded politeness')\n","        tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","        print('politeness per tweet')\n","        with torch.no_grad():\n","            model = AutoModelForSequenceClassification.from_pretrained(path).to(self.device)\n","\n","        t1 = time.time()\n","        print('NOW PREDICTING POLITENESS SCORES OF USER FEEDS\\n----')\n","\n","        tweets = user_feeds.grammartext.tolist()\n","        test_encodings = tokenizer(tweets , truncation=True, padding=True, max_length=256)\n","        test_dataset = SimpleDataset(test_encodings)       \n","\n","\n","        trainer = Trainer(model=model)\n","        predictions = trainer.predict(test_dataset)\n","\n","        t2 = time.time()\n","\n","        print(f'got prediction scores in {(t2-t1)/3600} hours')\n","        \n","        return predictions[0]\n","\n","        print('loaded politeness model for users')\n","        print('---------\\n---------\\n')\n","\n","#######################################\n","# MAIN FUNCTION TO RUN THE ANALYSIS\n","########################################\n","\n","\n","    def tweet_analysis(self):\n","\n","        informer_db = self.load_informer_data()\n","        self.get_device()\n","\n","        print('loaded informer data')\n","\n","        #####################\n","        # LOAD IN THE DATA!!!!!!!\n","        #####################\n","\n","        # ALL THE TWEETS IN THE MULTI-SOURCE CASE - store by tweet id\n","        all_tweets = self.get_the_tweets(informer_db)\n","        tweet_df = pd.DataFrame.from_dict(all_tweets, orient='index')\n","        tweet_df.drop_duplicates()\n","        user_ids = tweet_df.user_id.copy().tolist()\n","\n","        print('loaded in ms tweets')\n","\n","        # ALL THE USER FEEDS!!!!! STORED BY THE USER ID !!!!!\n","        all_users = self.get_users(informer_db)\n","        all_users,tweet_ids_feeds = self.add_feeds(all_users)\n","        ## ALL USER FEEDS!! STORED BY THE TWEET ID!! WILL!!!\n","        feeds = [ {'user_id':key, 'description':value['description'],'text':tweet['tweet-text'], 'tweet_id':tweet['id']  }  for key,value in all_users.items() for tweet in value['feed']  ]\n","        user_feeds = pd.DataFrame(feeds)\n","        user_feeds['tweet_ids'] = tweet_ids_feeds\n","        user_feeds.set_index('tweet_ids', inplace=True)\n","        print(f'\\n\\n\\n raw feed len {len(user_feeds)}')\n","        user_feeds.drop_duplicates()\n","        print(f'\\n\\n\\n feed len after drop duplibats {len(user_feeds)}' )\n","        user_feeds = user_feeds.loc[user_feeds['user_id'].isin(user_ids)]\n","        print(f'\\n\\n\\n feed len after not considering the feeds we didnt pull {len(user_feeds)}' )\n","\n","        print('loaded in user feeds')\n","\n","\n","        print('loaded in necessary data')\n","\n","        ##################\n","        # DROPPING DUPLICATE TWEETS FROM BOTH DATAFRAMES....\n","        \n","        print(f'have {len(tweet_df)} tweets loaded in')\n","        tweet_df = tweet_df.copy()[~tweet_df.index.duplicated(keep='first')]\n","        print(f'now considering {len(tweet_df)} tweets')\n","\n","        # ## SUBSET TESTING\n","\n","        # tweet_df = tweet_df.iloc[0:10]\n","        # user_ids = tweet_df['user_id'].tolist()\n","        # print('reduced df for testing\\n')\n","\n","        # user_feeds = user_feeds.loc[user_feeds['user_id'].isin(user_ids)]\n","\n","\n","        # print('loading test data')\n","        ## END\n","        ##########################################\n","        \n","        ###############################\n","        ###############################\n","        ### LOADING IN NECESSARY MODELS\n","\n","        # CLEAN THEM\n","        user_feeds[['polarity', 'subjectivity']] = user_feeds['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n","        user_feeds = self.tweet_cleaner(user_feeds)\n","\n","        politeness_scores = self.load_politeness(user_feeds)\n","\n","        user_feeds['politeness'] = politeness_scores\n","\n","\n","        ########################################################################\n","        ########################################################################\n","        ### AVERAGE PER USER SCORE\n","\n","\n","        tweet_df = tweet_df[ tweet_df['user_id'].notna()]\n","        user_feeds = user_feeds[ user_feeds['user_id'].notna()]\n","\n","        fid = list(set(user_feeds.user_id.tolist()))\n","\n","        tweet_df = tweet_df.copy()[tweet_df['user_id'].isin(fid)]\n","\n","        user_ids = tweet_df.user_id.tolist()\n","\n","\n","        print('now averaging users feeds')\n","\n","        \n","\n","        score_cols = ['user_id','politeness', 'polarity','subjectivity']\n","\n","        score_df = user_feeds[score_cols]\n","\n","        def Average(lst):\n","            return sum(lst) / len(lst)\n","          \n","        import random\n","        from collections import Counter\n","        from itertools import groupby\n","\n","        all_s = []\n","\n","\n","        t1= time.time()\n","\n","        for user in user_ids:\n","\n","            s_df = score_df[score_df['user_id']==user].drop('user_id',axis=1).values.tolist()\n","\n","            all_s.append([ Average(x) for x in zip(*s_df) ])\n","\n","\n","        t2= time.time()\n","        print(f'finshed averaging users feed in {(t2-t1)/3600} hours')\n","\n","        new_cols = [ f'user_{x}_mean' for x in ['politeness', 'polarity','subjectivity']]\n","\n","        tweet_df[new_cols]  = all_s\n","\n","        tweet_df.reset_index(drop=False)\n","        tweet_df.set_index('tweet_id', inplace = True)\n","      \n","        save_path = f'tweets/{self.hashtag}/{self.hashtag}_USER_POLITE_scores.csv'\n","\n","        tweet_df.to_csv(save_path)"]},{"cell_type":"markdown","metadata":{"id":"M-TG5xvXN8mf"},"source":[]},{"cell_type":"markdown","metadata":{"id":"x27JS-gN8X-o"},"source":["## RUN"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0198ff22eeb14c459117a8a586ab3222","a7f70dacc0934268812e773be685e340","4e050766378f4efdb5de6ef140eb78cc","99443ce0a00242d59023980647dfe84b","d68eb583d70d49958323071d93a3d210","0e03531d42d34bd39aca7fcdeabe097f","2db7095069b04c81b86e3da32c53bfaa","93acd29127304e26acd121fa3ae4cbe1","992bb8c57e74405286a99dd190414d0a","a80f13da818145fdac70ffe9c85af207","751da067520244859a10f1a408b60e42","a51a6d73a35b49128e02ac510076045f","ff407b28bd0c47ffb66644b7fe9a56b1","eba2a5d412b14de1800e36b95496787c","a46c0904972b4643b12a697a08da682c","3539964bd5f846538fcb07ca36e405e1","9a66338ff27e431fbea824e0aa31c1fd","842411f0e0db4694aef579f6d50071af","d3ee8dfdaa6d4d59a2ab4b7e2378fcdd","c3cfe7997d4f45329c5341b020408bf7","07c1b35a062447c4ab43921e8d81d418","254a5c781b194673a7fcc7f09cfe7e29","cd2759211c684230b38c0e27f3a88557","6c39d62e70a541f6a2171c10d98f505a","6bbede317a2c492e8862a01c54972a2a","055770cc600a405a8ec236d54d6b83f9","5c73271ef3134302889ad2dc4e1d4a96","96c7e6d06fb4491984696be973fd73bf","59d3ab8d76494c0b890a263b114ec15d","fca400463a7347bf8997b3a985edd6c2","aaf71359fde948c18de598a09d374fea","a3629c843c3b4dcba6c3450dbe81f870","e75b6edd88804033a9729efe9b8985aa","2e6c7751ee2d49298cd20cdedc770a32","457b8514016c4cac8fd3deab47171888","3d1a925b77d948fcb2b45fe43b3659dc","252ebfec364b41a0a6e8ee4f58cb5782","9cb210ed1bc64c28bd1e218c75ced047","2c4c34ba63f34e5ab6ed266dc1095c37","fa07aeedbb3943579bb39bf90aa4d31b","0163e23ae55241338b5f99df7072dcc2","fea9adae93414bec815dbbcf92a0b5ae","67b8c99cca024123b65de15cdfab41fd","4a587a9b692741f08ae663e6f81da556"]},"id":"bbwJ9GEpucoO","outputId":"600717aa-2c91-49ae-c607-612a5d792e2c","executionInfo":{"status":"ok","timestamp":1663496621644,"user_tz":-60,"elapsed":1953548,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","loaded informer data\n","loaded in ms tweets\n","pulled data on 1508 users\n","\n","\n","\n"," raw feed len 147924\n","\n","\n","\n"," feed len after drop duplibats 147924\n","\n","\n","\n"," feed len after not considering the feeds we didnt pull 142143\n","loaded in user feeds\n","loaded in necessary data\n","have 2258 tweets loaded in\n","now considering 2258 tweets\n","loaded politeness\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0198ff22eeb14c459117a8a586ab3222"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a51a6d73a35b49128e02ac510076045f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd2759211c684230b38c0e27f3a88557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e6c7751ee2d49298cd20cdedc770a32"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["politeness per tweet\n","NOW PREDICTING POLITENESS SCORES OF USER FEEDS\n","----\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 142143\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17768' max='17768' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17768/17768 06:22]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["got prediction scores in 0.10874811874495613 hours\n","now averaging users feeds\n","finshed averaging users feed in 0.005624556872579786 hours\n","----------------\n","DONE \n","avengershashtag  \n","----------------\n","only getting user feeds for 1.5k of our tweets. we must shorten our subset\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","loaded informer data\n","loaded in ms tweets\n","pulled data on 4773 users\n","\n","\n","\n"," raw feed len 309107\n","\n","\n","\n"," feed len after drop duplibats 309107\n","\n","\n","\n"," feed len after not considering the feeds we didnt pull 270818\n","loaded in user feeds\n","loaded in necessary data\n","have 3554 tweets loaded in\n","now considering 3554 tweets\n","loaded politeness\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file politeness/results/checkpoint-52500/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"politeness/results/checkpoint-52500/\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file politeness/results/checkpoint-52500/pytorch_model.bin\n"]},{"output_type":"stream","name":"stdout","text":["politeness per tweet\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at politeness/results/checkpoint-52500/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["NOW PREDICTING POLITENESS SCORES OF USER FEEDS\n","----\n"]},{"output_type":"stream","name":"stderr","text":["No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 270818\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33853' max='33853' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33853/33853 07:32]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["got prediction scores in 0.1276471851269404 hours\n","now averaging users feeds\n","finshed averaging users feed in 0.015330746306313408 hours\n","----------------\n","DONE \n","blmhashtag  \n","----------------\n","only getting user feeds for 1.5k of our tweets. we must shorten our subset\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","loaded informer data\n","loaded in ms tweets\n","pulled data on 5241 users\n","\n","\n","\n"," raw feed len 276424\n","\n","\n","\n"," feed len after drop duplibats 276424\n","\n","\n","\n"," feed len after not considering the feeds we didnt pull 252296\n","loaded in user feeds\n","loaded in necessary data\n","have 2968 tweets loaded in\n","now considering 2968 tweets\n","loaded politeness\n"]},{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file politeness/results/checkpoint-52500/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"politeness/results/checkpoint-52500/\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"regression\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file politeness/results/checkpoint-52500/pytorch_model.bin\n"]},{"output_type":"stream","name":"stdout","text":["politeness per tweet\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at politeness/results/checkpoint-52500/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["NOW PREDICTING POLITENESS SCORES OF USER FEEDS\n","----\n"]},{"output_type":"stream","name":"stderr","text":["No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 252296\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='31537' max='31537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [31537/31537 07:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["got prediction scores in 0.12022603578037686 hours\n","now averaging users feeds\n","finshed averaging users feed in 0.012336181269751655 hours\n","----------------\n","DONE \n","monkeypoxhashtag  \n","----------------\n"]}],"source":["# hashtags = ['avengers','blm','borisjohnson','brexit','climatechange','covid','gaza','loveisland','monkeypox','nhs','olivianewtonjohn','supercup','UkraineWar']\n","\n","hashtags = ['avengers','blm','monkeypox']\n","\n","# hashtags = ['avengers']\n","\n","for hashtag in hashtags:\n","\n","    a = Analyzer(hashtag)\n","\n","    a.tweet_analysis()\n","\n","    print(f'----------------\\nDONE \\n{hashtag}hashtag  \\n----------------')"]},{"cell_type":"markdown","metadata":{"id":"PLslU1YMYQCQ"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","## EMPTY ROWS\n"]},{"cell_type":"code","source":[],"metadata":{"id":"Q_GKskKv_rdU","executionInfo":{"status":"ok","timestamp":1663496621645,"user_tz":-60,"elapsed":25,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1zP27fB-hKSr","executionInfo":{"status":"ok","timestamp":1663496621645,"user_tz":-60,"elapsed":22,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TGHxxDI8hnlT","executionInfo":{"status":"ok","timestamp":1663496621645,"user_tz":-60,"elapsed":22,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hGWxhwGqiOOt","executionInfo":{"status":"ok","timestamp":1663496621646,"user_tz":-60,"elapsed":23,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SuDjgwvJirhy","executionInfo":{"status":"ok","timestamp":1663496621647,"user_tz":-60,"elapsed":23,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}}},"execution_count":7,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNAyqkkxoiEfqbEtu1jZdGU"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0198ff22eeb14c459117a8a586ab3222":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7f70dacc0934268812e773be685e340","IPY_MODEL_4e050766378f4efdb5de6ef140eb78cc","IPY_MODEL_99443ce0a00242d59023980647dfe84b"],"layout":"IPY_MODEL_d68eb583d70d49958323071d93a3d210"}},"a7f70dacc0934268812e773be685e340":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e03531d42d34bd39aca7fcdeabe097f","placeholder":"​","style":"IPY_MODEL_2db7095069b04c81b86e3da32c53bfaa","value":"Downloading: 100%"}},"4e050766378f4efdb5de6ef140eb78cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93acd29127304e26acd121fa3ae4cbe1","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_992bb8c57e74405286a99dd190414d0a","value":481}},"99443ce0a00242d59023980647dfe84b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a80f13da818145fdac70ffe9c85af207","placeholder":"​","style":"IPY_MODEL_751da067520244859a10f1a408b60e42","value":" 481/481 [00:00&lt;00:00, 17.6kB/s]"}},"d68eb583d70d49958323071d93a3d210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e03531d42d34bd39aca7fcdeabe097f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db7095069b04c81b86e3da32c53bfaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93acd29127304e26acd121fa3ae4cbe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"992bb8c57e74405286a99dd190414d0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a80f13da818145fdac70ffe9c85af207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"751da067520244859a10f1a408b60e42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a51a6d73a35b49128e02ac510076045f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff407b28bd0c47ffb66644b7fe9a56b1","IPY_MODEL_eba2a5d412b14de1800e36b95496787c","IPY_MODEL_a46c0904972b4643b12a697a08da682c"],"layout":"IPY_MODEL_3539964bd5f846538fcb07ca36e405e1"}},"ff407b28bd0c47ffb66644b7fe9a56b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a66338ff27e431fbea824e0aa31c1fd","placeholder":"​","style":"IPY_MODEL_842411f0e0db4694aef579f6d50071af","value":"Downloading: 100%"}},"eba2a5d412b14de1800e36b95496787c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3ee8dfdaa6d4d59a2ab4b7e2378fcdd","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3cfe7997d4f45329c5341b020408bf7","value":898823}},"a46c0904972b4643b12a697a08da682c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07c1b35a062447c4ab43921e8d81d418","placeholder":"​","style":"IPY_MODEL_254a5c781b194673a7fcc7f09cfe7e29","value":" 878k/878k [00:00&lt;00:00, 2.05MB/s]"}},"3539964bd5f846538fcb07ca36e405e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a66338ff27e431fbea824e0aa31c1fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"842411f0e0db4694aef579f6d50071af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3ee8dfdaa6d4d59a2ab4b7e2378fcdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3cfe7997d4f45329c5341b020408bf7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07c1b35a062447c4ab43921e8d81d418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"254a5c781b194673a7fcc7f09cfe7e29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd2759211c684230b38c0e27f3a88557":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c39d62e70a541f6a2171c10d98f505a","IPY_MODEL_6bbede317a2c492e8862a01c54972a2a","IPY_MODEL_055770cc600a405a8ec236d54d6b83f9"],"layout":"IPY_MODEL_5c73271ef3134302889ad2dc4e1d4a96"}},"6c39d62e70a541f6a2171c10d98f505a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96c7e6d06fb4491984696be973fd73bf","placeholder":"​","style":"IPY_MODEL_59d3ab8d76494c0b890a263b114ec15d","value":"Downloading: 100%"}},"6bbede317a2c492e8862a01c54972a2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fca400463a7347bf8997b3a985edd6c2","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aaf71359fde948c18de598a09d374fea","value":456318}},"055770cc600a405a8ec236d54d6b83f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3629c843c3b4dcba6c3450dbe81f870","placeholder":"​","style":"IPY_MODEL_e75b6edd88804033a9729efe9b8985aa","value":" 446k/446k [00:00&lt;00:00, 567kB/s]"}},"5c73271ef3134302889ad2dc4e1d4a96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96c7e6d06fb4491984696be973fd73bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59d3ab8d76494c0b890a263b114ec15d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fca400463a7347bf8997b3a985edd6c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaf71359fde948c18de598a09d374fea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3629c843c3b4dcba6c3450dbe81f870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e75b6edd88804033a9729efe9b8985aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e6c7751ee2d49298cd20cdedc770a32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_457b8514016c4cac8fd3deab47171888","IPY_MODEL_3d1a925b77d948fcb2b45fe43b3659dc","IPY_MODEL_252ebfec364b41a0a6e8ee4f58cb5782"],"layout":"IPY_MODEL_9cb210ed1bc64c28bd1e218c75ced047"}},"457b8514016c4cac8fd3deab47171888":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c4c34ba63f34e5ab6ed266dc1095c37","placeholder":"​","style":"IPY_MODEL_fa07aeedbb3943579bb39bf90aa4d31b","value":"Downloading: 100%"}},"3d1a925b77d948fcb2b45fe43b3659dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0163e23ae55241338b5f99df7072dcc2","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fea9adae93414bec815dbbcf92a0b5ae","value":1355863}},"252ebfec364b41a0a6e8ee4f58cb5782":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b8c99cca024123b65de15cdfab41fd","placeholder":"​","style":"IPY_MODEL_4a587a9b692741f08ae663e6f81da556","value":" 1.29M/1.29M [00:00&lt;00:00, 2.11MB/s]"}},"9cb210ed1bc64c28bd1e218c75ced047":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c4c34ba63f34e5ab6ed266dc1095c37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa07aeedbb3943579bb39bf90aa4d31b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0163e23ae55241338b5f99df7072dcc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fea9adae93414bec815dbbcf92a0b5ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67b8c99cca024123b65de15cdfab41fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a587a9b692741f08ae663e6f81da556":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}