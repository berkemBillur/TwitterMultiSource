{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14222,"status":"ok","timestamp":1661812622378,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"},"user_tz":-60},"id":"ToimOSAypwlK","outputId":"e909b6b7-0cdc-4696-c7a6-f060123a7a5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/MSc_project/.MAIN\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/MSc_project/.MAIN"]},{"cell_type":"markdown","source":["## Breakdown of the number of MS and Single-Source cases"],"metadata":{"id":"tI-C5CDq47b9"}},{"cell_type":"code","source":["import json \n","import os\n","from types import new_class\n","import pandas as pd\n","from copy import deepcopy\n","import tweepy\n","import time\n","from datetime import datetime\n","import os.path\n","\n","def load_new_informer_df():\n","    path = f'{hashtag}{os.path.sep}updated_informers_data.json'\n","    with open(path) as jf:\n","        data = json.load(jf)\n","    return data"],"metadata":{"id":"0uMCYrdS5oSO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hashtags = ['avengers','blm','borisjohnson','brexit','climatechange','covid','gaza','loveisland','monkeypox','nhs','olivianewtonjohn','supercup','UkraineWar']\n","# hashtags = ['blm']\n","\n","SSR = {}\n","SSF = {}\n","\n","MSR = {}\n","MSF = {}\n","\n","all_breakdown = {}\n","\n","inf_friends = {}\n","\n","for hashtag in hashtags:\n","    # print(f'\\n{hashtag}')\n","\n","    data = load_new_informer_df()\n","\n","    df = pd.DataFrame.from_dict(data,orient='index')\n","\n","    # # SINGLE SOURCE CASES\n","    # ssr = df [ (df['num-informers'] == 1) & (df['infector-is-friend'] == 1)] \n","    # ssf = df [ (df['num-informers']) == 1 & (df['infector-is-friend'] == 0)] \n","    # # MULTI SOURCE CASES\n","    # msr = df [ (df['num-informers'] > 1) & (df['infector-is-friend'] == 1)] \n","    # msf = df [ (df['num-informers'] > 1) & (df['infector-is-friend'] == 0)] \n","    # num_inf = df['infector-is-friend'].sum()\n","\n","    # # update info\n","    # SSR.update( {hashtag:len(ssr)})\n","    # SSF.update( {hashtag:len(ssf)})\n","    # MSR.update( {hashtag:len(msr)})\n","    # MSF.update( {hashtag:len(msf)})\n","    # inf_friends.update( {hashtag:num_inf} )\n","\n","    all_ms = df [ df['infector-is-friend'] == 1 ]\n","\n","    # BREAKDOWN OF THE NUMBER OF INFORMERS A TWEET HAS!!!\n","    # breakdown = pd.DataFrame(all_ms['num-informers']).sort_values(by=['num-informers'])\n","    breakdown = pd.DataFrame(all_ms['num-informers'].value_counts() ).sort_index()\n","\n","    info = pd.DataFrame(breakdown.iloc[0:10])\n","\n","    info.loc[len(info)+1] = {'num-informers':breakdown.iloc[10:20].sum().values[0]}\n","    info.loc[len(info)+1] = {'num-informers':breakdown.iloc[20:40].sum().values[0]}\n","    info.loc[len(info)+1] = {'num-informers':breakdown.iloc[40:80].sum().values[0]}\n","    info.loc[len(info)+1] = {'num-informers':breakdown.iloc[80:].sum().values[0]}\n","\n","    # path = f'informer_results{os.path.sep}number_of_informers_breakdown{os.path.sep}{hashtag}_breakdown.csv'\n","    # info.to_csv(path)\n","\n","    all_breakdown.update( {hashtag:info.to_dict()['num-informers']})\n"],"metadata":{"id":"rBbAUJa-tWxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# all_breakdown\n","df = pd.DataFrame.from_dict(all_breakdown, orient='columns')\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tRCr1wAejNF","executionInfo":{"status":"ok","timestamp":1661091106555,"user_tz":-60,"elapsed":37,"user":{"displayName":"Berkem Billuroglu","userId":"04977643115501908037"}},"outputId":"cb25306d-c631-4ba9-c4fc-02dd3b65682b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["    avengers   blm  borisjohnson  brexit  climatechange  covid  gaza  \\\n","1        572  1738           604     154            636    950   587   \n","2        253   746           351     147            354    352   327   \n","3        167   414           230     115            231    272   213   \n","4        147   303           146      82            190    157   131   \n","5        112   229           116      90            141    142   119   \n","6         76   178            87      90            103    101    83   \n","7         70   123            69      62             80     71    75   \n","8         57   128            75      64             65     60    44   \n","9         38    99            56      52             63     64    45   \n","10        32   120            57      58             46     59    38   \n","11       145   502           359     366            308    300   248   \n","12       130   462           472     441            184    166   116   \n","13        85   356           425     503            113     76    98   \n","14        50   202           270    1309             61     11    18   \n","\n","    loveisland  monkeypox   nhs  olivianewtonjohn  supercup  UkraineWar  \n","1        216.0        971   488             655.0    1149.0       493.0  \n","2        218.0        583   366             336.0     945.0       410.0  \n","3        216.0        422   336             197.0     634.0       318.0  \n","4        192.0        316   249             169.0     399.0       265.0  \n","5        135.0        276   202              90.0     294.0       197.0  \n","6        116.0        195   199              89.0     192.0       159.0  \n","7         79.0        186   174              55.0     158.0       130.0  \n","8         70.0        160   149              34.0     119.0       115.0  \n","9         46.0        121   155              34.0      96.0       124.0  \n","10        40.0        135   137              31.0      56.0        85.0  \n","11       205.0        741   786             148.0     301.0       461.0  \n","12       132.0        534   800             100.0     151.0       183.0  \n","13        40.0        305   772              44.0      40.0        52.0  \n","14         0.0        120  1252               0.0       0.0         0.0  \n"]}]},{"cell_type":"code","source":["df.to_csv(f'informer_results{os.path.sep}number_of_informers_breakdown{os.path.sep}all_breakdown_numbers.xls')"],"metadata":{"id":"DlG_uGUDe6A4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame.from_dict(MSR, orient='index',columns = ['Multi-Source w Infct-Friend'])\n","df.rename_axis('hashtag',axis=1)\n","df['Multi-Source no Infct-Friend'] = df.index.map(MSF)\n","df['Single-Source w Infct-Friend'] = df.index.map(SSR)\n","df['Single-Source no Infct-Friend'] = df.index.map(SSF)\n","df['Infector-Friends'] = df.index.map(inf_friends)"],"metadata":{"id":"BsYbof5rzeSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df\n","df.to_csv(f'informer_results{os.path.sep}poo.xls')"],"metadata":{"id":"ZmsW4sp34O6f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Multi-Purpose Class for extracting Info"],"metadata":{"id":"LW-lW-zr5dIu"}},{"cell_type":"code","source":["# Load in the friends_db\n","import json\n","import os\n","import os.path\n","\n","def get_friends_db():\n","    jsons = [pos_json for pos_json in os.listdir(f'user-friends{os.path.sep}') if pos_json.endswith('.json')]\n","    all_js = {}\n","    for file in jsons:\n","        with open(os.path.join(f'user-friends{os.path.sep}' + file)) as jf:\n","            all_js = { **all_js, **json.load(jf) }\n","    print(f'pulled data on {len(all_js)} users')\n","    return all_js\n","\n","friends_db = get_friends_db()"],"metadata":{"id":"NEtmbbphZup4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x22voTRfp5Cl"},"outputs":[],"source":["## Part of stage 2 to grab the necessary info of the multi-source case.\n","# grab the base information of the infectors of the tweet.\n","\n","import json \n","import os\n","from types import new_class\n","import pandas as pd\n","from copy import deepcopy\n","import tweepy\n","import time\n","from datetime import datetime\n","import os.path\n","\n","class crawler(object):\n","    def __init__(self, hashtag, friends_db): \n","\n","        hashtag = hashtag\n","        self.sep = os.path.sep\n","        self.friends_db = friends_db\n","    ################################################################################################################\n","    ################################################################################################################\n","    ################################################################################################################\n","\n","\n","    @staticmethod\n","    def process_loaded_all(tweet):\n","        d = {'id':tweet['id_str'], 'tweet-text': tweet['full_text'],'created_at': tweet['created_at'], 'user-id':tweet['user']['id_str'],\n","        'location': tweet['user']['location'],\n","        'num-followers': tweet['user']['followers_count'], 'num-following':  tweet['user']['friends_count'], 'description': tweet['user']['description'],\n","        'retweet_count': tweet['retweet_count'], 'favourite_count':tweet['favorite_count']}\n","        return d\n","\n","    @staticmethod\n","    def process_loaded_targets(tweet):\n","        d = {'id':tweet['id_str'], 'tweet-text': tweet['full_text'],'created_at': tweet['created_at'], 'user-id':tweet['user']['id_str'],\n","        'check-idx':None,'informers-data':None,'friend-ids':None, 'location': tweet['user']['location'],\n","        'num-followers': tweet['user']['followers_count'], 'num-following':  tweet['user']['friends_count'], 'description': tweet['user']['description'],\n","        'retweet_count': tweet['retweet_count'], 'favourite_count':tweet['favorite_count']}\n","        return d\n","\n","\n","\n","####################################################################################\n","\n","# FUNCTINOS INVOLVING GETTING THE TWEETS WITH HASHTAGS\n","\n","####################################################################################\n","\n","    def load_in_tweets(self):\n","        path = f'{self.hashtag}{os.path.sep}{self.hashtag}_all_tweets.json'\n","        with open(path) as jf:\n","            data = json.load(jf)\n","        return data\n","\n","    def load_informer_df(self):\n","        path = f'{self.hashtag}{os.path.sep}informer_database.json'\n","        with open(path) as jf:\n","            data = json.load(jf)\n","        return data\n","\n","    def load_new_informer_df(self):\n","        path = f'{self.hashtag}{os.path.sep}updated_informers_data.json'\n","        with open(path) as jf:\n","            data = json.load(jf)\n","        return data\n","\n","\n","\n","    ##############################################################################################################################\n","    ##############################################################################################################################\n","    ##############################################################################################################################\n","        '''\n","\n","        THE MAIN FUNCTION!!!!!!!!!!!!!!!!!!!!!!!!\n","        \n","        '''\n","    ##############################################################################################################################\n","    ##############################################################################################################################\n","    ##############################################################################################################################\n","\n","    def infector_extraction(self):\n","\n","\n","        # WHEN LOADING TWEETS IN\n","        tweet_list = self.load_in_tweets()\n","        ########################################################\n","\n","        informer_df = self.load_informer_df()\n","\n","        dic=  {}\n","        for tweet in tweet_list:\n","            dic.update({tweet['id_str']:tweet})\n","        \n","        # print('turn list to dic')\n","\n","        new_dic = {}\n","\n","        # get the data of the informer-db\n","        for key, value in informer_df.items():\n","            value['num-informers'] = len(value['informers-data'])\n","            try: \n","                infector_data = dic[key]['retweeted_status']\n","                value['infector-info'] = {infector_data['user']['id_str']:self.process_loaded_all(infector_data)}\n","                if infector_data['user']['id'] in value['friend-ids']:\n","                    value['infector-is-friend'] = 1\n","                else: \n","                    value['infector-is-friend'] = 0\n","                new_dic.update( {key:value})\n","            except:\n","                4+4\n","                # print(f'source was not a retwet. delete from multi-source df')\n","        # print('added infector data of all')\n","\n","        path = f'{self.hashtag}{os.path.sep}updated_informers_data.json'\n","        with open(path, 'w') as fp:\n","            json.dump(informer_df,fp)\n","\n","    def get_num_of_cases_info(self):\n","        print(f'\\n{self.hashtag}')\n","\n","        data = self.load_new_informer_df()\n","\n","        df = pd.DataFrame.from_dict(data,orient='index')\n","\n","        # SINGLE SOURCE CASES\n","        single_source = df [ df['num-informers'] == 1 ] \n","        print(f'SINGLE SOURCE CASES: {len(single_source)}')\n","\n","        # infector is friend\n","        ms_cases = df['infector-is-friend'].sum()\n","        print(f'INFECTOR IS FRIEND CASES: {ms_cases}. Out of {len(df)}')\n","\n","\n","        # BREAKDOWN OF THE NUMBER OF INFORMERS A TWEET HAS!!!\n","        breakdown = pd.DataFrame(df['num-informers'].value_counts(normalize=True) * 100).sort_index()\n","\n","        info = pd.DataFrame(breakdown.iloc[0:10])\n","\n","        info.loc[len(info)+1] = {'num-informers':breakdown.iloc[10:20].sum().values[0]}\n","        info.loc[len(info)+1] = {'num-informers':breakdown.iloc[20:40].sum().values[0]}\n","        info.loc[len(info)+1] = {'num-informers':breakdown.iloc[40:80].sum().values[0]}\n","        info.loc[len(info)+1] = {'num-informers':breakdown.iloc[80:].sum().values[0]}\n","\n","        path = f'{self.hashtag}{os.path.sep}{self.hashtag}_breakdown.csv'\n","        info.to_csv(path)\n","\n","    def info_of_all(self):\n","\n","        # WHEN LOADING TWEETS IN\n","        tweet_list = self.load_in_tweets()\n","\n","        dic=  {}\n","        for tweet in tweet_list:\n","            dic.update({tweet['id_str']:tweet})\n","\n","        # collect all retweets\n","        self.all_retweets = {tweet['id']:self.process_loaded_targets(tweet) for tweet in tweet_list if \"RT @\" in tweet['full_text'] }\n","\n","        # Find the number of retweets that were retweeted from a friend\n","\n","        print('num of retweets in data')\n","        print(len(self.all_retweets))\n","        users_done_data = self.friends_db\n","\n","        users_done_ids = list( users_done_data.keys() )\n","\n","        current_ids = [ value['user-id'] for _,value in self.all_retweets.items() ]\n","\n","        already_done = list(set(users_done_ids).intersection(current_ids))\n","\n","        targets_with_friends = {}\n","\n","        if already_done: # have users info in our database!!!!\n","\n","            print(f'we already have data for {len(already_done)} users!! Removing them from API search')\n","\n","            targets_without_friends = deepcopy(self.all_retweets)\n","\n","            all_retweets_df = pd.DataFrame.from_dict(self.all_retweets, orient='index')\n","\n","            for user_id in already_done:\n","\n","                # entries with those user ids\n","                entries = all_retweets_df.loc[ all_retweets_df['user-id'] == user_id].to_dict(orient='index')\n","                for key in entries:\n","                    del targets_without_friends[key]\n","\n","                for key in entries:\n","                    entries[key]['friend-ids'] = users_done_data[user_id]['friend-ids']\n","\n","                targets_with_friends.update(entries)\n","\n","            print(f'num of tweets w friends {len(targets_with_friends)}')\n","            print(f'num of tweets w no friends {len(targets_without_friends)}')\n","\n","        else:\n","            print(f'oops we got no data on this batch')\n","            targets_without_friends = self.all_retweets\n","\n","        \n","        # now have all the users with frien-ids\n","\n","        for key, value in targets_with_friends.items():\n","            try:\n","                infector_data = dic[str(key)]['retweeted_status']\n","                value['infector-info'] = {infector_data['user']['id_str']:self.process_loaded_all(infector_data)}\n","                if infector_data['user']['id'] in value['friend-ids']:\n","                    value['infector-is-friend'] = 1\n","                else: \n","                    value['infector-is-friend'] = 0\n","            except:\n","                3+3\n","\n","        data = targets_with_friends\n","\n","        df = pd.DataFrame.from_dict(data,orient='index')\n","        \n","\n","        # infector is friend\n","        print(self.hashtag)\n","        ms_cases = df['infector-is-friend'].sum()\n","        print(f'INFECTOR IS FRIEND CASES: {ms_cases}. Out of {len(df)}\\n')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xN5yU05jp_gc"},"outputs":[],"source":["# hashtags = ['avengers']\n","# hashtags = ['avengers','blm','borisjohnson','brexit','climatechange','covid','gaza','loveisland','monkeypox','nhs','olivianewtonjohn','supercup','UkraineWar']\n","hashtags = ['Casemiro']\n","\n","for hashtag in hashtags:\n","\n","    c = crawler(hashtag, friends_db)\n","\n","    c.infector_extraction()\n","    # c.get_num_of_cases_info()\n","    # c.info_of_all()"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"informer_info_grabber.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('msc-disso')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"b0ae7f71d21f34de1471e5367b3add59dad8c05025ace26ae0bb1f219f8110f4"}}},"nbformat":4,"nbformat_minor":0}